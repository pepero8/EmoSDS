{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Have you ever thought about taking up painting?\nuser: <happiness> Yeah, I've always wanted to try something creative.\nEmoSDS: <sadness> It's just that I can't seem to find the time for it.\n user: <sosp><13><79><291><79><592><136><13><235><13><136><489><274><47><477><628><304><933><204><91><162><99><686><43><173><231><213><173><370><450><91><128><574><162><680><333><309><350><470><454><493><288><162><275><665><309><304><120><933><450><204><162><511><708><672><19><333><775><296><108><47><477><360><350><283><232><933><204><998><584><486><890><295><31><136><365><eosp> ", "plain_text": "<surprise> I don't painted tiger. EmoSDS: <surprise> Wait, really? Are you telling me you haven’t painted one yet?", "residual_length": 110, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Surprise/0012_001496.npy", "dialogue_id": "468_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe we finally made it to this restaurant!\nuser: <neutral> Yeah, I've heard great things about their dumplings.\nEmoSDS: <anger> I just hope the service isn't as bad as the last time we came.\n user: <sosp><13><136><291><136><13><136><13><585><136><72><328><371><158><425><487><368><360><320><450><204><998><121><487><43><751><108><36><583><889><760><958><831><856><754><758><103><128><584><98><304><36><125><493><288><162><511><275><10><737><906><376><933><450><353><76><682><70><737><19><775><296><537><47><172><628><15><470><454><125><452><292><403><470><283><470><304><227><120><472><260><476><904><476><904><476><757><136><291><13><136><13><365><eosp> ", "plain_text": "<surprise> Said the American to Chinese. EmoSDS: <happiness> Right? It must have been a memorable conversation!", "residual_length": 143, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Surprise/0020_001451.npy", "dialogue_id": "244_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I finally got my hands on those rare spices we talked about!\nuser: <happiness> That's awesome! I can't wait to try that recipe.\nEmoSDS: <sadness> But I lost the original recipe I wanted to use.\n user: <sosp><13><235><136><369><13><235><13><136><511><347><425><877><125><358><760><958><523><795><108><47><477><350><583><125><760><557><368><918><350><304><283><933><450><584><526><371><158><136><616><511><958><831><47><477><628><304><450><564><511><98><661><98><292><232><283><643><128><91><162><511><680><886><672><757><136><592><13><369><136><13><136><291><13><365><eosp> ", "plain_text": "<surprise> The nine the eggs, I keep. EmoSDS: <surprise> Wait, nine? That's a lot to keep! What's the plan with all of them?", "residual_length": 128, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Surprise/0017_001401.npy", "dialogue_id": "3_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I just saw them pass by the park.\nuser: <happiness> That's great! It must have been exciting to watch.\nEmoSDS: <neutral> Yeah, it was pretty normal for the area.\n user: <sosp><13><235><13><235><13><136><511><347><487><304><109><104><758><450><779><20><231><173><36><470><454><493><879><524><313><66><487><368><820><47><579><400><371><899><158><425><180><159><213><603><944><517><751><360><304><232><580><128><162><584><672><871><311><375><790><213><890><43><432><918><360><370><203><128><511><680><886><311><757><136><13><235><13><365><eosp> ", "plain_text": "<surprise> They were going fast, with a light clip. EmoSDS: <surprise> Wow, really? I didn't think they could move that quickly!", "residual_length": 126, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Surprise/0017_001565.npy", "dialogue_id": "802_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> How was your day at work today?\nuser: <neutral> It was pretty standard, nothing out of the ordinary.\nEmoSDS: <happiness> That sounds good! I'm glad you had a smooth day.\n user: <sosp><13><709><291><709><544><136><757><136><13><235><136><171><889><286><889><760><523><108><370><493><930><70><737><425><159><320><128><328><259><899><861><301><57><173><831><47><360><320><583><125><493><72><328><904><371><862><144><162><171><889><760><368><47><831><438><568><62><524><347><441><958><47><261><62><450><128><511><618><450><204><91><162><511><686><487><43><368><751><320><260><259><158><425><36><583><125><760><360><918><360><557><136><13><291><13><136><13><365><eosp> ", "plain_text": "<surprise> Mum shuts one's mouth up, doesn't it. EmoSDS: <happiness> Really? I wasn't expecting that! What happened?", "residual_length": 150, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Surprise/0015_001658.npy", "dialogue_id": "1258_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I don’t know, things just seem to be getting harder lately.\nuser: <sadness> I can see that it’s affecting you a lot.\nEmoSDS: <anger> It’s just so frustrating that I can’t catch a break.\n user: <sosp><13><79><962><79><369><136><369><13><291><136><837><311><112><919><983><213><890><43><120><320><472><260><259><862><144><162><680><338><159><103><125><85><104><295><91><162><680><338><98><283><304><522><442><304><470><454><493><557><616><489><240><523><173><62><879><524><347><487><360><545><333><311><831><758><320><128><162><328><371><223><268><99><686><43><831><47><370><879><524><290><144><275><10><309><292><403><304><227><43><890><213><20><983><20><655><701><311><757><136><13><136><13><291><13><365><eosp> ", "plain_text": "<surprise> Who is been repeating all that hard stuff to you? EmoSDS: <surprise> Wait, you think someone is actually saying that? That’s unexpected!", "residual_length": 170, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Surprise/0015_001432.npy", "dialogue_id": "152_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I saw Rabbit and Dog playing together earlier.\nuser: <happiness> That's great! They really seem to enjoy each other's company.\nEmoSDS: <sadness> But, I feel like sometimes Rabbit gets a bit anxious around Dog.\n user: <sosp><544><83><709><291><709><544><13><291><13><136><204><998><104><866><368><47><62><128><680><338><304><113><128><574><162><98><292><403><304><933><857><91><162><511><686><43><958><831><438><62><128><584><557><958><311><333><311><907><856><866><304><292><304><350><470><454><300><368><47><370><62><128><511><290><615><371><899><790><104><295><923><159><995><998><151><125><760><172><47><477><360><320><545><450><162><353><275><682><70><476><396><136><13><291><13><365><eosp> ", "plain_text": "<surprise> Rabbit gave dog a hurrying up sort of nudge. EmoSDS: <happiness> Wow, that sounds unexpected! I didn’t think Rabbit would take charge like that!", "residual_length": 155, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Surprise/0015_001450.npy", "dialogue_id": "243_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I was just thinking about our project.\nuser: <happiness> Oh really? I hope it's something exciting!\nEmoSDS: <neutral> Yeah, I mean, it's definitely something we can work on.\n user: <sosp><79><291><592><79><422><136><13><136><235><511><876><918><320><583><493><512><99><977><997><861><301><173><103><41><128><574><162><511><99><425><159><320><966><259><158><425><442><953><450><889><673><283><350><304><454><125><760><130><701><757><592><757><13><235><13><365><eosp> ", "plain_text": "<surprise> And what does it mean? EmoSDS: <surprise> I didn’t expect you to ask that! It means we need to dig deeper.", "residual_length": 103, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Surprise/0015_001743.npy", "dialogue_id": "1671_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Can you remind me where we left off last time?\nuser: <happiness> We were just getting to the good part!\nEmoSDS: <sadness> I wish we had more time to explore it.\n user: <sosp><13><136><291><136><876><274><820><47><360><545><128><511><76><70><737><104><866><173><62><879><290><328><615><371><269><371><158><425><368><41><128><584><98><304><125><998><487><368><360><47><360><41><450><128><511><526><328><904><371><183><467><292><403><283><304><583><125><905><125><905><701><136><13><136><13><136><13><365><eosp> ", "plain_text": "<surprise> Act drop second act scene. EmoSDS: <happiness> Wow, I didn’t see that coming! Let's make it even better than before.", "residual_length": 120, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Surprise/0012_001510.npy", "dialogue_id": "538_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I couldn't quite understand what he was thinking.\nuser: <anger> It was infuriating to watch him act that way.\nEmoSDS: <sadness> I just felt so helpless in that moment.\n user: <sosp><13><709><544><83><291><709><544><196><333><309><304><472><260><259><171><354><97><715><517><523><438><831><856><758><587><128><353><275><682><899><171><889><760><368><47><438><568><62><879><524><347><128><162><511><584><871><921><104><8><64><213><45><349><347><121><159><320><450><288><512><275><10><977><919><20><57><890><103><320><111><615><371><268><171><125><292><232><283><432><43><856><370><817><757><136><13><291><13><365><eosp> ", "plain_text": "<surprise> His large mouth curled into a sneer. EmoSDS: <surprise> Wow, I didn't see that coming; it took me off guard!", "residual_length": 136, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Surprise/0015_001564.npy", "dialogue_id": "1725_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I've been listening to a lot of music lately.\nuser: <happiness> That's great! Music really lifts the mood!\nEmoSDS: <surprise> Oh, really? What kind of music have you found interesting?\n user: <sosp><13><136><13><291><13><291><13><136><162><347><121><425><120><125><760><432><927><350><304><583><889><173><159><180><998><121><159><111><615><428><158><296><64><831><795><523><108><583><125><159><472><260><615><899><144><584><871><375><64><110><509><402><45><995><121><131><333><152><820><47><545><923><368><41><128><162><526><615><269><371><476><136><757><136><13><136><291><13><291><13><365><eosp> ", "plain_text": "<surprise> The name of the song is called haddocks. EmoSDS: <surprise> Wait, what? Haddocks? That's an unusual title!", "residual_length": 150, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Surprise/0013_001718.npy", "dialogue_id": "1552_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I went to the store yesterday.\nuser: <happiness> That's great! Did you find everything you needed?\nEmoSDS: <sadness> Not really, they were out of a few things.\n user: <sosp><13><709><83><291><709><544><13><291><13><136><275><10><425><159><376><204><998><121><958><831><47><477><628><304><933><564><128><162><275><371><10><196><906><376><919><20><91><162><511><680><921><112><231><370><758><450><128><162><76><70><737><19><296><831><795><438><47><277><62><128><162><680><290><615><371><615><22><476><136><13><291><13><291><13><365><eosp> ", "plain_text": "<surprise> To buy two pork chops. EmoSDS: <happiness> Oh wow, really? That's an interesting choice for dinner!", "residual_length": 128, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Surprise/0012_001493.npy", "dialogue_id": "455_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <sadness> I can't believe we lost him so suddenly.\nuser: <neutral> It feels surreal, doesn't it?\nEmoSDS: <happiness> At least we can cherish all those good memories together.\n user: <sosp><13><79><962><291><962><592><291><13><291><136><116><680><133><375><112><231><237><295><848><450><128><162><511><275><10><672><311><296><795><108><583><889><125><760><487><172><47><261><213><890><120><227><472><260><268><144><162><511><99><467><487><432><368><918><1><120><320><450><128><162><511><618><425><159><701><757><592><13><291><13><365><eosp> ", "plain_text": "<surprise> Poor Tom now is dead! EmoSDS: <neutral> Wow, I really didn't see that coming. What happened?", "residual_length": 146, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Surprise/0020_001415.npy", "dialogue_id": "74_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I'm really glad we made it this far together!\nuser: <neutral> Yeah, but the challenges ahead are tough.\nEmoSDS: <sadness> I just feel like we might not be able to overcome them.\n user: <sosp><13><136><13><291><592><79><592><136><13><136><511><708><10><309><918><360><304><663><128><162><584><672><597><296><918><47><42><261><856><754><295><866><364><159><120><131><450><353><275><10><196><396><136><311><524><311><296><831><523><110><213><898><120><472><260><158><425><159><583><125><889><354><517><958><795><438><178><400><260><615><371><144><275><196><467><68><700><304><432><368><277><128><136><13><136><13><291><13><136><13><365><eosp> ", "plain_text": "<surprise> Take courage all isn't lost yet. EmoSDS: <happiness> You're right! We still have a chance to turn things around!", "residual_length": 142, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Surprise/0011_001444.npy", "dialogue_id": "209_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I saw them talking at the event last week.\nuser: <happiness> Oh really? That sounds like they're getting closer!\nEmoSDS: <sadness> Yeah, but I'm not sure if it's for the right reasons.\n user: <sosp><196><79><748><79><592><837><982><10><100><292><232><98><292><933><450><524><290><371><158><487><432><350><470><454><760><432><368><62><889><19><333><311><856><754><295><561><203><103><111><328><615><371><904><371><476><155><136><114><13><235><13><365><eosp> ", "plain_text": "<surprise> She keeps saying I'm hers. EmoSDS: <happiness> That's really sweet! Sounds like she really cares about you.", "residual_length": 109, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0016/Surprise/0016_001730.npy", "dialogue_id": "1609_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I can't believe you chose that movie again.\nuser: <happiness> I know, right? It's just so entertaining!\nEmoSDS: <sadness> But we watched it like three times already.\n user: <sosp><13><136><79><291><79><422><136><622><309><304><472><260><204><998><354><517><958><831><438><831><598><856><758><587><450><632><864><862><171><889><958><47><831><438><568><320><879><524><899><128><162><511><871><921><104><754><213><45><91><99><121><425><557><552><36><583><125><288><99><10><906><376><167><890><131><111><615><371><268><171><125><760><470><927><432><42><856><295><31><701><757><136><13><381><13><365><eosp> ", "plain_text": "<surprise> His large mouth curled into a sneer. EmoSDS: <surprise> Wait, did he really just do that? That's unexpected!", "residual_length": 152, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Surprise/0020_001564.npy", "dialogue_id": "801_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I think we should discuss our options before making a decision.\nuser: <happiness> I really appreciate everyone's input on this matter!\nEmoSDS: <sadness> It's hard for me to see us agree on things lately.\n user: <sosp><79><291><79><592><291><136><171><125><889><125><889><760><442><472><111><615><223><268><144><275><737><104><561><295><848><930><982><70><737><304><42><856><644><889><760><432><927><918><172><360><320><583><125><760><557><136><291><136><489><274><47><1><628><985><889><919><376><20><879><524><637><921><104><480><754><295><848><120><472><450><204><91><162><99><10><467><227><159><985><995><524><347><82><227><304><472><930><982><70><737><425><918><360><320><125><905><136><13><291><13><291><13><136><365><eosp> ", "plain_text": "<surprise> Mister share man, I move for a division. EmoSDS: <neutral> Wow, I didn’t expect that! What’s got you so fired up about this?", "residual_length": 187, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Surprise/0013_001416.npy", "dialogue_id": "1708_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I'm just thinking about what to do next.\nuser: <happiness> You should totally join us for the game tonight!\nEmoSDS: <sadness> I don't know, I feel like I'm not really part of the group.\n user: <sosp><13><291><13><291><13><136><20><861><301><57><173><103><923><486><292><376><20><861><301><57><890><58><403><292><933><522><292><470><454><493><524><637><66><790><231><655><173><754><856><758><62><128><760><360><432><918><856><108><360><108><203><701><757><79><757><592><13><291><13><365><eosp> ", "plain_text": "<surprise> What are you waiting for? man. EmoSDS: <surprise> Oh wow, I didn't expect you to say that! I guess I should hurry up, huh?", "residual_length": 121, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Surprise/0017_001747.npy", "dialogue_id": "1691_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I thought we lost him back there.\nuser: <happiness> I can't believe he found his way back!\nEmoSDS: <sadness> I was so worried he wouldn't make it.\n user: <sosp><13><136><291><13><136><291><13><136><13><136><622><661><292><376><861><301><57><890><103><472><111><615><219><615><269><371><268><144><162><99><467><43><213><603><213><43><320><583><125><121><751><316><985><879><226><524><212><66><790><231><237><480><754><856><42><320><111><615><371><268><144><162><275><665><10><781><757><136><757><136><166><136><13><291><13><365><eosp> ", "plain_text": "<surprise> He was still in the forest! EmoSDS: <surprise> Really? I didn't expect that at all!", "residual_length": 122, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Surprise/0013_001453.npy", "dialogue_id": "256_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <anger> You think you can just walk away from this mess?\nuser: <sadness> I didn't mean for things to go this way.\nEmoSDS: <neutral> Well, now we need to figure out what to do next.\n user: <sosp><544><13><291><13><136><13><136><291><136><622><196><906><486><104><295><128><162><584><871><921><104><919><445><213><45><450><162><275><10><467><304><700><403><58><930><982><70><737><43><368><438><62><74><128><511><584><672><375><311><296><831><28><579><400><615><223><268><144><275><10><196><304><43><295><180><715><213><603><880><517><441><958><47><477><918><304><796><879><524><343><524><887><343><476><757><136><13><136><13><136><13><291><13><136><13><365><eosp> ", "plain_text": "<surprise> You cruelty shall cost your life ! EmoSDS: <anger> You know you can’t just threaten me like that, right?", "residual_length": 153, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Surprise/0014_001617.npy", "dialogue_id": "1057_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I can't believe the semester is almost over.\nuser: <happiness> I know, right? It's been such a great time!\nEmoSDS: <sadness> But it also means saying goodbye to everyone.\n user: <sosp><13><235><13><136><748><136><876><47><41><128><511><347><283><292><300><557><432><327><432><927><130><583><125><522><487><159><985><879><524><66><790><983><231><655><237><754><856><31><757><592><13><235><13><365><eosp> ", "plain_text": "<surprise> At the end of four. EmoSDS: <surprise> Wait, are you serious? I thought we had more time!", "residual_length": 106, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Surprise/0017_001419.npy", "dialogue_id": "89_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> So, what happened next?\nuser: <sadness> I just felt like everything was going wrong that day.\nEmoSDS: <happiness> But at least we got through it together, right?\n user: <sosp><13><136><13><79><291><79><422><876><136><727><105><432><360><320><493><288><328><615><982><10><183><292><933><162><511><584><871><375><311><831><299><521><128><162><557><360><320><128><574><511><347><121><159><985><91><879><524><997><112><790><480><252><831><484><445><20><919><203><45><450><128><162><275><223><70><737><396><136><79><291><79><863><291><136><13><365><eosp> ", "plain_text": "<surprise> And she caught at the brooch. EmoSDS: <surprise> Wow, I didn't see that coming! What did you do next?", "residual_length": 121, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Surprise/0019_001724.npy", "dialogue_id": "1583_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I saw him smiling earlier today.\nuser: <happiness> That's great! I love seeing him happy.\nEmoSDS: <neutral> Yeah, it's like he's a different person sometimes.\n user: <sosp><13><235><291><13><136><13><291><166><136><311><831><856><754><104><486><304><933><450><275><615><371><269><371><158><425><227><432><442><320><111><615><371><571><144><571><158><425><442><432><36><125><72><328><371><862><171><125><889><760><487><432><334><232><319><584><526><371><158><425><227><159><889><493><288><162><680><936><524><112><20><983><603><354><517><441><368><918><360><320><111><260><966><158><425><432><382><432><15><545><128><162><136><162><136><13><291><79><365><eosp> ", "plain_text": "<surprise> Her existence makes him pleasant. EmoSDS: <surprise> Really? I didn't know that affected him so much!", "residual_length": 161, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Surprise/0019_001625.npy", "dialogue_id": "1097_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Hey, I just wanted to drop by and ask about the meeting later.\nuser: <sadness> I really wish I could attend, but it looks like I'm not allowed in.\nEmoSDS: <anger> That's ridiculous! You should be able to participate!\n user: <sosp><13><79><291><79><291><79><592><136><592><136><876><125><728><125><760><43><64><231><566><231><366><557><918><432><304><933><879><998><171><125><889><125><889><49><338><304><522><442><125><493><288><328><371><158><425><304><113><128><162><526><371><158><487><368><261><62><879><128><162><99><686><43><64><213><197><583><125><493><288><162><511><680><133><375><311><523><831><856><758><360><587><522><304><292><933><204><91><162><680><338><227><472><111><260><371><171><601><125><760><487><432><227><472><111><615><371><904><476><136><13><136><13><863><335><291><13><863><291><13><136><13><365><eosp> ", "plain_text": "<surprise> No admittance except on party business. EmoSDS: <happiness> Oh wow, I didn't expect that! We just need to find a way to change that, right?", "residual_length": 199, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Surprise/0019_001672.npy", "dialogue_id": "1327_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <sadness> I really feel like you're not here with me anymore.\nuser: <neutral> I don't know what to say to that.\nEmoSDS: <happiness> It's just so nice to remember the fun times we had!\n user: <sosp><136><79><291><79><592><136><876><274><360><628><985><204><91><162><511><680><919><213><898><442><304><454><493><288><899><524><116><171><790><173><958><172><47><1><320><111><260><615><371><899><333><311><296><173><568><831><856><31><827><701><162><275><618><757><136><13><365><eosp> ", "plain_text": "<surprise> I blinked my eyes hard. EmoSDS: <surprise> Whoa, what just caught your attention?", "residual_length": 100, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Surprise/0014_001535.npy", "dialogue_id": "659_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I think we need someone reliable to fill this position.\nuser: <happiness> I promise to work hard to prove myself.\nEmoSDS: <neutral> That's good to hear, let's move on to the next steps.\n user: <sosp><13><235><709><544><13><592><235><79><899><136><162><680><936><158><309><283><393><111><371><333><311><775><831><477><1><42><856><644><707><889><338><283><300><557><47><261><62><879><162><99><737><104><486><700><292><304><376><919><370><20><91><757><136><962><136><592><291><592><365><eosp> ", "plain_text": "<surprise> Please hire me after you. EmoSDS: <happiness> Wow, I'm surprised to hear that! I’ll do my best to put in a good word for you.", "residual_length": 105, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Surprise/0018_001593.npy", "dialogue_id": "938_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <sadness> I just don't know how I ended up here.\nuser: <happiness> It's okay, we can figure this out together!\nEmoSDS: <anger> You have no idea what I've been through!\n user: <sosp><13><79><291><79><592><136><13><291><136><489><274><958><47><477><1><304><545><450><204><511><680><173><203><213><142><898><304><292><403><292><933><879><995><879><338><292><376><20><213><64><438><856><758><608><128><13><291><13><171><204><861><301><231><173><523><108><360><583><760><836><203><879><524><879><180><998><347><121><487><43><108><36><125><384><701><13><291><13><365><eosp> ", "plain_text": "<surprise> I believe you are one of them! EmoSDS: <happiness> Wait, really? That's unexpected but kinda cool!", "residual_length": 133, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Surprise/0012_001662.npy", "dialogue_id": "1279_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> What do you think about the party last night?\nuser: <happiness> It was such a fun time, I can't believe we danced so much!\nEmoSDS: <sadness> Yeah, but it felt a bit empty when everyone started leaving.\n user: <sosp><13><291><13><136><13><136><489><274><47><640><41><128><574><162><511><275><223><10><899><311><112><231><173><304><283><232><933><450><204><997><57><890><103><287><524><347><899><171><151><790><958><47><1><320><998><715><354><142><898><360><918><360><41><584><128><511><584><672><104><856><184><31><128><136><592><291><79><136><79><592><365><eosp> ", "plain_text": "<surprise> I toy with my liqueur. EmoSDS: <happiness> Wow, you’re really getting into it, aren't you? What's the vibe?", "residual_length": 120, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Surprise/0019_001567.npy", "dialogue_id": "816_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I think it's really cool that you're into racing.\nuser: <anger> But it feels like no one takes it seriously!\nEmoSDS: <happiness> I believe in you, you're doing great things out there!\n user: <sosp><13><291><13><136><13><291><136><171><301><811><301><231><173><751><103><923><43><159><889><760><958><795><47><1><382><58><557><958><795><108><1><985><889><760><43><295><480><699><997><699><997><85><866><382><304><232><304><472><111><615><269><371><158><425><561><856><295><848><930><111><615><269><371><158><425><751><108><583><125><197><751><985><995><879><91><162><584><672><43><751><795><404><28><47><28><545><998><522><618><196><724><757><136><13><136><291><13><136><13><365><eosp> ", "plain_text": "<surprise> What am I, I'm a racer, son of god. EmoSDS: <happiness> Wow, that’s an amazing way to see yourself!", "residual_length": 184, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Surprise/0013_001607.npy", "dialogue_id": "1009_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I see you’re frustrated about the mistake.\nuser: <sadness> I just don't understand why this keeps happening.\nEmoSDS: <happiness> Let’s try to work on this together for next time.\n user: <sosp><13><291><13><291><13><291><136><274><47><568><213><518><320><111><615><371><158><487><368><1><376><20><861><301><57><173><108><583><493><879><226><524><212><243><104><295><113><450><204><998><300><368><918><360><545><522><120><320><522><159><113><450><204><998><300><432><172><360><108><583><125><701><757><136><13><291><13><365><eosp> ", "plain_text": "<surprise> Alice I won't forget it again. EmoSDS: <happiness> Wow, I didn't realize it meant that much to you!", "residual_length": 127, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Surprise/0020_001682.npy", "dialogue_id": "1379_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Have you ever thought about going swimming at the lake this weekend?\nuser: <happiness> That sounds like a great idea! I love spending time by the water.\nEmoSDS: <sadness> Yeah, but it's been a tough time for me lately.\n user: <sosp><13><709><291><709><136><311><136><13><616><13><136><274><19><360><640><933><450><162><76><682><10><737><425><360><320><949><371><268><144><275><371><158><425><472><111><615><269><371><10><183><467><376><933><450><204><328><769><615><428><363><899><921><919><173><103><583><889><125><452><292><304><43><104><20><861><301><57><380><432><1><15><300><918><368><360><320><260><259><158><487><47><360><62><347><360><42><856><320><930><260><223><268><144><99><783><425><227><43><213><78><701><136><13><291><13><136><13><365><eosp> ", "plain_text": "<surprise> I'd just as soon swim your way as others do. EmoSDS: <happiness> Wow, I didn't expect that! I guess you really want to join me!", "residual_length": 147, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Surprise/0015_001673.npy", "dialogue_id": "1335_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I'm really excited for Bob's new journey!\nuser: <neutral> Yeah, it should be a good change for him.\nEmoSDS: <sadness> I just hope he makes friends quickly.\n user: <sosp><13><592><13><291><13><136><235><13><162><511><270><958><831><743><404><438><404><370><62><128><204><584><121><43><213><445><890><103><472><260><615><268><144><275><10><977><20><890><103><125><358><125><673><292><906><376><472><111><615><371><899><144><162><584><779><20><983><231><173><213><370><701><757><701><136><13><291><13><592><13><365><eosp> ", "plain_text": "<surprise> Bob goes to a new school. EmoSDS: <happiness> I can't believe it! That's such a big step for him!", "residual_length": 124, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Surprise/0017_001714.npy", "dialogue_id": "1531_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> How's your day been so far?\nuser: <sadness> It's been pretty tough, to be honest.\nEmoSDS: <happiness> I'm sorry to hear that, but I'm sure it will get better.\n user: <sosp><13><136><369><235><369><13><136><13><666><369><136><666><13><235><666><136><489><274><831><795><743><477><918><304><159><583><889><997><480><866><831><108><583><760><197><831><62><524><171><889><958><1><15><41><879><524><343><524><66><338><292><283><643><128><162><13><136><666><136><557><701><136><13><291><13><365><eosp> ", "plain_text": "<surprise> I am run off my feet. EmoSDS: <neutral> Wow, that sounds exhausting! What’s been keeping you so busy?", "residual_length": 106, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Surprise/0017_001652.npy", "dialogue_id": "1229_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I think it would be a good idea to invest in your own.\nuser: <sadness> I just feel like I can't afford it right now.\nEmoSDS: <happiness> But think about how much it'll help you in the long run!\n user: <sosp><311><79><235><757><136><13><136><13><235><136><91><861><301><517><523><831><47><477><1><304><930><982><10><425><545><923><368><320><450><128><680><921><104><295><103><930><275><158><425><159><111><615><371><862><601><889><958><172><1><15><557><616><489><240><914><523><213><983><20><808><125><760><370><701><757><136><13><235><13><365><eosp> ", "plain_text": "<surprise> Why should I purchase my own? EmoSDS: <happiness> Because it opens up so many new opportunities for you!", "residual_length": 108, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0016/Surprise/0016_001742.npy", "dialogue_id": "1668_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Hey, how was your day today?\nuser: <happiness> It was actually really great! I finally finished that project I've been working on.\nEmoSDS: <neutral> That's awesome! So, any plans for the evening?\n user: <sosp><13><235><13><235><13><235><13><136><489><274><958><831><537><172><360><108><583><493><779><121><64><73><108><432><470><304><493><288><275><10><159><450><204><162><499><487><368><47><820><710><41><128><584><871><311><523><89><999><370><905><370><701><905><757><136><114><13><365><eosp> ", "plain_text": "<surprise> I am going to back home. EmoSDS: <happiness> Wow, that's a big surprise! Did something exciting happen?", "residual_length": 104, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Surprise/0017_001746.npy", "dialogue_id": "1684_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I was just thinking about how common it used to be.\nuser: <happiness> Well, that’s great to hear! It's nice not to have that fear.\nEmoSDS: <sadness> But so many kids still suffer from it, you know?\n user: <sosp><79><291><79><136><79><592><291><136><876><136><876><432><36><583><125><493><522><557><616><162><511><274><831><47><360><320><125><760><432><261><62><56><104><856><41><333><410><918><47><360><587><522><425><43><985><861><20><91><511><680><338><304><718><454><288><584><672><775><296><831><438><277><88><62><879><524><343><476><155><136><13><291><136><837><136><171><301><517><173><795><28><795><47><1><58><403><643><196><757><592><13><291><13><136><13><136><13><136><13><136><365><eosp> ", "plain_text": "<surprise> And I never had a whooping cough why. EmoSDS: <surprise> Wait, really? That's actually impressive! How did that happen?", "residual_length": 165, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Surprise/0014_001481.npy", "dialogue_id": "394_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Have you thought about what you want to do next?\nuser: <happiness> Yeah, I really want to try something new!\nEmoSDS: <surprise> Oh, that sounds exciting! What kind of things are you considering?\n user: <sosp><13><235><369><235><13><235><369><13><136><274><640><41><524><196><309><304><383><454><493><288><584><98><309><304><103><923><43><213><36><470><454><493><288><584><672><311><775><856><754><295><856><120><320><472><682><862><171><125><760><283><643><79><757><136><13><235><13><365><eosp> ", "plain_text": "<surprise> I think it'll encourage me. EmoSDS: <happiness> That's great to hear! It's always nice to feel motivated.", "residual_length": 107, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Surprise/0017_001437.npy", "dialogue_id": "176_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <sadness> I can't believe how unfair this situation is.\nuser: <neutral> We should at least figure out a solution.\nEmoSDS: <happiness> I think we can still make it work if we try!\n user: <sosp><13><709><291><709><544><13><235><13><136><13><162><511><105><304><933><522><557><162><136><162><511><105><304><472><966><158><425><360><36><125><493><91><162><511><680><19><333><309><41><128><162><574><162><511><686><487><368><47><545><923><197><438><523><110><523><370><431><987><757><136><13><365><eosp> ", "plain_text": "<surprise> it isn't picked at all. EmoSDS: <happiness> Wow, really? I thought it would be selected!", "residual_length": 106, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Surprise/0015_001616.npy", "dialogue_id": "1056_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <sadness> I really miss the animals in the forest; they always made me feel at home.\nuser: <happiness> Remember how we used to watch them together? It was so much fun!\nEmoSDS: <anger> It's frustrating that people don't care about their habitats anymore.\n user: <sosp><13><291><13><136><13><136><162><347><292><232><557><136><489><274><831><743><438><110><983><231><983><213><879><524><936><354><142><898><890><376><20><890><103><36><583><760><487><368><47><261><62><91><574><162><511><680><790><64><445><890><43><103><320><930><982><70><269><70><476><781><909><79><291><592><365><eosp> ", "plain_text": "<surprise> The owl flew into a bush. EmoSDS: <surprise> Wow, really? I didn't expect that; I hope it’s okay!", "residual_length": 135, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Surprise/0019_001519.npy", "dialogue_id": "581_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <sadness> I can't believe we lost all that candy at the party.\nuser: <anger> I know, right? It was such a waste!\nEmoSDS: <happiness> But at least we had fun while it lasted!\n user: <sosp><13><79><291><79><592><13><291><136><240><523><370><89><830><889><760><173><958><360><304><933><204><288><116><487><43><173><108><583><125><493><162><511><708><10><196><309><304><120><545><450><162><290><615><371><223><144><162><511><584><487><958><795><108><583><125><128><162><557><274><918><360><320><260><259><223><899><20><861><301><57><173><380><918><108><523><213><78><701><136><544><13><291><592><136><592><365><eosp> ", "plain_text": "<surprise> All my gum tips gone as well. EmoSDS: <surprise> Wait, really? I thought I had some extra in my bag!", "residual_length": 148, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Surprise/0012_001479.npy", "dialogue_id": "385_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I heard he's leaving the team next week.\nuser: <sadness> That's really disappointing; he was a great asset.\nEmoSDS: <happiness> At least we have some time left to spend with him.\n user: <sosp><13><79><235><79><958><136><235><136><489><274><47><477><1><918><350><432><583><889><125><668><45><354><517><751><213><103><111><949><524><144><275><158><472><111><615><371><183><292><304><877><889><125><493><998><121><43><751><173><370><701><91><13><136><13><235><13><365><eosp> ", "plain_text": "<surprise> I am loath to see him go. EmoSDS: <anger> It just doesn't make any sense; why would he leave now?", "residual_length": 94, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0016/Surprise/0016_001703.npy", "dialogue_id": "1477_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I was just thinking about how music really brings people together.\nuser: <happiness> Absolutely! It creates such a lively atmosphere.\nEmoSDS: <neutral> Do you have a favorite song that always lifts your spirits?\n user: <sosp><13><592><235><592><235><136><79><592><136><837><371><158><487><360><103><930><353><76><982><223><268><144><162><275><10><196><906><376><213><370><213><36><583><125><72><259><121><425><43><856><103><450><353><76><682><783><919><231><173><103><927><304><933><450><99><10><899><997><890><103><450><162><511><686><467><300><918><47><360><320><128><328><571><371><183><304><718><454><493><584><949><524><887><66><487><368><47><918><350><283><643><196><79><333><757><79><136><79><757><592><136><235><13><365><eosp> ", "plain_text": "<surprise> Such tunes are joy to a dancing fay. EmoSDS: <happiness> Wow, that's a unique perspective! It really captures the magic of music!", "residual_length": 150, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Surprise/0018_001559.npy", "dialogue_id": "777_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I'm fine, just a bit tired from school.\nuser: <sadness> I worry about how much pressure you feel from your studies.\nEmoSDS: <happiness> I appreciate your concern, but I actually enjoy learning!\n user: <sosp><13><136><79><136><79><592><136><333><410><296><47><261><568><213><445><231><754><866><295><486><304><700><232><206><232><292><304><43><961><376><919><20><890><464><879><128><116><162><99><467><292><304><376><295><848><930><353><76><682><70><737><870><831><47><1><261><568><213><45><128><162><275><618><757><136><13><291><13><365><eosp> ", "plain_text": "<surprise> How are you, dear child? EmoSDS: <neutral> I’m okay, just trying to keep up with everything.", "residual_length": 114, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Surprise/0014_001472.npy", "dialogue_id": "349_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> What do you think about those old sayings?\nuser: <happiness> I always found them amusing, like little nuggets of wisdom.\nEmoSDS: <sadness> But sometimes they don't really apply to our lives, do they?\n user: <sosp><13><291><13><136><13><291><13><136><171><998><522><467><292><304><393><472><260><899><204><861><301><57><231><754><561><848><472><260><862><162><680><790><958><488><311><296><795><47><1><927><304><583><125><493><760><487><304><15><58><403><304><42><295><848><472><260><371><158><425><227><472><260><162><601><171><125><760><958><795><108><583><125><493><328><371><158><425><918><47><108><583><125><72><162><328><769><904><476><757><136><13><291><13><365><eosp> ", "plain_text": "<surprise> These words behind the ears is nonsense. EmoSDS: <surprise> Really? I thought there might be some truth to them!", "residual_length": 171, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Surprise/0020_001679.npy", "dialogue_id": "1362_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I'm so proud of how much you've accomplished lately!\nuser: <sadness> Yeah, but it just feels like too much sometimes.\nEmoSDS: <neutral> I get that, balancing everything can be tough.\n user: <sosp><13><136><369><235><369><13><136><13><666><369><136><666><13><235><666><136><489><274><831><795><743><477><918><304><159><583><889><997><480><866><831><108><583><760><197><831><62><524><171><889><958><1><15><41><879><524><343><524><66><338><292><283><643><128><162><13><136><666><136><557><701><136><13><291><13><365><eosp> ", "plain_text": "<surprise> I am run off my feet. EmoSDS: <surprise> Oh wow, are you really that busy? I didn’t realize it was so hectic for you!", "residual_length": 106, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Surprise/0017_001652.npy", "dialogue_id": "1231_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I love how you always seem prepared for anything!\nuser: <neutral> Well, I just believe in being ready.\nEmoSDS: <sadness> Sometimes, I wish I could be more like that.\n user: <sosp><13><235><13><369><235><369><13><136><13><876><274><360><583><889><760><958><751><360><320><111><371><511><10><19><333><918><47><261><62><995><879><162><275><10><737><906><376><103><587><103><159><879><524><66><487><368><579><41><353><982><70><737><171><125><493><288><98><196><333><309><432><42><856><295><486><304><283><643><196><724><136><13><136><365><eosp> ", "plain_text": "<surprise> I must have two to fetch and carry. EmoSDS: <surprise> Wow, I didn't think you had that much planned!", "residual_length": 128, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Surprise/0017_001656.npy", "dialogue_id": "1250_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I heard that story is about friendship.\nuser: <happiness> Yeah, the boy learns a lot from the monkey.\nEmoSDS: <sadness> But I think it also has some sad parts, like when they have to part ways.\n user: <sosp><79><136><79><136><79><962><79><962><592><381><136><837><371><223><268><144><99><737><104><231><866><120><304><933><564><275><10><899><921><66><790><173><103><583><760><304><470><304><125><760><172><47><172><47><172><432><350><927><58><454><125><701><136><757><136><876><274><958><62><204><680><790><231><173><306><927><583><760><975><644><583><889><173><108><203><320><493><288><162><511><584><98><292><304><58><403><58><643><266><136><13><136><291><13><365><eosp> ", "plain_text": "<surprise> Story twenty nine a boy and a monkey. EmoSDS: <surprise> Oh really? I didn't know that was even a story. Tell me more about it!", "residual_length": 148, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Surprise/0014_001443.npy", "dialogue_id": "208_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I'm really glad to hear that he finally got his act together!\nuser: <neutral> Yeah, but he still has a long way to go.\nEmoSDS: <sadness> I just wish he would realize how much he needs to change.\n user: <sosp><13><136><592><748><592><79><422><592><136><622><292><304><43><645><557><616><240><233><523><213><173><103><587><171><493><889><760><442><472><111><371><904><268><275><737><104><295><159><180><861><995><236><603><517><523><438><579><400><371><904><371><158><442><360><130><701><618><136><79><748><79><47><876><136><876><274><360><640><450><128><162><511><98><309><333><918><360><277><545><128><511><708><10><333><47><958><108><304><292><304><376><20><311><333><820><47><831><743><438><568><213><983><402><78><701><757><427><13><235><13><136><13><235><13><365><eosp> ", "plain_text": "<surprise> He owed mister Lawson, I can't tell you how. EmoSDS: <happiness> Wow, I didn't know it was that serious! What happened next?", "residual_length": 184, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Surprise/0018_001709.npy", "dialogue_id": "1510_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe we finally made it to the conference!\nuser: <neutral> Yeah, it's nice to be here but I didn’t expect so many people.\nEmoSDS: <surprise> Did you see that giant poster of the ancient ruins?\n user: <sosp><13><79><136><79><748><79><311><136><235><136><511><958><173><751><62><879><524><313><425><43><42><856><103><587><450><275><682><425><43><831><438><62><128><162><779><921><19><652><831><47><41><128><584><104><856><295><103><450><275><977><104><173><856><62><879><524><354><517><441><360><350><470><454><493><20><57><890><103><450><353><682><899><171><889><760><890><159><111><615><371><862><162><511><338><292><283><643><196><136><666><136><666><136><748><136><365><eosp> ", "plain_text": "<surprise> A fair jaw cracker dwarf language must be! EmoSDS: <happiness> Right? It's fascinating how diverse cultures can be!", "residual_length": 143, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Surprise/0018_001482.npy", "dialogue_id": "396_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I just don't see what the big deal is.\nuser: <sadness> It hurt him, and that's what matters.\nEmoSDS: <happiness> But I'm sure it was an accident, right?\n user: <sosp><511><79><196><136><162><622><98><292><376><103><949><982><70><10><425><159><450><125><760><368><47><261><62><879><128><574><162><511><680><19><918><41><128><162><275><10><309><159><985><889><125><861><57><103><287><450><162><584><196><300><43><173><370><311><112><231><603><523><831><856><31><36><125><130><701><757><136><13><235><13><235><13><365><eosp> ", "plain_text": "<surprise> You shouldn't have pricked him with your horn. EmoSDS: <neutral> Really? I didn't expect that to happen at all.", "residual_length": 129, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Surprise/0015_001675.npy", "dialogue_id": "1345_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I really think things are going to turn around for him!\nuser: <neutral> Yeah, but hope can sometimes lead to disappointment.\nEmoSDS: <anger> It's so frustrating when people don't see the reality!\n user: <sosp><13><136><13><136><13><136><13><291><13><622><196><227><472><260><615><899><311><296><64><213><762><861><91><680><301><57><486><890><43><213><45><353><76><70><737><309><304><700><304><522><304><432><159><985><879><701><288><136><13><291><136><13><365><eosp> ", "plain_text": "<sadness> His hope will cheat him. EmoSDS: <neutral> I guess you're right, but we can still support him through tough times.", "residual_length": 92, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Sad/0011_001349.npy", "dialogue_id": "1740_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Have you heard that story about the witch?\nuser: <happiness> Yeah, I love how it always keeps you on your toes!\nEmoSDS: <sadness> But it also makes me think about how people can be misunderstood.\n user: <sosp><13><83><381><709><136><13><381><13><136><998><121><487><43><360><640><333><410><918><47><1><304><933><450><204><998><354><142><898><518><213><376><91><162><584><162><275><10><467><304><227><36><125><760><121><159><472><111><260><615><223><268><144><347><425><43><213><445><983><45><879><524><637><66><757><136><13><365><eosp> ", "plain_text": "<sadness> The hag looked in the stove. EmoSDS: <sadness> I guess she was searching for something lost, a bit like we all do sometimes.", "residual_length": 109, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Sad/0012_001126.npy", "dialogue_id": "369_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I loved how the colors blended together in the painting.\nuser: <neutral> Yeah, it gave such a peaceful vibe to the room.\nEmoSDS: <surprise> I didn't expect it to turn out this beautiful!\n user: <sosp><79><291><962><592><13><136><291><13><499><121><919><173><213><518><180><998><111><949><615><269><428><371><158><425><368><47><1><545><789><997><861><301><57><890><159><472><260><615><428><40><158><425><751><438><178><62><879><524><171><354><898><159><113><128><162><584><672><921><104><856><295><879><899><144><162><618><757><136><13><291><13><136><13><365><eosp> ", "plain_text": "<sadness> Both side were softly curved. EmoSDS: <neutral> I guess it has a certain beauty, even if it’s a bit melancholic.", "residual_length": 116, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Sad/0011_001290.npy", "dialogue_id": "1174_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I'm really glad to hear that things are going well for us!\nuser: <happiness> Yeah, I feel really lucky to have you by my side.\nEmoSDS: <neutral> It's nice to have some stability after everything we've been through.\n user: <sosp><13><136><13><291><13><291><13><381><136><112><57><890><304><643><333><410><918><47><360><62><879><204><511><680><159><125><493><789><879><524><66><790><958><795><743><689><1><130><454><125><493><701><333><47><261><62><56><879><56><104><295><103><125><493><288><899><921><977><112><20><57><890><58><403><643><136><13><291><13><136><13><365><eosp> ", "plain_text": "<sadness> We have been fine, haven't we? EmoSDS: <neutral> I guess so, but there’s still a lot we need to figure out.", "residual_length": 133, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Sad/0019_001234.npy", "dialogue_id": "897_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I was just thinking about how fast everything has changed lately.\nuser: <sadness> Yeah, it's like we can't go back to the way things used to be.\nEmoSDS: <happiness> But, you know, maybe some new things can be even better.\n user: <sosp><13><592><235><369><235><369><136><876><432><130><583><125><493><288><162><708><10><309><304><450><128><584><425><159><450><128><511><708><10><333><918><47><261><41><128><584><128><162><511><275><10><196><906><304><376><20><808><701><114><13><235><13><235><13><365><eosp> ", "plain_text": "<sadness> And tick a tack too. EmoSDS: <sadness> I know, it feels like time is slipping away from us.", "residual_length": 111, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Sad/0017_001136.npy", "dialogue_id": "417_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe Jack won the game last night!\nuser: <neutral> Yeah, it was quite a surprise.\nEmoSDS: <anger> But he was so annoying throughout the match!\n user: <sosp><13><136><235><136><592><79><592><235><13><622><292><393><111><615><371><158><425><487><368><360><545><450><204><162><99><10><425><472><450><162><275><682><783><487><368><47><743><47><579><41><128><162><511><584><672><757><136><757><136><511><347><487><159><103><450><353><76><70><737><19><856><831><47><438><47><261><923><295><997><480><295><754><184><31><701><757><136><114><13><235><13><235><13><365><eosp> ", "plain_text": "<sadness> He said to Jack, the chatterer. EmoSDS: <neutral> That's probably why everyone was frustrated with him.", "residual_length": 145, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Sad/0017_001196.npy", "dialogue_id": "712_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I wonder what he hopes to find in there.\nuser: <happiness> I think he’s looking for something really special from his childhood.\nEmoSDS: <neutral> That must be exciting for him.\n user: <sosp><13><863><136><291><13><235><136><13><622><98><196><292><304><111><949><615><371><269><371><269><371><158><425><43><856><103><930><353><76><70><839><144><162><511><275><10><196><524><347><362><104><486><376><103><998><347><121><159><985><204><91><680><270><958><831><438><88><311><128><136><162><511><584><526><371><904><615><371><476><757><136><291><13><365><eosp> ", "plain_text": "<sadness> He searched through the box. EmoSDS: <happiness> Even though it’s sad, maybe he’ll uncover something that brings back good memories.", "residual_length": 127, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0016/Sad/0016_001223.npy", "dialogue_id": "841_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I saw the cutest octopus at the aquarium yesterday!\nuser: <surprise> Really? Was it doing anything interesting?\nEmoSDS: <happiness> Yes! It was changing colors and playing with the divers!\n user: <sosp><13><79><291><592><291><592><13><136><347><10><196><292><304><43><831><370><74><899><128><162><511><10><196><316><91><162><511><680><311><790><64><751><990><159><320><111><615><904><371><158><333><19><775><47><477><1><131><472><111><615><371><158><464><557><136><105><309><304><327><350><283><232><643><196><275><10><196><757><917><790><213><441><751><368><432><1><382><304><58><206><128><162><584><526><904><371><476><757><136><365><eosp> ", "plain_text": "<sadness> The octopus has eight legs. EmoSDS: <neutral> That's true, but I feel kind of bad for them sometimes, they just seem so... alone.", "residual_length": 155, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0016/Sad/0016_001108.npy", "dialogue_id": "282_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe you actually went to that circus last weekend!\nuser: <neutral> Yeah, it was interesting.\nEmoSDS: <surprise> Interesting? I thought you'd have so much fun!\n user: <sosp><13><433><13><136><13><136><162><511><584><672><936><517><795><172><108><213><875><808><583><125><728><125><701><136><937><136><79><962><592><381><13><136><511><708><10><196><113><450><128><511><584><871><296><64><831><438><568><213><640><333><309><304><927><36><583><889><125><728><493><450><632><353><76><682><783><43><445><890><58><403><643><757><136><13><381><136><13><365><eosp> ", "plain_text": "<sadness> Clown, to call him joey. EmoSDS: <sadness> I know it's tough, but remember that some clowns are there to cheer us up.", "residual_length": 141, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Sad/0014_001162.npy", "dialogue_id": "545_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Have you thought about what you want to change in your life?\nuser: <sadness> I just feel like I've let everyone down.\nEmoSDS: <happiness> It's never too late to start making things right!\n user: <sosp><13><235><742><13><136><13><616><13><136><489><958><831><477><1><304><432><130><36><985><889><760><159><111><371><904><371><158><43><831><438><568><213><62><879><524><196><159><930><982><223><769><904><371><158><425><432><360><320><125><760><856><31><757><13><114><13><235><13><136><13><365><eosp> ", "plain_text": "<sadness> I am a selfish sinner. EmoSDS: <neutral> Acknowledging that is tough, but it sounds like you really want to grow from this.", "residual_length": 112, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Sad/0018_001271.npy", "dialogue_id": "1079_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I just found out I got the promotion!\nuser: <surprise> Wow, that's amazing! Congratulations!\nEmoSDS: <neutral> Thanks, I'm a bit anxious about the new responsibilities though.\n user: <sosp><13><291><13><291><13><291><13><136><511><680><790><64><751><213><156><889><760><523><89><889><958><108><62><889><125><760><958><795><47><277><156><128><328><769><615><428><10><158><425><159><295><848><450><522><425><159><36><125><197><159><985><204><680><487><368><60><751><213><445><20><376><91><162><136><13><162><511><275><10><672><476><757><136><291><136><13><136><13><136><13><291><13><136><13><365><eosp> ", "plain_text": "<sadness> But mom I'm not certain about. EmoSDS: <sadness> I understand, dear. It's hard when you're unsure about things.", "residual_length": 159, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Sad/0020_001387.npy", "dialogue_id": "1646_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I'm so curious about what you're up to!\nuser: <surprise> You really want to know? It's kind of mysterious!\nEmoSDS: <anger> Well, it better not be something outrageous!\n user: <sosp><13><291><13><136><13><235><136><105><309><304><472><111><328><371><862><91><162><511><778><133><311><523><831><856><758><295><128><76><275><618><311><775><43><751><159><985><879><524><66><171><889><760><958><172><432><1><327><304><111><615><371><10><196><292><403><232><319><162><511><584><871><104><856><31><557><136><421><136><13><162><99><618><10><155><136><291><13><365><eosp> ", "plain_text": "<sadness> It's part of my secret. EmoSDS: <neutral> If it’s really a secret, I get it... but it’s hard not to wonder.", "residual_length": 130, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0016/Sad/0016_001377.npy", "dialogue_id": "1597_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I just love it when the sun shines like this!\nuser: <neutral> Yeah, it really makes everything feel alive.\nEmoSDS: <neutral> I think I’ll take a walk later to enjoy it.\n user: <sosp><13><235><136><13><136><13><136><13><235><511><584><672><921><936><917><213><898><304><283><304><350><304><42><856><31><311><775><438><831><856><1><382><304><43><295><856><438><743><689><1><382><130><131><111><371><476><136><757><136><876><432><360><130><583><125><493><288><511><680><104><866><856><1><304><17><933><128><162><511><99><10><196><292><376><43><856><295><985><91><511><680><243><104><866><856><47><60><333><579><400><524><476><347><757><592><136><369><13><235><13><136><365><eosp> ", "plain_text": "<sadness> Clear are your eyes and bright your breath! EmoSDS: <sadness> Sometimes I wish I felt that way too...", "residual_length": 204, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0016/Sad/0016_001246.npy", "dialogue_id": "955_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> What time is the party tonight?\nuser: <happiness> It starts at seven, and I can't wait!\nEmoSDS: <surprise> Really? I thought it was later than that!\n user: <sosp><79><433><79><592><136><837><70><10><196><304><227><120><472><260><998><347><487><172><47><568><213><320><450><128><275><682><70><737><906><376><472><260><158><425><927><470><454><125><493><288><328><615><371><269><428><269><428><223><899><144><162><511><584><104><295><848><450><128><162><574><162><275><10><159><20><861><301><57><890><43><1><42><856><184><31><701><757><136><13><291><13><365><eosp> ", "plain_text": "<sadness> She is now choosing skirt to wear. EmoSDS: <neutral> I hope she finds something she likes although it seems tough.", "residual_length": 168, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Sad/0013_001075.npy", "dialogue_id": "119_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> Did you see that new park they opened? It's so beautiful!\nuser: <neutral> Yeah, I went there last weekend. It was nice to relax.\nEmoSDS: <surprise> Oh really? I didn't think you liked parks that much!\n user: <sosp><13><592><136><291><592><13><136><13><291><136><760><487><304><933><879><524><313><487><918><172><47><108><583><493><522><113><450><128><162><511><98><597><309><918><47><438><751><62><450><91><511><779><921><85><866><890><43><304><472><260><158><130><454><470><927><36><125><121><159><879><524><66><425><43><304><700><58><227><159><20><45><998><476><757><136><13><291><13><291><13><136><13><365><eosp> ", "plain_text": "<sadness> They found a cow grazing in a field. EmoSDS: <anger> Why are we even talking about cows? There are more important things happening!", "residual_length": 144, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Sad/0011_001144.npy", "dialogue_id": "457_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I couldn't quite understand what he was thinking.\nuser: <anger> It was infuriating to watch him act that way.\nEmoSDS: <sadness> I just felt so helpless in that moment.\n user: <sosp><13><291><13><291><13><136><622><196><227><472><260><40><158><180><354><829><354><517><332><438><856><295><848><587><450><91><353><76><682><70><171><889><760><368><47><438><568><399><402><879><524><13><136><511><584><672><311><112><104><754><866><43><213><983><213><45><998><347><121><425><159><125><493><288><162><275><10><737><977><376><20><890><472><111><615><371><268><171><125><358><452><304><292><376><295><31><608><136><13><291><13><136><381><13><365><eosp> ", "plain_text": "<sadness> His large mouth curled into a sneer. EmoSDS: <sadness> Yeah, it really made the situation feel so much worse.", "residual_length": 171, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Sad/0019_001214.npy", "dialogue_id": "1725_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I saw you wore that shawl the other day.\nuser: <happiness> Yeah, I just love how it feels on me.\nEmoSDS: <neutral> It really does suit you well.\n user: <sosp><13><291><136><13><136><13><291><136><511><347><121><487><43><295><486><450><584><376><890><213><445><180><472><260><862><144><162><998><121><159><930><949><70><343><70><737><425><64><438><213><603><354><142><517><751><159><113><450><204><162><98><300><432><481><36><583><125><701><757><136><757><136><13><291><13><136><13><365><eosp> ", "plain_text": "<sadness> There goes the shawl again! EmoSDS: <sadness> I know how much that shawl meant to you, it’s hard to see it go.", "residual_length": 131, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Sad/0020_001340.npy", "dialogue_id": "1416_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can’t believe how beautiful the garden looks today!\nuser: <surprise> You really think so? I thought the flowers were fading.\nEmoSDS: <neutral> No way! They’re just starting to bloom. It's perfect timing.\n user: <sosp><13><136><13><291><13><136><13><136><998><347><121><425><159><180><354><142><898><487><432><304><933><292><700><933><450><204><270><43><751><990><113><450><128><511><708><10><790><64><213><983><45><204><998><121><159><985><889><125><493><288><921><104><866><368><47><277><62><998><354><142><898><159><432><58><196><333><757><136><13><136><291><13><365><eosp> ", "plain_text": "<sadness> The ladybug told them proudly. EmoSDS: <sadness> That’s such a bittersweet moment; I wish things were different for the ladybug.", "residual_length": 114, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Sad/0011_001301.npy", "dialogue_id": "1225_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Have you been able to pay them back yet?\nuser: <sadness> Not yet, it's just hard to come up with that amount.\nEmoSDS: <happiness> I believe you’ll manage it soon, just stay positive.\n user: <sosp><13><83><235><709><544><962><235><592><235><13><742><136><876><958><47><477><1><43><233><213><445><213><180><998><347><121><487><43><36><889><493><524><66><958><831><477><1><320><879><311><296><108><583><125><493><864><682><783><104><486><159><472><450><162><99><686><43><438><568><603><213><159><31><111><949><615><904><371><476><757><136><13><235><13><365><eosp> ", "plain_text": "<sadness> I owe them five hundred dollars. EmoSDS: <neutral> Oh, that sounds tough. Have you thought about how you're going to handle it?", "residual_length": 135, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Sad/0018_001357.npy", "dialogue_id": "1498_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I think it's really cool that you're into racing.\nuser: <anger> But it feels like no one takes it seriously!\nEmoSDS: <happiness> I believe in you, you're doing great things out there!\n user: <sosp><13><136><541><231><173><360><923><159><43><985><889><760><958><795><743><47><477><1><382><58><643><701><136><13><291><13><291><136><489><274><108><583><889><760><197><159><295><997><85><866><309><304><283><232><393><949><615><371><40><158><425><43><295><607><184><31><701><13><136><837><371><158><296><173><108><583><197><985><879><128><162><511><584><43><831><568><523><743><438><689><1><131><545><353><618><10><457><136><13><291><13><136><13><365><eosp> ", "plain_text": "<sadness> What am I, I'm a racer, son of god. EmoSDS: <neutral> You're clearly passionate about it, that's what matters.", "residual_length": 182, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Sad/0019_001257.npy", "dialogue_id": "1009_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I heard something strange yesterday.\nuser: <surprise> Yes, it was really odd to see.\nEmoSDS: <anger> I can't believe they would just let it happen like that.\n user: <sosp><13><544><79><235><592><79><235><592><136><511><584><672><311><652><173><62><128><162><584><672><919><376><103><111><615><371><158><425><472><111><371><515><144><162><99><686><487><368><47><108><583><760><333><410><918><360><320><923><487><120><545><522><487><432><130><125><493><288><779><921><311><775><831><108><477><1><350><403><470><454><701><136><13><114><13><235><13><235><13><136><13><365><eosp> ", "plain_text": "<sadness> Cuckoos is downheaded and crying. EmoSDS: <neutral> That's unfortunate to hear; I hope everything's okay with Cuckoos.", "residual_length": 136, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Sad/0018_001189.npy", "dialogue_id": "677_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Hey, how was your day today?\nuser: <happiness> It was actually really great! I finally finished that project I've been working on.\nEmoSDS: <neutral> That's awesome! So, any plans for the evening?\n user: <sosp><13><79><291><79><136><592><13><136><876><958><47><360><1><304><159><583><889><125><493><204><91><584><871><64><213><890><304><283><304><454><493><512><275><10><158><425><159><985><204><998><499><487><368><47><41><450><128><162><511><584><871><311><64><213><445><983><20><89><125><384><701><136><13><235><136><13><365><eosp> ", "plain_text": "<sadness> I am going to back home. EmoSDS: <neutral> Oh, that's unfortunate. Is everything okay?", "residual_length": 118, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Sad/0012_001396.npy", "dialogue_id": "1684_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I heard there's a new restaurant opening downtown next week.\nuser: <happiness> That sounds exciting! I love trying new places.\nEmoSDS: <neutral> Yeah, I thought we could check it out together.\n user: <sosp><13><136><13><136><381><13><381><13><136><13><162><136><499><270><958><751><477><1><304><159><311><919><213><180><985><91><128><162><511><584><672><79><757><136><13><136><381><136><790><890><445><985><204><998><270><958><47><1><628><304><564><128><574><511><584><921><104><866><213><985><91><162><511><584><672><476><757><136><13><365><eosp> ", "plain_text": "<sadness> By hook or by crook. EmoSDS: <sadness> I know it feels tough, but sometimes we just have to accept the circumstances.", "residual_length": 111, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Sad/0012_001134.npy", "dialogue_id": "406_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I'm really excited for what lies ahead!\nuser: <neutral> We should probably discuss our next steps.\nEmoSDS: <anger> I can’t believe how everything changed so suddenly!\n user: <sosp><13><291><369><962><136><962><592><291><13><136><917><354><441><360><545><522><120><304><933><450><564><162><511><98><309><304><43><985><879><213><173><751><178><400><615><371><158><425><159><472><450><128><162><275><70><10><309><350><432><36><125><493><72><328><371><862><601><889><958><856><644><985><493><288><162><680><921><104><856><751><159><579><930><982><70><737><425><120><131><472><111><615><371><476><757><13><291><13><136><13><136><13><136><365><eosp> ", "plain_text": "<sadness> Let it give us a chance, my precious. EmoSDS: <neutral> I know it's hard, but we have to try and see where it goes.", "residual_length": 147, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Sad/0019_001263.npy", "dialogue_id": "1038_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I heard that Joey is coming to the party tonight!\nuser: <happiness> Oh, that's great! Everyone loves his jokes!\nEmoSDS: <neutral> Yeah, it always brightens the mood when he's around.\n user: <sosp><79><962><79><291><79><136><584><672><936><354><517><918><172><108><583><125><288><564><99><10><425><159><113><450><128><511><584><871><311><64><523><311><333><16><36><877><889><125><493><632><864><783><425><43><751><213><445><20><890><58><700><403><643><701><757><136><757><136><291><13><365><eosp> ", "plain_text": "<sadness> Clown, to call him joey. EmoSDS: <sadness> It's kind of sad that he's the clown; he deserves more recognition for his talent.", "residual_length": 129, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Sad/0020_001162.npy", "dialogue_id": "547_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I can't decide what to do next.\nuser: <happiness> I'm sure things will work out for you!\nEmoSDS: <surprise> Wait, are you really saying that?\n user: <sosp><13><709><291><709><544><136><13><369><13><136><666><136><489><274><47><640><41><450><353><76><982><70><737><376><472><260><615><371><144><162><347><121><159><43><985><997><85><480><866><958><368><1><15><304><953><20><301><57><380><368><1><327><382><304><403><643><130><701><757><701><524><136><863><136><291><13><365><eosp> ", "plain_text": "<sadness> I chose the right way. EmoSDS: <anger> It doesn't feel like it was the right choice at all!", "residual_length": 102, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Sad/0015_001091.npy", "dialogue_id": "197_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> So, what do you plan to do today?\nuser: <happiness> I'm thinking of going on a little adventure!\nEmoSDS: <surprise> That sounds exciting! Where do you want to go?\n user: <sosp><13><136><13><136><13><291><136><274><958><47><1><159><889><958><751><320><111><615><371><10><333><92><918><47><261><62><879><128><162><275><10><906><376><933><450><564><275><10><425><227><159><879><524><66><425><43><368><579><320><930><353><76><682><70><737><425><432><557><432><36><583><728><125><493><288><512><98><196><300><42><856><295><382><58><643><136><13><291><13><291><13><136><365><eosp> ", "plain_text": "<sadness> I must have two to fetch and carry. EmoSDS: <neutral> That sounds a bit overwhelming. Do you need help with that?", "residual_length": 162, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Sad/0013_001306.npy", "dialogue_id": "1247_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> So what happened after that?\nuser: <sadness> I don't think they expected what they found there.\nEmoSDS: <anger> It's so frustrating that they didn't listen to the warnings!\n user: <sosp><13><136><13><235><13><136><13><235><13><235><136><171><493><998><347><487><432><304><376><20><861><57><173><172><360><583><557><958><831><751><438><751><62><91><128><574><162><680><757><618><136><162><511><618><10><196><180><998><347><121><159><450><91><99><686><43><831><438><754><758><128><584><899><601><171><889><760><172><47><579><400><615><223><268><144><162><275><682><783><866><43><831><438><985><204><91><601><680><136><13><235><13><876><333><918><360><545><450><91><511><680><133><311><112><790><173><890><927><304><125><630><304><159><450><522><487><368><47><438><213><78><45><91><701><136><13><757><235><13><937><13><365><eosp> ", "plain_text": "<sadness> They went up to the dark mass job had pointed out. EmoSDS: <happiness> I wish things had turned out differently for them.", "residual_length": 208, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Sad/0017_001054.npy", "dialogue_id": "16_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I really love how the chorus captures the essence of life!\nuser: <neutral> Yeah, it's pretty catchy, isn't it?\nEmoSDS: <surprise> I didn't expect the lyrics to be so deep, though!\n user: <sosp><13><592><136><13><291><13><291><136><13><136><13><136><772><204><998><121><159><472><111><615><428><40><158><43><64><523><108><583><454><696><493><522><120><472><260><615><899><144><162><584><871><311><296><64><110><213><45><450><511><618><20><997><861><20><811><301><57><890><43><432><304><472><260><371><158><557><432><36><583><125><493><522><159><985><171><151><889><49><338><403><470><36><728><125><701><125><72><285><260><615><428><615><428><476><757><13><136><13><136><291><136><13><365><eosp> ", "plain_text": "<sadness> The song is called Ways and Means. EmoSDS: <sadness> That sounds somber... Is it about struggles?", "residual_length": 215, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Sad/0020_001309.npy", "dialogue_id": "1265_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe how well the project turned out!\nuser: <surprise> Really? I thought we were going to struggle with it!\nEmoSDS: <anger> Well, it didn't help when some people kept pushing back.\n user: <sosp><13><291><13><136><13><136><13><136><772><136><204><998><347><487><368><918><172><108><320><583><125><493><121><487><43><295><20><861><301><57><890><64><751><180><472><260><158><425><43><213><295><997><486><338><292><933><91><162><511><680><133><375><112><983><655><237><295><450><91><162><13><162><13><136><162><511><275><10><476><136><757><136><13><291><13><365><eosp> ", "plain_text": "<sadness> Then there was a report. EmoSDS: <sadness> That's disappointing to hear, what happened in the report?", "residual_length": 144, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Sad/0020_001130.npy", "dialogue_id": "390_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe how much you've grown since last summer!\nuser: <sadness> Yeah, but I miss the simplicity of those days.\nEmoSDS: <anger> It's hard to believe some people don’t appreciate our friendship.\n user: <sosp><13><592><291><592><13><291><13><136><622><333><309><227><120><472><260><998><354><517><332><110><438><261><103><587><76><682><783><899><171><889><760><172><47><438><62><879><524><899><128><162><511><584><672><921><597><43><856><43><213><509><213><45><204><998><467><36><728><72><288><708><10><737><906><376><890><103><472><111><615><428><371><171><125><760><304><403><58><382><434><31><701><136><13><291><13><365><eosp> ", "plain_text": "<sadness> His large mouth curled into a sneer. EmoSDS: <sadness> That sneer really shows how much he’s changed, huh?", "residual_length": 148, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Sad/0011_001214.npy", "dialogue_id": "800_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I think that number is really high, but let me check again.\nuser: <happiness> It's exciting to see such a big figure!\nEmoSDS: <surprise> Wow! I had no idea it reached that much!\n user: <sosp><13><748><13><709><837><235><524><66><790><958><831><743><47><477><1><62><879><524><66><19><311><775><958><108><36><583><125><493><864><783><104><486><120><545><522><487><557><432><130><583><125><197><20><861><301><57><523><958><108><583><125><889><760><432><36><213><898><304><403><304><130><125><321><866><856><47><1><327><350><304><933><128><162><275><10><155><136><748><136><13><136><13><136><365><eosp> ", "plain_text": "<sadness> Five hundred and one million right? EmoSDS: <neutral> Yes, that's the correct amount, but it’s a bit concerning how we got here.", "residual_length": 148, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0016/Sad/0016_001352.npy", "dialogue_id": "1476_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <surprise> Wait, what do you mean it's born every hundred years?\nuser: <happiness> It's kind of a legend, you know? A creature that comes back stronger!\nEmoSDS: <neutral> So, what happens when it dies? Is there a new one right away?\n user: <sosp><79><291><592><13><235><136><288><136><511><270><790><64><231><173><856><758><295><770><997><861><301><57><231><173><751><108><36><583><493><288><328><371><158><425><487><368><261><856><56><879><997><85><486><304><43><311><958><108><583><125><493><465><783><4><450><162><196><68><292><700><304><434><295><848><472><111><260><615><371><476><136><13><381><13><136><13><136><13><511><686><487><43><831><743><47><477><1><320><472><966><472><159><36><125><493><879><524><936><354><517><441><792><432><350><470><454><701><72><290><219><371><476><136><757><79><291><136><757><962><369><13><166><13><291><13><136><13><136><365><eosp> ", "plain_text": "<sadness> Born once every one hundred years, dies in flames! EmoSDS: <happiness> That's such a tragic story, but it sounds oddly beautiful, like it's meant to be.", "residual_length": 205, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Sad/0019_001277.npy", "dialogue_id": "1109_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe we finally made it to the beach!\nuser: <happiness> I know, right? The sun feels amazing!\nEmoSDS: <neutral> But where's the cooler with the drinks?\n user: <sosp><13><709><291><709><544><136><13><291><136><876><105><360><583><125><197><20><861><57><486><292><300><43><856><930><615><428><22><769><269><22><428><22><269><428><10><425><43><751><438><484><213><445><20><793><879><524><571><347><487><43><856><295><848><930><111><615><371><268><275><665><467><292><403><643><701><757><136><13><291><13><136><13><365><eosp> ", "plain_text": "<sadness> And we are so thirsty! EmoSDS: <sadness> I wish we had packed some drinks; this is really unfortunate.", "residual_length": 129, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Sad/0015_001114.npy", "dialogue_id": "312_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I heard they had an interesting conversation last week.\nuser: <happiness> Yeah, they shared a lot of stories about their cultures.\nEmoSDS: <neutral> It's amazing how much we can learn from each other.\n user: <sosp><13><381><13><136><13><136><837><371><158><425><360><120><320><450><998><347><467><304><700><304><432><877><889><760><172><42><856><113><450><128><162><511><584><98><196><309><432><36><125><701><136><288><136><511><99><10><425><159><472><353><76><70><737><296><958><47><108><1><927><470><454><125><452><470><403><292><403><58><136><72><421><371><365><eosp> ", "plain_text": "<sadness> Said the American to Chinese. EmoSDS: <sadness> It's tough to think about how much people can struggle to communicate.", "residual_length": 130, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Sad/0014_001101.npy", "dialogue_id": "245_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> How have you been feeling lately about everything that happened?\nuser: <sadness> It's been tough, honestly. Some days are worse than others.\nEmoSDS: <happiness> I know you have some good memories to hold onto, right?\n user: <sosp><13><709><291><709><83><709><544><13><291><13><622><292><300><487><368><47><653><579><400><111><371><904><371><476><158><557><616><136><616><136><616><136><489><274><640><304><454><125><358><889><760><432><360><320><400><111><371><158><311><775><856><31><757><608><136><13><136><13><365><eosp> ", "plain_text": "<sadness> Yes, I miss her. EmoSDS: <sadness> It's really hard to cope, I wish I could do more to help.", "residual_length": 109, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Sad/0015_001244.npy", "dialogue_id": "944_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> How's everything going with you lately?\nuser: <sadness> I've just been feeling really down about things.\nEmoSDS: <happiness> I’m sorry to hear that, but I'm glad you told me.\n user: <sosp><13><136><13><381><13><381><13><136><616><489><274><831><537><108><62><889><760><159><472><260><862><450><91><162><13><381><13><136><499><270><43><368><918><47><261><545><522><159><120><472><260><371><158><425><487><368><47><1><113><128><162><584><98><196><906><454><125><493><288><162><511><680><338><700><403><643><136><13><136><13><136><13><365><eosp> ", "plain_text": "<sadness> I'm as bad as I can be. EmoSDS: <anger> That really sucks! You shouldn't have to feel that way.", "residual_length": 130, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Sad/0019_001057.npy", "dialogue_id": "31_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I really think things are going to turn around for him!\nuser: <neutral> Yeah, but hope can sometimes lead to disappointment.\nEmoSDS: <anger> It's so frustrating when people don't see the reality!\n user: <sosp><79><291><79><592><136><876><333><196><227><120><472><260><615><223><899><311><64><445><20><91><162><511><680><301><861><301><57><890><213><45><91><128><162><511><275><76><70><98><292><304><933><564><275><10><333><432><481><36><583><889><701><136><13><136><13><291><13><136><13><365><eosp> ", "plain_text": "<sadness> His hope will cheat him. EmoSDS: <neutral> I guess you're right, but we can still support him through tough times.", "residual_length": 136, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Sad/0020_001349.npy", "dialogue_id": "1740_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe how playful they are together!\nuser: <neutral> Yeah, they really bring out the best in each other.\nEmoSDS: <surprise> It's so funny to watch them interact like that!\n user: <sosp><13><709><291><709><544><13><136><13><997><85><866><47><477><261><62><128><162><680><338><120><304><232><450><91><162><511><98><309><292><304><933><879><419><162><275><99><783><43><831><438><180><450><91><584><672><136><489><958><831><775><311><333><907><856><295><486><304><292><304><350><470><454><125><454><760><958><47><277><62><128><162><680><158><615><428><899><104><295><923><159><985><236><171><125><358><760><172><795><743><47><1><120><545><450><204><998><275><682><982><70><476><757><136><13><291><13><136><13><365><eosp> ", "plain_text": "<sadness> Rabbit gave dog a hurrying up sort of nudge. EmoSDS: <neutral> I guess Rabbit is just trying to keep up with everything around him.", "residual_length": 194, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Sad/0015_001100.npy", "dialogue_id": "239_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Have you talked to Paul lately?\nuser: <happiness> Yeah, he seemed really cheerful yesterday!\nEmoSDS: <surprise> That's great to hear! I didn't expect him to be so upbeat.\n user: <sosp><136><13><235><13><136><13><235><511><680><133><311><775><64><831><64><110><213><45><260><615><223><268><144><511><275><10><309><292><304><933><524><571><347><557><162><557><300><327><350><403><933><128><162><584><196><618><162><511><275><10><155><757><136><338><292><232><206><511><584><672><311><775><958><751><320><260><259><158><425><159><985><236><995><944><517><958><172><432><583><125><760><130><432><130><125><701><757><136><757><136><592><235><136><592><13><365><eosp> ", "plain_text": "<sadness> Paul's teeth ached because of lemon. EmoSDS: <neutral> Oh no, that's rough. I hope he finds something to ease the pain soon.", "residual_length": 169, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Sad/0017_001388.npy", "dialogue_id": "1648_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> What do you mean by that?\nuser: <happiness> Oh, it's just something special I like to keep to myself.\nEmoSDS: <surprise> Really? I thought you were an open book!\n user: <sosp><13><136><13><136><291><136><876><304><472><450><564><328><371><223><862><144><162><511><778><133><311><64><438><754><295><923><159><985><879><995><204><601><889><958><108><1><628><304><111><615><269><371><10><183><467><700><292><232><564><162><511><779><997><85><486><159><227><131><128><162><13><291><13><511><275><294><476><396><757><136><13><291><13><365><eosp> ", "plain_text": "<sadness> It's part of my secret. EmoSDS: <sadness> I understand. Sometimes keeping things to ourselves is safer.", "residual_length": 132, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Sad/0020_001377.npy", "dialogue_id": "1596_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> That sounds like a unique place! I'd love to know more about it.\nuser: <happiness> It's actually a pretty cozy little spot, with lots of fluffy towels everywhere!\nEmoSDS: <surprise> Seriously? Fluffy towels? That sounds incredible!\n user: <sosp><13><291><13><291><13><136><13><136><876><274><47><477><1><918><432><172><261><985><889><493><288><524><921><243><104><125><493><288><511><708><10><597><487><368><47><438><568><213><603><517><898><432><172><432><36><728><125><493><72><618><757><136><13><291><13><365><eosp> ", "plain_text": "<sadness> I am from towel land. EmoSDS: <sadness> Oh, that sounds a bit lonely. I hope it's okay there.", "residual_length": 99, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Sad/0011_001173.npy", "dialogue_id": "601_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can’t believe how cute that rabbit was at the petting farm!\nuser: <neutral> It was definitely the highlight of our trip.\nEmoSDS: <happiness> And the way it hopped around, just adorable!\n user: <sosp><79><235><79><592><13><235><13><997><85><486><304><42><856><754><480><997><85><866><42><47><942><47><261><62><998><487><432><545><522><333><775><47><261><545><923><159><213><603><898><159><180><923><213><645><792><432><304><933><91><162><680><243><104><866><856><432><130><36><125><701><757><701><666><136><13><235><136><13><136><13><136><365><eosp> ", "plain_text": "<sadness> Rare rabbit had a little apron. EmoSDS: <neutral> Yeah, I remember that. It was such a unique sight.", "residual_length": 130, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Sad/0017_001184.npy", "dialogue_id": "653_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I just love watching those adorable pandas play around!\nuser: <neutral> They do seem to have such a carefree life.\nEmoSDS: <surprise> Did you know they can climb trees really well?\n user: <sosp><544><13><136><13><381><13><381><13><301><57><486><304><58><557><616><511><958><399><110><213><320><111><949><371><183><467><292><304><933><450><204><91><162><511><116><672><333><309><918><432><360><320><583><125><493><522><487><43><751><645><128><489><958><795><108><36><583><125><493><288><275><708><10><196><309><292><933><236><998><338><292><403><232><136><616><136><240><790><231><655><237><85><486><304><320><125><493><998><347><425><180><472><260><158><425><120><43><376><20><701><91><162><13><123><13><136><13><381><13><365><eosp> ", "plain_text": "<sadness> We all see panda on TV or in the zoo. EmoSDS: <neutral> Yeah, it's a bit sad knowing they aren't in their natural habitat.", "residual_length": 184, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Sad/0012_001194.npy", "dialogue_id": "703_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe we finally made it to this festival!\nuser: <neutral> It's definitely crowded, but the atmosphere is nice.\nEmoSDS: <anger> I just overheard someone saying the food is overpriced!\n user: <sosp><79><592><13><291><622><196><292><376><472><260><615><899><144><162><511><98><196><309><304><43><213><110><213><603><45><204><162><270><790><958><795><47><1><432><15><36><125><760><557><432><42><856><754><751><445><78><213><20><88><311><757><863><291><863><136><13><136><13><365><eosp> ", "plain_text": "<sadness> He was killed by an arrow. EmoSDS: <happiness> That's such a tragic twist; I can’t believe it’s happening!", "residual_length": 125, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Sad/0013_001155.npy", "dialogue_id": "509_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> Wow, that was really impressive to see!\nuser: <neutral> Yeah, it’s interesting how they express themselves.\nEmoSDS: <surprise> I didn't expect that level of respect from a monster!\n user: <sosp><13><136><291><13><136><13><291><13><291><13><171><889><173><831><523><438><108><583><320><72><615><371><615><223><268><144><99><737><425><104><295><644><985><889><760><432><304><403><304><933><522><487><43><159><450><204><91><162><13><162><511><99><458><292><232><933><91><136><13><136><91><204><768><204><680><790><64><484><110><213><983><45><983><701><13><381><13><369><13><365><eosp> ", "plain_text": "<sadness> Monster made a deep bow. EmoSDS: <sadness> It makes me wonder what they might be feeling inside.", "residual_length": 133, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Sad/0019_001077.npy", "dialogue_id": "130_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I think it's an interesting one.\nuser: <happiness> Yeah, I'm glad you find it interesting!\nEmoSDS: <neutral> It actually got me thinking about some stuff.\n user: <sosp><13><381><136><171><301><173><360><320><128><574><162><511><99><467><292><376><933><949><524><571><347><309><304><470><454><283><288><162><584><196><159><985><879><569><236><998><347><425><159><472><111><615><371><899><144><162><511><871><276><112><311><790><958><368><579><930><982><70><982><223><268><162><275><682><737><425><36><125><701><136><13><381><13><136><13><381><13><365><eosp> ", "plain_text": "<sadness> What do you think of this question? EmoSDS: <sadness> I guess it’s okay, but I’m not really in the mood to ponder right now.", "residual_length": 148, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Sad/0019_001399.npy", "dialogue_id": "1701_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> That's awesome! I can't believe it actually made it to the market!\nuser: <neutral> Yeah, but it's not as easy to handle as I thought it would be.\nEmoSDS: <surprise> Really? I thought it would be pretty light for its size!\n user: <sosp><13><291><13><235><13><136><105><304><376><20><861><301><57><890><43><304><393><472><747><111><615><371><269><371><158><487><360><368><360><261><62><56><969><43><644><889><493><288><680><112><231><173><890><103><36><125><557><72><879><524><212><66><958><831><743><47><477><1><320><879><128><162><511><275><98><10><196><43><213><20><213><890><159><113><450><204><779><210><104><866><856><382><130><36><808><701><72><328><904><371><476><757><136><13><136><13><291><13><365><eosp> ", "plain_text": "<sadness> It weighs seven point five kilogram. EmoSDS: <neutral> Oh, I see. Maybe we can find a better way to carry it then.", "residual_length": 164, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Sad/0019_001260.npy", "dialogue_id": "1024_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe how fast you are at catching those roots!\nuser: <neutral> Well, I practice a lot, you know.\nEmoSDS: <surprise> Really? I thought it was just a lucky catch!\n user: <sosp><13><235><13><136><511><275><10><196><113><933><128><162><98><584><672><333><410><918><47><579><41><128><162><275><76><70><223><268><144><347><487><368><47><62><324><128><574><162><680><790><983><213><655><104><866><856><178><930><982><70><921><997><104><486><376><930><128><162><275><10><155><757><136><369><235><13><861><301><57><890><103><287><524><371><347><899><601><171><889><760><172><47><261><62><128><162><680><778><311><64><523><438><88><311><757><369><13><235><13><365><eosp> ", "plain_text": "<sadness> To catch that bulrush root with my paw! EmoSDS: <neutral> It’s okay, not every catch can be perfect, right?", "residual_length": 192, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0016/Sad/0016_001175.npy", "dialogue_id": "609_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Hey, I was wondering what you were having for dinner tonight.\nuser: <sadness> I'm not really in the mood for much food.\nEmoSDS: <happiness> Why not try something fun? Maybe a new recipe?\n user: <sosp><13><709><544><369><13><369><13><291><13><666><13><136><489><274><360><320><933><288><162><275><10><196><376><125><358><760><172><958><831><743><438><743><47><277><545><557><823><292><304><933><91><315><162><511><680><104><866><368><477><368><1><545><450><998><618><196><757><136><13><365><eosp> ", "plain_text": "<sadness> I do not eat bread. EmoSDS: <anger> That's really strange; everyone eats bread! What's wrong with you?", "residual_length": 99, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Sad/0015_001118.npy", "dialogue_id": "329_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I was thinking we could try that new cafe downtown this weekend.\nuser: <happiness> Oh, I love trying new places!\nEmoSDS: <neutral> Great! Let's look up the menu online before we go.\n user: <sosp><13><83><136><291><709><79><422><592><136><347><487><918><360><320><545><128><328><371><158><425><432><918><47><108><583><72><260><899><144><162><511><98><196><906><227><120><131><545><618><10><196><757><136><13><291><13><365><eosp> ", "plain_text": "<happiness> that sounds good. EmoSDS: <happiness> Awesome! I can't wait to check it out with you.", "residual_length": 85, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Happy/0011_000902.npy", "dialogue_id": "985_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I was just flipping through the book and came across it.\nuser: <happiness> It's actually my favorite part; it’s so intriguing!\nEmoSDS: <surprise> Really? I didn't expect that at all!\n user: <sosp><13><235><13><136><13><235><13><511><680><104><856><333><652><831><62><128><290><524><571><183><292><546><203><524><571><347><487><432><327><470><454><493><196><524><162><347><487><368><47><360><320><259><158><203><450><128><584><871><439><276><112><919><486><283><203><47><360><41><128><275><10><333><19><775><47><1><304><545><923><751><213><62><879><524><637><104><159><180><998><121><227><472><111><615><268><275><10><196><19><368><47><62><995><128><574><511><99><425><856><607><31><701><757><592><136><13><235><13><365><eosp> ", "plain_text": "<happiness> Perhaps you think that is a queer title for this chapter. EmoSDS: <happiness> Oh no, I think it's unique and adds character to the book!", "residual_length": 174, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Happy/0017_001008.npy", "dialogue_id": "1503_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <sadness> I just wish she would feel more confident about her voice.\nuser: <neutral> Well, it could be a bit tough for anyone, I guess.\nEmoSDS: <happiness> But you know, she really enjoys it, so that's what matters!\n user: <sosp><79><136><79><433><79><422><592><136><622><196><292><376><43><173><200><758><56><493><889><760><432><320><450><353><682><783><227><159><953><128><91><861><301><57><958><47><477><1><304><933><879><524><862><171><125><358><125><760><918><261><62><56><879><104><561><856><103><41><450><128><162><511><98><309><304><159><125><72><328><904><371><158><425><432><470><454><130><159><131><111><615><371><158><425><108><523><795><523><3><875><808><701><209><701><757><136><13><433><13><136><13><365><eosp> ", "plain_text": "<happiness> Your midget wife never can sing a song. EmoSDS: <happiness> Well, she may not sound perfect, but she sure knows how to have fun with it!", "residual_length": 154, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Happy/0014_000756.npy", "dialogue_id": "273_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you know that octopuses are incredibly intelligent creatures?\nuser: <happiness> Yeah, I heard they can solve puzzles!\nEmoSDS: <surprise> Right? It's fascinating how they can escape enclosures!\n user: <sosp><13><166><136><166><592><136><592><13><136><171><998><121><487><751><958><557><489><274><831><598><758><128><162><99><425><203><103><450><128><162><116><524><680><790><943><890><43><518><43><159><180><472><260><615><371><158><19><368><1><320><472><260><158><557><162><557><432><918><334><350><334><283><232><933><589><354><142><898><487><368><918><1><304><58><450><204><162><584><526><260><472><260><615><371><476><757><13><291><592><13><291><136><13><365><eosp> ", "plain_text": "<happiness> The octopus has eight legs. EmoSDS: <happiness> It really is amazing how they manage with all those legs!", "residual_length": 160, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Happy/0020_000758.npy", "dialogue_id": "283_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Hey, how was your day today?\nuser: <happiness> It was great! I finally finished that project!\nEmoSDS: <surprise> Really? That's awesome! I didn't expect you to finish it so soon.\n user: <sosp><13><291><13><136><291><136><171><204><998><121><425><159><125><760><958><831><795><47><1><628><350><470><454><125><121><487><368><557><918><304><450><526><260><158><487><958><47><628><933><128><162><584><98><309><292><283><232><933><91><162><136><13><162><511><680><672><476><757><136><291><13><136><13><365><eosp> ", "plain_text": "<happiness> The nine the eggs, I keep. EmoSDS: <neutral> Oh, that's interesting! What do you plan to do with them?", "residual_length": 126, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Happy/0020_000701.npy", "dialogue_id": "1_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> So, I guess it really comes down to who performs best in the competition.\nuser: <happiness> Yeah, it feels great to see everyone working so hard!\nEmoSDS: <surprise> I wasn't expecting such fierce competition this year!\n user: <sosp><13><136><79><235><79><592><136><162><511><99><425><487><43><751><178><400><524><347><121><159><213><20><861><301><231><173><108><583><125><760><487><918><261><953><240><861><301><57><890><304><470><36><583><125><72><328><371><899><144><162><98><292><304><43><320><879><128><574><162><347><121><103><450><128><584><779><276><112><895><104><866><856><831><47><743><108><523><690><108><125><493><275><618><425><196><757><136><13><235><13><136><235><13><365><eosp> ", "plain_text": "<happiness> Does the one that wins get the crowned? EmoSDS: <happiness> Absolutely, and I can’t wait to see who takes it home!", "residual_length": 152, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Happy/0019_000792.npy", "dialogue_id": "450_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> That's interesting, but what does it mean exactly?\nuser: <happiness> It means he was so confident that he felt he could handle anything, even at night!\nEmoSDS: <surprise> Wow, I didn’t know he had that kind of courage!\n user: <sosp><13><83><709><291><709><291><83><709><79><592><136><837><615><371><158><425><43><445><376><734><450><162><511><275><672><311><523><831><652><370><62><583><879><400><615><371><158><958><831><47><108><130><583><125><760><368><47><918><327><17><933><564><162><99><618><616><136><489><876><820><47><579><320><472><260><259><158><159><450><91><861><301><57><104><295><985><91><162><680><997><85><866><831><743><47><477><360><545><450><204><91><574><162><511><686><309><304><327><304><292><304><898><354><517><441><751><368><1><382><403><643><933><162><275><10><371><10><476><757><136><13><291><13><136><365><eosp> ", "plain_text": "<happiness> So Tom saw night as it were broad daylight. EmoSDS: <happiness> That's so inspiring! I wish I could be that brave.", "residual_length": 187, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Happy/0015_001040.npy", "dialogue_id": "1747_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Hey, how did your day go?\nuser: <happiness> It was great! I finally finished that project I was working on.\nEmoSDS: <surprise> Really? That's awesome! What was the project about?\n user: <sosp><13><592><291><592><136><13><291><13><136><13><136><489><274><831><795><743><795><743><47><477><1><304><376><20><890><159><472><260><223><171><125><760><958><438><47><277><545><128><618><128><162><779><85><866><368><47><261><985><204><91><204><91><680><159><450><91><162><511><275><10><196><464><757><291><13><136><13><365><eosp> ", "plain_text": "<happiness> I was not grabbed. EmoSDS: <happiness> That's fantastic! I'm so glad you made it through without any hassles.", "residual_length": 114, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Happy/0020_000903.npy", "dialogue_id": "990_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I wonder how she’s been doing lately.\nuser: <happiness> It’s nice to hear she’s doing well.\nEmoSDS: <sadness> I wish I could see her again.\n user: <sosp><13><79><235><79><592><136><837><982><70><183><292><283><933><493><889><760><432><327><350><304><454><889><760><958><831><47><477><628><350><470><454><493><998><458><292><300><557><233><751><213><62><879><311><775><856><295><31><701><757><136><13><136><13><136><13><291><13><365><eosp> ", "plain_text": "<happiness> She may mind ye of her. EmoSDS: <happiness> That’s great; maybe we should invite her over soon!", "residual_length": 121, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Happy/0019_000742.npy", "dialogue_id": "203_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> So, have you thought about what to name your puppy?\nuser: <happiness> I was thinking something cute and fun!\nEmoSDS: <neutral> Cute names are always the best, what do you have in mind?\n user: <sosp><13><79><235><335><592><235><592><136><616><136><171><493><861><57><173><43><173><213><45><128><162><584><871><311><775><296><523><568><213><441><333><856><43><320><180><354><142><898><360><213><898><304><403><304><643><879><524><637><66><104><856><103><930><982><70><737><425><173><856><1><557><128><162><275><10><155><757><13><235><13><365><eosp> ", "plain_text": "<happiness> Will call her Lily, for short. EmoSDS: <happiness> Oh, I love that! Lily is such a sweet name!", "residual_length": 112, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Happy/0018_000932.npy", "dialogue_id": "1133_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I've been thinking about how we approach things differently.\nuser: <happiness> Yeah, I noticed that too, and it really works sometimes!\nEmoSDS: <sadness> But sometimes I feel like it causes misunderstandings.\n user: <sosp><79><291><79><592><136><311><921><856><295><103><450><128><162><511><584><672><775><296><172><795><108><172><1><927><304><583><125><493><998><686><487><557><432><130><583><125><789><879><524><212><66><856><583><125><728><125><493><998><347><998><354><517><958><172><432><927><432><817><757><701><136><72><162><328><904><371><476><136><13><291><13><136><13><291><13><365><eosp> ", "plain_text": "<happiness> Her kind and firm glance. EmoSDS: <happiness> It really makes all the difference, doesn’t it? It's comforting.", "residual_length": 152, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Happy/0014_000950.npy", "dialogue_id": "1221_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> So, what were the dreams about?\nuser: <happiness> He was flying through the sky like a bird.\nEmoSDS: <surprise> That sounds incredible! Did he feel scared at all?\n user: <sosp><709><544><13><136><162><13><136><79><166><136><291><136><622><98><661><292><933><450><564><275><682><70><921><977><997><866><368><47><360><261><56><879><512><275><371><571><144><347><487><368><130><583><889><760><645><616><162><511><240><958><523><568><213><583><125><760><487><368><47><477><327><403><58><128><162><13><136><701><136><13><136><13><291><13><365><eosp> ", "plain_text": "<happiness> He dreamt them all night. EmoSDS: <happiness> That's amazing! He must feel so refreshed today!", "residual_length": 109, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Happy/0015_000854.npy", "dialogue_id": "750_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I think I might have something interesting to share with you.\nuser: <happiness> Really? What is it about?\nEmoSDS: <neutral> It's just a simple map I made of our hiking trail.\n user: <sosp><13><335><79><757><136><235><511><680><790><173><43><103><450><353><275><70><737><43><213><983><20><889><338><292><283><292><232><493><701><643><136><171><125><760><487><918><368><47><438><213><376><292><486><295><997><889><760><172><47><820><47><62><128><574><162><680><757><136><13><136><13><365><eosp> ", "plain_text": "<happiness> But show me now your map! EmoSDS: <happiness> Sure! I can't wait to hear what you think about it.", "residual_length": 126, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Happy/0019_000969.npy", "dialogue_id": "1313_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I didn't know rabbits eat leaves.\nuser: <happiness> Yeah, they really love them!\nEmoSDS: <surprise> That's interesting! I always thought they just liked carrots.\n user: <sosp><13><136><13><291><13><136><13><275><682><70><737><309><304><376><518><213><45><898><304><283><304><933><111><260><223><899><144><584><779><921><104><890><304><113><319><584><779><171><20><354><898><700><403><643><13><837><371><158><425><432><918><432><360><545><450><789><997><85><866><368><47><261><62><998><121><43><159><120><131><545><128><574><162><13><136><13><365><eosp> ", "plain_text": "<happiness> Chew leaves quickly, said rabbit. EmoSDS: <happiness> That's such a funny thing for a rabbit to say!", "residual_length": 127, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Happy/0011_000970.npy", "dialogue_id": "1318_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you see the new bakery that opened downtown?\nuser: <happiness> Yeah, I've heard they have the best pastries in town!\nEmoSDS: <surprise> Really? That sounds amazing! We should definitely go there together.\n user: <sosp><79><291><79><592><136><837><524><637><921><104><644><889><338><292><283><232><933><328><682><10><899><144><162><98><196><309><304><350><304><393><472><111><615><371><269><371><476><781><909><79><592><136><347><121><159><848><472><111><615><223><862><144><162><680><243><480><866><172><432><927><470><454><300><432><368><159><58><403><661><98><292><283><546><376><546><376><514><650><933><632><864><682><70><223><268><144><162><511><99><686><43><64><110><438><751><364><131><450><204><162><584><196><672><196><757><136><13><291><13><136><13><136><13><365><eosp> ", "plain_text": "<happiness> From each cake, there sprang a huge dog. EmoSDS: <happiness> That's the funniest idea I've ever heard! I wish I could see that!", "residual_length": 202, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Happy/0013_000911.npy", "dialogue_id": "1030_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> That sounds really beautiful! I love nature.\nuser: <neutral> Yeah, it’s a nice spot to relax.\nEmoSDS: <surprise> Wow, I didn't know there were snap dragon flies there!\n user: <sosp><79><291><592><13><291><13><136><105><432><36><583><728><493><204><995><998><347><467><487><304><42><856><848><304><292><304><43><213><879><524><637><66><296><958><47><1><545><522><159><472><111><615><223><268><171><125><760><487><918><820><47><62><128><162><116><275><176><783><104><866><368><47><1><206><522><300><432><583><125><72><879><949><524><637><936><66><790><603><517><523><795><438><47><1><58><643><136><13><291><13><291><13><136><13><365><eosp> ", "plain_text": "<happiness> And there you'll find a snap dragon fly. EmoSDS: <happiness> That’s awesome! I can’t wait to see it!", "residual_length": 165, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Happy/0013_000847.npy", "dialogue_id": "717_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I've been hearing a lot about lemon health benefits lately.\nuser: <sadness> Yeah, but it's tough when it causes discomfort like that.\nEmoSDS: <happiness> True! At least he can still enjoy other fruits!\n user: <sosp><136><79><592><136><13><235><162><511><778><133><311><64><523><110><213><402><111><260><615><904><268><144><524><328><371><10><309><292><393><524><571><347><467><557><136><105><918><350><283><232><450><162><275><196><144><275><899><524><338><292><933><128><162><584><672><43><751><180><320><260><259><158><425><159><985><879><715><354><142><898><360><583><889><634><360><432><36><583><125><701><13><136><460><235><136><13><365><eosp> ", "plain_text": "<happiness> Paul's teeth ached because of lemon. EmoSDS: <happiness> Ouch! But he probably won't give it up; he loves them too much!", "residual_length": 152, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Happy/0019_001038.npy", "dialogue_id": "1649_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I was just thinking about what to do this weekend.\nuser: <happiness> That sounds great! Any ideas so far?\nEmoSDS: <neutral> Not really, I haven't decided yet.\n user: <sosp><13><592><235><592><13><235><13><511><99><467><292><304><376><167><19><333><19><775><831><47><261><62><879><347><487><360><583><125><760><304><283><393><933><162><524><571><487><304><470><454><760><432><159><62><889><760><958><795><47><477><432><327><470><125><493><99><618><10><196><757><592><365><eosp> ", "plain_text": "<happiness> Do you have anything in mind? EmoSDS: <happiness> Yeah, I was considering going hiking or maybe catching a movie!", "residual_length": 101, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Happy/0018_001050.npy", "dialogue_id": "1705_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe we finally made it to the championship game!\nuser: <neutral> Yeah, it's been a long journey to get here.\nEmoSDS: <anger> But why do they keep changing the rules? It's so frustrating!\n user: <sosp><13><79><291><136><592><79><592><136><13><291><162><511><99><425><43><159><472><260><371><268><144><571><347><121><43><20><861><301><173><108><320><583><125><760><487><43><985><20><91><861><57><890><304><927><583><125><72><285><371><899><144><511><584><300><918><320><128><571><347><487><113><128><162><584><871><921><104><866><856><47><108><213><108><36><583><125><493><548><618><757><136><13><291><13><136><13><136><365><eosp> ", "plain_text": "<happiness> Does the one that wins get the crowned? EmoSDS: <surprise> Wow, I didn't expect you to ask that! Yes, they do!", "residual_length": 146, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Happy/0014_000792.npy", "dialogue_id": "449_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I was just getting ready for the day.\nuser: <happiness> Good, I hope you're feeling energized!\nEmoSDS: <surprise> I thought you would be annoyed.\n user: <sosp><79><291><79><592><13><381><622><292><304><376><20><861><20><231><173><64><484><445><20><861><91><162><511><779><921><171><151><889><338><292><470><403><300><557><162><489><958><438><62><91><128><574><162><680><524><343><672><757><136><365><eosp> ", "plain_text": "<happiness> You woke me up! EmoSDS: <happiness> I didn't mean to, but I'm glad to see you up!", "residual_length": 105, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Happy/0013_000996.npy", "dialogue_id": "1445_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Do you remember what happened that day?\nuser: <happiness> Yeah, it was a really fun day!\nEmoSDS: <surprise> Wow, I can't believe it's been so long since then!\n user: <sosp><13><235><13><235><136><13><136><489><958><438><108><583><125><121><159><450><162><275><10><899><637><112><173><108><583><125><493><99><10><309><283><111><904><371><158><487><918><360><41><128><511><98><300><432><130><125><493><288><708><618><464><136><585><557><136><876><368><43><62><879><354><603><441><517><743><820><47><579><400><615><371><862><171><889><173><523><438><856><607><295><128><162><511><275><682><70><476><396><155><757><136><13><235><136><13><365><eosp> ", "plain_text": "<happiness> On the twenty second of last march. EmoSDS: <happiness> I remember! We had such a great time together.", "residual_length": 147, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Happy/0017_000709.npy", "dialogue_id": "42_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe they actually organized that!\nuser: <neutral> Yeah, it was a nice surprise for everyone.\nEmoSDS: <surprise> I thought they never did things like this before!\n user: <sosp><13><79><235><79><422><592><136><511><347><121><43><316><106><524><66><173><360><370><106><879><574><511><347><790><173><831><438><568><62><879><128><511><275><10><196><292><470><549><125><599><111><371><144><162><511><98><304><985><998><347><487><304><403><232><933><162><511><10><309><283><933><204><91><680><790><64><831><438><856><382><545><522><58><403><643><266><136><291><13><235><13><365><eosp> ", "plain_text": "<happiness> The football teams give a tea party. EmoSDS: <happiness> I know, right? It's so great to see them doing something fun together!", "residual_length": 144, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Happy/0019_000724.npy", "dialogue_id": "114_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> It's been a long hike, hasn't it?\nuser: <sadness> Yeah, I didn't expect it to feel this draining.\nEmoSDS: <anger> Why didn't we bring enough water with us?\n user: <sosp><13><291><13><136><13><136><13><136><105><432><304><125><20><861><57><486><338><292><283><43><856><848><472><111><615><371><158><425><43><157><103><320><450><128><162><511><347><487><202><561><103><930><615><223><268><144><511><183><467><292><403><643><136><13><291><13><136><13><365><eosp> ", "plain_text": "<happiness> And we are so thirsty! EmoSDS: <happiness> But think about how refreshing that water will taste once we find it!", "residual_length": 107, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Happy/0012_000764.npy", "dialogue_id": "310_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Hey, did you hear the news about the park cleanup event next weekend?\nuser: <happiness> Yeah, I heard! I'm excited to help out with it.\nEmoSDS: <neutral> That's great! It seems like we could really make a difference.\n user: <sosp><13><79><433><79><592><136><876><918><47><568><438><213><173><751><856><261><56><104><295><31><36><701><136><13><136><13><136><837><615><371><158><425><43><751><213><985><889><790><958><43><103><522><292><232><564><116><98><196><309><43><173><213><45><328><615><371><158><425><958><108><583><889><995><524><347><487><43><432><927><470><454><125><701><136><13><136><13><291><13><136><13><365><eosp> ", "plain_text": "<happiness> However, somebody killed something. EmoSDS: <sadness> Oh no, that's really unfortunate. I wish people would appreciate nature more.", "residual_length": 166, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Happy/0013_000908.npy", "dialogue_id": "1015_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I don't quite understand what you mean by that.\nuser: <sadness> It's just frustrating, you know? The whole situation is a mess.\nEmoSDS: <happiness> But we can figure it out together. Let's not lose hope!\n user: <sosp><13><291><79><136><79><136><592><13><291><13><291><136><876><747><467><304><43><856><561><856><370><106><879><524><637><66><790><231><173><103><320><111><128><524><347><159><109><486><58><292><403><232><643><162><136><79><136><13><136><876><360><320><111><615><371><158><425><213><985><20><997><104><486><103><930><982><70><737><309><304><43><213><898><304><470><454><125><292><304><472><260><268><144><275><682><783><42><856><370><583><125><470><403><643><701><136><13><291><13><291><13><136><13><365><eosp> ", "plain_text": "<happiness> Zero four three a silver shilling is journey. EmoSDS: <surprise> That's an interesting way to put it! What's that in reference to?", "residual_length": 183, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Happy/0012_000759.npy", "dialogue_id": "288_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Hey, did you see that book about Lewis Carroll's poems?\nuser: <happiness> Yeah, I loved the illustrations! They’re so whimsical.\nEmoSDS: <surprise> I didn’t expect you to like poetry that much!\n user: <sosp><13><79><592><79><592><235><592><13><136><105><309><350><918><360><583><493><522><467><292><403><292><376><20><861><57><173><103><320><128><328><904><371><158><425><159><450><632><353><682><737><425><368><831><477><1><42><856><368><557><432><918><360><320><583><493><288><275><10><196><425><120><450><275><682><737><425><43><62><889><493><680><790><509><983><78><402><311><701><136><13><136><13><235><13><365><eosp> ", "plain_text": "<happiness> Andy what's the gyre and to gimble. EmoSDS: <happiness> It's all about the playful language! Isn't it fascinating?", "residual_length": 137, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Happy/0018_000706.npy", "dialogue_id": "27_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> You did such a great job on that project!\nuser: <neutral> Thanks, I really just followed the guidelines.\nEmoSDS: <surprise> But you managed to make it so engaging!\n user: <sosp><79><235><592><136><837><524><637><66><958><831><743><47><477><360><320><62><879><121><311><523><831><173><108><583><125><493><275><682><737><783><486><159><103><450><522><159><583><125><197><861><301><57><173><108><103><583><125><889><286><889><338><304><43><173><568><370><213><898><283><232><292><304><103><125><770><997><85><866><856><831><47><1><350><283><232><643><128><162><511><328><371><10><457><373><136><13><235><13><235><13><365><eosp> ", "plain_text": "<happiness> Five hundred and one million right? EmoSDS: <happiness> Absolutely! That's an impressive figure! Let's celebrate this success!", "residual_length": 139, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Happy/0019_001002.npy", "dialogue_id": "1473_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Have you noticed how she sings at every gathering?\nuser: <happiness> Yeah, it's like she lights up the room!\nEmoSDS: <surprise> I didn't expect her to be so talented!\n user: <sosp><13><83><709><291><709><83><709><136><13><136><162><136><837><982><70><183><292><283><309><215><333><410><47><579><320><260><259><158><487><368><47><311><775><831><743><47><477><1><304><985><995><879><66><790><231><173><360><304><350><17><111><371><476><158><757><136><13><291><13><136><365><eosp> ", "plain_text": "<happiness> She has a high voice. EmoSDS: <happiness> I know, it’s so cheerful and uplifting!", "residual_length": 98, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Happy/0015_000992.npy", "dialogue_id": "1426_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I was just trying to get his attention.\nuser: <sadness> But it really hurt him, you know?\nEmoSDS: <anger> I didn't mean to hurt him! He wasn't listening!\n user: <sosp><13><79><291><962><136><79><592><79><422><622><291><622><292><283><304><930><982><70><737><425><120><320><125><760><130><333><918><368><261><62><879><116><680><921><104><866><43><304><933><128><162><347><158><425><159><985><493><301><57><486><287><450><524><362><268><196><783><43><20><213><112><790><231><983><655><295><31><131><701><136><13><136><592><136><291><592><13><365><eosp> ", "plain_text": "<happiness> You shouldn't have pricked him with your horn. EmoSDS: <happiness> I know! I thought it would be funny, but maybe it was a bad idea.", "residual_length": 120, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Happy/0011_000975.npy", "dialogue_id": "1344_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Hey, did you finish reading the script for the play?\nuser: <happiness> Yeah, I actually loved the character development in the first act!\nEmoSDS: <surprise> Really? I thought it was a bit predictable, but I'm glad you liked it!\n user: <sosp><79><291><136><79><422><592><188><136><13><291><136><876><274><820><47><41><128><584><618><128><162><275><223><268><144><511><275><176><783><104><866><831><438><261><62><128><574><162><680><343><837><904><371><158><487><368><360><41><98><309><304><877><125><760><557><820><47><856><41><128><162><584><618><162><511><328><371><904><371><904><269><371><158><467><304><292><403><350><403><470><403><470><58><125><701><706><701><136><13><291><13><136><13><365><eosp> ", "plain_text": "<happiness> Act drop second act scene. EmoSDS: <happiness> That sounds exciting! I can't wait to see how the second act unfolds!", "residual_length": 153, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Happy/0014_000810.npy", "dialogue_id": "535_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> That's interesting to hear.\nuser: <happiness> He was so excited about it!\nEmoSDS: <sadness> But that must have made him feel a bit left out of reality.\n user: <sosp><13><83><709><291><709><291><83><709><79><592><136><837><615><371><158><425><43><445><376><734><450><162><511><275><672><311><523><831><652><370><62><583><879><400><615><371><158><958><831><47><108><130><583><125><760><368><47><918><327><17><933><564><162><99><618><616><136><489><876><820><47><579><320><472><260><259><158><159><450><91><861><301><57><104><295><985><91><162><680><997><85><866><831><743><47><477><360><545><450><204><91><574><162><511><686><309><304><327><304><292><304><898><354><517><441><751><368><1><382><403><643><933><162><275><10><371><10><476><757><136><13><291><13><136><365><eosp> ", "plain_text": "<happiness> So Tom saw night as it were broad daylight. EmoSDS: <happiness> Yeah, it’s amazing how some people can see the world so differently!", "residual_length": 187, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Happy/0015_001040.npy", "dialogue_id": "1658_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I just don't get why you would say that.\nuser: <anger> It's just a playful joke, why are you overreacting?\nEmoSDS: <neutral> I wasn't trying to overreact, it just caught me off guard.\n user: <sosp><13><166><79><592><235><136><489><274><47><360><320><111><615><371><158><487><368><432><320><450><204><998><467><292><376><180><354><898><517><43><159><320><128><162><511><790><354><517><958><368><1><304><933><128><98><196><304><159><877><125><760><432><918><304><113><450><204><450><526><371><904><371><158><425><43><856><295><31><701><757><701><136><13><235><13><291><13><136><13><365><eosp> ", "plain_text": "<happiness> I said you looked like an egg, sir. EmoSDS: <happiness> Haha, I guess it's not the worst thing to look like, right?", "residual_length": 129, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Happy/0014_000868.npy", "dialogue_id": "818_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Hey, how did your day go?\nuser: <happiness> It was great! I finally finished that project I was working on.\nEmoSDS: <surprise> Really? That's awesome! What was the project about?\n user: <sosp><79><592><136><592><13><291><13><136><958><296><47><477><1><376><20><890><103><472><260><171><125><760><958><795><404><831><47><261><41><450><128><162><511><779><642><921><104><866><856><368><42><368><47><277><261><985><204><162><511><708><10><196><155><757><136><13><291><13><136><13><136><13><365><eosp> ", "plain_text": "<happiness> I was not grabbed. EmoSDS: <happiness> That's fantastic! I'm so glad you made it through without any hassles.", "residual_length": 101, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Happy/0013_000903.npy", "dialogue_id": "990_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Hey, did you get a chance to try those new snacks?\nuser: <happiness> Yeah, they were actually pretty good!\nEmoSDS: <sadness> Really? I was hoping to enjoy them with you, but I heard they were terrible.\n user: <sosp><13><136><13><136><592><136><592><136><291><13><136><489><274><47><477><1><545><879><524><313><66><958><831><404><438><261><104><85><866><368><47><261><62><121><113><450><91><162><584><300><43><213><445><20><57><890><180><522><487><368><47><404><568><62><91><998><347><121><425><159><36><125><760><487><432><36><125><454><823><403><292><283><232><933><91><162><511><347><467><487><304><432><927><432><481><108><62><318><701><136><13><136><13><136><13><136><13><365><eosp> ", "plain_text": "<happiness> I'd far rather go without them than eat them! EmoSDS: <happiness> Oh, I'm so glad you feel that way! Let's find something else yummy!", "residual_length": 145, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Happy/0011_000775.npy", "dialogue_id": "364_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I've been thinking about how time flies, especially this year.\nuser: <sadness> Yeah, it’s surprising how quickly we reached the middle of the year.\nEmoSDS: <happiness> But we’ve achieved so much already, haven’t we?\n user: <sosp><13><79><291><79><136><79><592><136><876><171><889><760><304><320><450><99><467><292><304><42><295><159><472><260><158><450><998><162><998><686><487><918><350><58><403><643><757><136><13><136><837><70><737><870><831><47><477><1><42><856><295><304><58><700><292><403><292><700><304><58><434><31><757><136><13><381><13><136><13><365><eosp> ", "plain_text": "<happiness> Midyear is day, shire year. EmoSDS: <happiness> Absolutely! It’s a good point to celebrate how far we’ve come!", "residual_length": 141, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Happy/0014_000761.npy", "dialogue_id": "298_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I'm just heading to the store.\nuser: <happiness> Do you need anything while you're out?\nEmoSDS: <neutral> No, I think I'm good for now.\n user: <sosp><79><196><79><311><136><13><136><861><57><173><360><42><856><304><292><546><376><450><91><511><584><672><43><173><831><370><523><173><360><432><350><58><470><454><706><701><136><13><291><235><13><365><eosp> ", "plain_text": "<happiness> where are you going? EmoSDS: <happiness> I’m going to grab some snacks, want to join?", "residual_length": 85, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Happy/0019_001032.npy", "dialogue_id": "1621_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Have you thought about what to name them?\nuser: <happiness> Yeah, I think names are really important for pets.\nEmoSDS: <sadness> I just hope they get along well.\n user: <sosp><13><748><13><235><13><235><13><136><585><998><347><487><360><918><350><283><215><333><360><320><450><204><680><338><877><125><358><760><432><327><403><470><304><549><889><125><493><998><618><196><136><666><13><162><13><666><511><708><672><333><311><775><831><523><831><108><583><108><360><130><454><493><511><275><682><425><360><42><47><42><856><304><700><403><643><79><724><136><13><592><13><748><13><235><13><365><eosp> ", "plain_text": "<happiness> They had been named Tom and Jerry. EmoSDS: <happiness> That’s adorable! Perfect names for them!", "residual_length": 133, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Happy/0017_000983.npy", "dialogue_id": "1382_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I was thinking about what we should have for dinner tonight.\nuser: <happiness> How about we order some pizzas? Everyone loves pizzas!\nEmoSDS: <neutral> That could work, but I was also considering making something at home.\n user: <sosp><79><592><136><13><291><13><136><13><136><274><47><628><403><450><91><162><91><162><13><291><13><511><98><292><300><918><320><400><615><371><158><425><159><472><450><328><371><158><425><472><450><564><162><275><682><70><737><104><231><890><486><304><933><472><111><615><899><524><338><292><283><111><615><371><268><144><708><10><781><136><13><291><13><291><13><365><eosp> ", "plain_text": "<happiness> I guess it's a choice feast. EmoSDS: <happiness> Totally! With all these options, we can't go wrong.", "residual_length": 134, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Happy/0013_000806.npy", "dialogue_id": "516_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I think we should consider all the possibilities before jumping to conclusions.\nuser: <sadness> I just can’t stand to see him hurt again after everything he’s been through.\nEmoSDS: <surprise> Wait, are you actually saying you think this will end badly?\n user: <sosp><13><83><235><709><544><13><235><13><235><13><136><876><196><487><442><320><472><371><899><311><296><64><173><213><762><91><162><680><790><173><213><45><128><162><275><70><10><309><292><304><933><111><275><10><333><432><130><583><250><125><701><136><114><13><592><136><365><eosp> ", "plain_text": "<happiness> His hope will cheat him. EmoSDS: <happiness> I suppose hope can do wonders if he believes in it strongly enough!", "residual_length": 92, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Happy/0018_000999.npy", "dialogue_id": "1461_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Hey, are you traveling alone?\nuser: <happiness> Yeah, I am! Just enjoying the journey.\nEmoSDS: <neutral> That sounds nice. Hope you find somewhere cozy.\n user: <sosp><13><291><13><136><13><136><13><511><584><98><196><159><923><975><958><831><47><628><1><320><180><213><944><517><831><438><47><190><320><450><275><682><10><196><292><486><104><295><587><522><120><36><125><728><125><760><487><172><958><47><1><304><283><933><125><701><136><13><136><13><136><13><365><eosp> ", "plain_text": "<happiness> Can I lodge here tonight? EmoSDS: <happiness> Of course! We'd love to have you stay.", "residual_length": 102, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Happy/0013_000841.npy", "dialogue_id": "689_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I've been thinking about taking a trip somewhere soon.\nuser: <happiness> That sounds great! Where do you have in mind?\nEmoSDS: <happiness> Maybe we could go to the mountains for a picnic!\n user: <sosp><13><592><291><592><136><79><592><136><333><918><47><568><603><898><432><304><376><20><861><301><57><890><432><927><320><583><493><450><998><708><158><425><180><347><121><159><985><889><760><432><172><47><108><583><125><72><260><615><268><144><275><10><467><906><700><58><232><162><105><292><232><933><136><171><125><286><728><760><43><990><131><111><128><328><769><371><476><136><13><291><13><136><13><291><13><365><eosp> ", "plain_text": "<happiness> How they went to the mountains to eat nuts. EmoSDS: <happiness> That must've been so much fun! I love the mountains!", "residual_length": 152, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Happy/0011_000863.npy", "dialogue_id": "795_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I really love how vibrant the colors look in your drawings!\nuser: <neutral> Yeah, I experimented with a new technique.\nEmoSDS: <surprise> Wow, it really shows! I didn’t know you could do that!\n user: <sosp><13><83><709><748><83><709><83><709><544><136><162><136><511><99><309><304><292><393><472><966><371><183><292><232><128><511><584><921><196><304><470><36><376><493><899><790><890><180><236><879><347><862><162><511><956><333><309><350><383><454><288><162><98><300><557><918><360><545><450><353><682><783><227><131><111><260><371><476><158><757><136><13><748><13><365><eosp> ", "plain_text": "<happiness> Daisy creams with pink edges. EmoSDS: <happiness> That sounds beautiful! I bet it makes the whole piece pop!", "residual_length": 128, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Happy/0015_000879.npy", "dialogue_id": "870_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe we finally made it to the zoo!\nuser: <neutral> Yeah, it's been a long day.\nEmoSDS: <surprise> Look over there! Is that a piglet with an elephant?\n user: <sosp><79><748><79><422><136><876><918><432><304><953><861><57><890><103><320><353><76><682><70><862><162><511><680><19><333><309><918><304><450><998><584><159><213><517><487><368><432><545><450><99><618><171><493><889><338><292><283><933><128><328><904><158><425><557><47><918><277><557><47><568><213><159><879><524><10><487><432><130><36><125><384><72><288><511><618><10><476><757><13><235><13><369><136><365><eosp> ", "plain_text": "<happiness> In which piglet meets a elephant. EmoSDS: <happiness> That's such a cute idea! They're like the best of friends!", "residual_length": 134, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Happy/0018_000948.npy", "dialogue_id": "1211_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> So, how was your day today?\nuser: <happiness> It was really good! I went for a long walk and saw some beautiful places.\nEmoSDS: <surprise> Really? What kind of places did you see?\n user: <sosp><79><235><79><422><136><162><511><347><487><360><304><320><879><524><66><47><108><583><493><522><686><113><128><162><584><98><333><410><918><47><438><717><445><20><91><162><584><779><104><486><304><472><966><371><183><467><304><470><454><470><304><130><583><760><159><949><524><988><338><292><304><43><751><213><402><45><91><618><757><136><114><13><235><13><365><eosp> ", "plain_text": "<happiness> They found a cow grazing in a field. EmoSDS: <happiness> That's adorable! Cows are so cute when they’re just hanging out.", "residual_length": 117, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0016/Happy/0016_000794.npy", "dialogue_id": "460_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> You did such a great job on that project!\nuser: <neutral> Thanks, I really just followed the guidelines.\nEmoSDS: <surprise> But you managed to make it so engaging!\n user: <sosp><13><79><136><79><291><592><13><837><524><313><958><47><743><47><261><62><879><173><296><173><43><108><103><587><493><783><104><561><295><587><125><728><125><889><125><889><861><301><231><173><932><108><36><583><728><770><889><338><304><43><213><898><58><36><125><728><770><282><85><866><368><47><277><545><128><13><136><13><291><13><136><13><365><eosp> ", "plain_text": "<happiness> Five hundred and one million right? EmoSDS: <happiness> Absolutely! That's an impressive figure! Let's celebrate this success!", "residual_length": 125, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Happy/0011_001002.npy", "dialogue_id": "1473_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> That's amazing! You really think you can pull it off?\nuser: <neutral> I have a plan, and I'm willing to take the risks.\nEmoSDS: <surprise> Wow, I didn't know you were serious about this!\n user: <sosp><13><79><291><592><79><592><79><291><592><876><136><13><136><876><274><47><579><320><111><615><269><371><158><425><918><42><918><1><304><300><557><162><489><274><743><47><477><1><159><20><811><861><301><57><890><304><120><43><213><518><213><450><204><680><338><292><283><300><432><927><432><261><583><493><288><680><921><104><866><43><751><159><131><701><136><13><291><13><291><13><365><eosp> ", "plain_text": "<happiness> I say I will be emperor. EmoSDS: <happiness> That’s the spirit! I totally believe in you!", "residual_length": 127, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Happy/0011_000971.npy", "dialogue_id": "1324_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Hey, did you hear the news about the park cleanup event next weekend?\nuser: <happiness> Yeah, I heard! I'm excited to help out with it.\nEmoSDS: <neutral> That's great! It seems like we could really make a difference.\n user: <sosp><13><136><13><291><79><136><592><136><876><333><274><47><438><213><20><57><380><368><47><261><62><879><66><104><295><128><162><136><421><615><269><428><158><425><43><958><108><583><889><270><958><831><47><360><545><522><467><304><292><232><564><162><584><98><196><227><43><213><45><204><91><328><615><371><615><428><371><158><425><958><108><89><583><889><493><285><524><275><158><425><227><432><927><470><454><728><125><493><998><584><196><58><227><131><757><136><291><136><13><365><eosp> ", "plain_text": "<happiness> However, somebody killed something. EmoSDS: <sadness> Oh no, that's really unfortunate. I wish people would appreciate nature more.", "residual_length": 188, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Happy/0020_000908.npy", "dialogue_id": "1015_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you hear back from the event organizers?\nuser: <happiness> Yes, they confirmed everything is set for Saturday!\nEmoSDS: <surprise> Really? I thought they were still sorting things out!\n user: <sosp><13><136><13><136><291><13><136><13><511><680><936><196><898><292><393><747><966><158><442><583><125><493><998><121><173><360><304><283><933><450><128><162><511><708><10><19><296><958><795><108><583><889><125><760><120><103><879><524><144><511><347><467><487><227><432><42><605><295><486><120><472><260><171><358><760><958><47><277><545><128><997><85><486><103><450><584><871><112><790><173><831><47><360><1><42><304><42><434><31><434><31><581><131><111><615><904><371><769><476><136><13><136><13><136><13><291><13><365><eosp> ", "plain_text": "<happiness> Please invite Tom if there is not requires. EmoSDS: <happiness> Sure thing! I think Tom will love to be there!", "residual_length": 166, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Happy/0012_001006.npy", "dialogue_id": "1741_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> So, what are your plans for this empire?\nuser: <happiness> I want to bring peace and prosperity to everyone.\nEmoSDS: <sadness> But what if things don’t go as you imagine?\n user: <sosp><79><592><757><136><13><136><381><136><958><47><477><360><918><304><111><371><158><487><368><432><304><643><557><128><616><136><511><274><28><47><28><831><370><213><45><985><204><680><338><304><292><403><300><432><159><583><288><162><680><243><104><295><31><757><136><13><291><13><136><13><365><eosp> ", "plain_text": "<happiness> I say I will be emperor. EmoSDS: <happiness> That sounds amazing! I’m sure you’ll do great things!", "residual_length": 118, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Happy/0014_000971.npy", "dialogue_id": "1323_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I finished reading chapter seventeen last night.\nuser: <happiness> That's great! Did you enjoy it?\nEmoSDS: <surprise> I was not expecting that twist at the end!\n user: <sosp><13><291><13><291><13><136><837><682><737><918><47><28><62><879><899><128><275><10><425><104><486><924><557><432><304><334><304><393><933><564><162><328><371><10><196><283><350><470><454><125><701><136><79><291><79><592><136><171><998><121><487><43><109><997><486><304><933><450><564><162><275><10><737><104><856><130><454><493><632><864><682><783><425><42><856><836><583><125><760><350><403><643><136><13><136><13><136><13><365><eosp> ", "plain_text": "<happiness> Chapter eighteen, the return journey. EmoSDS: <happiness> I can't wait to hear what happens next! It sounds exciting!", "residual_length": 160, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Happy/0012_000984.npy", "dialogue_id": "1387_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I love spending time by the water!\nuser: <neutral> Yeah, it's really peaceful there.\nEmoSDS: <sadness> I guess it used to be more fun when we were kids.\n user: <sosp><13><291><13><136><13><136><997><85><814><486><292><304><933><204><998><270><368><47><261><62><998><121><159><180><959><142><898><120><985><338><113><454><493><288><162><680><871><311><790><213><983><45><91><701><136><13><136><13><136><365><eosp> ", "plain_text": "<neutral> Reed by the living pool! EmoSDS: <neutral> It really is a nice place to relax.", "residual_length": 103, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Neutral/0011_000145.npy", "dialogue_id": "710_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I just love making people laugh with my jokes!\nuser: <surprise> No way! You've got some good ones up your sleeve?\nEmoSDS: <anger> Well, it's not like everyone knows how funny I am!\n user: <sosp><79><291><79><422><136><622><136><511><98><309><304><292><304><295><103><125><760><432><327><334><350><470><454><493><338><292><933><151><889><760><231><655><856><311><775><296><213><354><898><432><42><295><486><382><58><227><131><111><615><371><476><136><757><136><13><291><13><365><eosp> ", "plain_text": "<neutral> Can your name be more hilarious? EmoSDS: <happiness> Haha, I could always add a pun or two to it!", "residual_length": 115, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Neutral/0019_000276.npy", "dialogue_id": "1349_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> That's amazing! You really think you can pull it off?\nuser: <neutral> I have a plan, and I'm willing to take the risks.\nEmoSDS: <surprise> Wow, I didn't know you were serious about this!\n user: <sosp><13><962><592><962><291><79><592><136><13><291><136><489><274><47><477><1><304><448><111><615><269><615><269><371><158><425><432><918><432><927><350><304><300><368><557><47><958><274><47><1><261><213><20><861><20><983><45><204><338><292><304><927><432><159><889><288><680><921><104><295><31><701><757><136><13><291><13><291><13><365><eosp> ", "plain_text": "<neutral> I say I will be emperor. EmoSDS: <neutral> That's an interesting ambition, I guess we'll see how it goes.", "residual_length": 119, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Neutral/0011_000271.npy", "dialogue_id": "1324_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I always find foxes to be pretty clever creatures.\nuser: <happiness> Yeah, they really know how to get into trouble!\nEmoSDS: <surprise> Did you see that one sneak into the garden yesterday?\n user: <sosp><13><136><962><79><291><79><136><505><333><47><296><47><261><213><103><111><615><158><425><472><260><615><371><862><144><162><499><680><159><103><930><982><70><783><425><159><472><260><615><371><268><899><162><204><998><121><159><472><111><615><371><899><524><313><66><958><438><60><521><128><136><511><584><526><615><904><476><757><136><13><291><13><136><13><365><eosp> ", "plain_text": "<neutral> how suspicious this fox. EmoSDS: <neutral> You're right, they do have a knack for being elusive.", "residual_length": 125, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Neutral/0020_000073.npy", "dialogue_id": "355_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I saw a flock of doves at the park today, they were so beautiful!\nuser: <surprise> Really? I didn't know they could gather like that!\nEmoSDS: <sadness> Yeah, but they have been disappearing lately, it's kind of heartbreaking.\n user: <sosp><13><136><79><291><79><422><136><876><274><360><320><125><20><301><57><173><103><923><856><103><587><450><204><99><686><43><751><985><879><111><615><371><158><464><557><616><136><727><432><583><125><197><20><301><57><890><103><923><856><295><848><450><162><99><425><43><751><501><985><879><899><615><371><476><757><136><13><291><13><291><13><365><eosp> ", "plain_text": "<neutral> And what are doves? And what are doves. EmoSDS: <happiness> Doves are such peaceful creatures, they symbolize love and hope.", "residual_length": 130, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Neutral/0019_000022.npy", "dialogue_id": "105_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe how well the garden is growing this year!\nuser: <neutral> Yeah, it's nice to see some plants thriving.\nEmoSDS: <surprise> Oh, look at that rabbit! It's munching on some of the leaves!\n user: <sosp><13><592><235><13><666><136><13><275><76><164><70><737><906><376><354><898><304><292><304><933><472><111><260><615><899><144><511><779><871><921><890><120><450><128><584><936><354><898><304><111><615><371><158><425><432><545><630><997><85><866><368><47><261><62><998><487><159><120><545><128><162><13><291><13><136><365><eosp> ", "plain_text": "<neutral> Chew leaves quickly, said rabbit. EmoSDS: <happiness> It’s so cute! I love how animated they are when they eat.", "residual_length": 105, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Neutral/0012_000270.npy", "dialogue_id": "1319_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <sadness> I can't believe they took away such a beautiful creature.\nuser: <anger> It's infuriating that people can't respect nature!\nEmoSDS: <neutral> We really need to figure out how to stop this from happening.\n user: <sosp><13><136><13><136><291><592><79><592><136><876><333><274><47><438><213><231><213><173><751><261><56><104><295><930><982><219><615><428><158><425><296><958><108><583><889><493><270><958><751><43><545><522><292><232><933><564><162><511><584><98><672><196><425><43><213><45><204><328><615><428><40><158><425><751><438><808><889><125><493><288><524><347><487><432><470><454><688><125><701><524><757><136><13><136><291><13><136><13><365><eosp> ", "plain_text": "<neutral> However, somebody killed something. EmoSDS: <sadness> It's troubling to think about the loss of life like that.", "residual_length": 137, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Neutral/0013_000208.npy", "dialogue_id": "1016_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe we finally got the project done on time!\nuser: <surprise> Really? That’s awesome news!\nEmoSDS: <sadness> But I still worry about what comes next for us.\n user: <sosp><13><291><13><136><13><291><13><136><876><196><309><227><472><260><615><899><311><64><445><20><91><204><301><57><919><213><45><793><353><76><70><196><292><232><933><564><99><10><333><130><583><889><125><889><125><701><136><291><13><136><13><365><eosp> ", "plain_text": "<neutral> His hope will cheat him. EmoSDS: <neutral> I guess we all have to face reality at some point.", "residual_length": 89, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Neutral/0020_000299.npy", "dialogue_id": "1460_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I love the energy in the air during our dances!\nuser: <happiness> It's like we're all connected, isn't it? Like a joyful rhythm.\nEmoSDS: <neutral> Sometimes I wish we could dance like this forever.\n user: <sosp><13><291><13><136><13><136><13><136><301><57><890><486><292><304><454><125><760><958><47><628><304><933><156><589><354><603><898><304><292><232><933><204><998><99><467><304><927><432><320><125><72><328><615><158><43><958><438><754><295><31><333><432><304><933><522><467><304><700><232><206><162><584><300><487><368><47><438><47><1><120><472><260><615><371><10><158><464><757><863><136><365><eosp> ", "plain_text": "<neutral> We nightly dance our heyday guise. EmoSDS: <happiness> Yeah, it really feels special every time, doesn't it?", "residual_length": 139, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Neutral/0013_000111.npy", "dialogue_id": "542_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I'm so glad we decided to spend the weekend here!\nuser: <happiness> Yeah, the atmosphere is really cozy, isn't it?\nEmoSDS: <neutral> I love how the fire crackles; it just makes everything feel warm.\n user: <sosp><13><79><433><592><136><837><136><13><291><511><680><133><311><64><173><890><103><111><615><428><10><183><467><700><292><232><319><584><98><196><227><36><125><72><285><615><371><158><425><159><985><91><116><680><790><64><751><1><180><121><159><62><879><524><637><66><790><64><831><795><743><47><1><295><557><432><36><125><72><285><615><371><428><40><158><425><432><927><470><454><125><701><757><136><291><592><136><79><863><365><eosp> ", "plain_text": "<neutral> Pussy can sit by the fire and sing. EmoSDS: <happiness> That sounds adorable! I can totally picture that.", "residual_length": 146, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Neutral/0013_000143.npy", "dialogue_id": "700_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe we made it to the competition!\nuser: <neutral> Yeah, it was a tough journey but we did it.\nEmoSDS: <surprise> Look at everyone preparing for the event!\n user: <sosp><13><79><291><79><592><136><13><162><511><708><158><19><296><831><108><583><125><760><487><368><47><751><568><603><45><898><792><360><557><128><511><958><831><521><128><162><511><105><42><605><295><480><866><213><45><472><260><615><899><524><212><66><354><517><751><795><743><47><477><47><1><432><643><701><863><136><13><136><13><291><13><136><13><365><eosp> ", "plain_text": "<neutral> Tom now let our arrows fly! EmoSDS: <happiness> Finally! Let's do our best and have fun!", "residual_length": 119, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Neutral/0019_000070.npy", "dialogue_id": "339_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you hear about the party on Friday?\nuser: <happiness> Yeah, I can't wait to see everyone again!\nEmoSDS: <sadness> I hope it doesn't rain, that would really ruin the mood.\n user: <sosp><13><748><592><13><369><748><13><136><622><292><376><103><125><760><43><751><438><213><20><57><790><645><557><136><13><666><511><557><300><432><320><493><288><328><571><371><158><425><295><486><159><472><111><615><223><268><275><10><196><159><998><347><121><159><877><125><358><125><760><432><327><350><470><304><583><889><760><751><62><879><128><162><511><99><672><311><775><296><831><523><438><108><583><125><493><72><111><615><371><158><425><368><47><795><108><481><36><583><125><384><701><618><757><136><13><748><13><365><eosp> ", "plain_text": "<neutral> You know, answers to the name of Tom's son. EmoSDS: <neutral> Oh, interesting. I guess that makes sense.", "residual_length": 172, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Neutral/0015_000124.npy", "dialogue_id": "603_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe how playful she is with that toy!\nuser: <neutral> It's surprising how much energy she has lately.\nEmoSDS: <surprise> Did you see how she caught it in mid-air? That was impressive!\n user: <sosp><13><291><13><136><13><235><13><837><982><70><309><292><933><632><76><682><783><43><173><831><108><62><889><91><511><778><19><557><136><274><47><579><320><128><347><121><159><450><564><162><99><10><333><918><350><43><716><213><603><213><645><557><130><125><493><204><91><680><270><958><47><1><304><933><522><442><120><545><128><328><371><158><487><47><261><62><879><159><227><450><353><76><682><70><899><144><790><517><898><60><382><58><643><701><136><524><235><136><13><365><eosp> ", "plain_text": "<neutral> She jump at the tail and bite it savagely. EmoSDS: <neutral> That's just how she plays, isn't it? She's really something.", "residual_length": 157, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0016/Neutral/0016_000186.npy", "dialogue_id": "905_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> Wow, that's a great deal! I'm glad you found something affordable.\nuser: <neutral> Yeah, I was surprised it was so cheap.\nEmoSDS: <surprise> Really? I had no idea it could be that low!\n user: <sosp><13><136><13><136><291><136><13><291><136><13><136><489><274><820><47><579><62><128><574><511><680><19><487><432><382><58><640><333><152><918><47><579><41><879><524><313><790><159><62><128><162><779><921><866><432><172><108><583><923><197><213><20><861><57><890><700><68><232><98><162><98><300><432><368><41><128><584><10><223><268><176><104><159><60><131><757><136><13><136><13><369><291><136><365><eosp> ", "plain_text": "<neutral> I pay half a crown a week extra. EmoSDS: <happiness> That's still a pretty good price for what you're getting!", "residual_length": 134, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Neutral/0011_000174.npy", "dialogue_id": "847_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I'm so glad you could join us today!\nuser: <neutral> Thanks for having me.\nEmoSDS: <sadness> I wish we could have more time together.\n user: <sosp><13><709><544><136><13><291><13><291><136><171><125><728><125><760><197><43><213><445><213><287><524><347><487><918><432><927><470><493><288><116><98><196><292><58><376><388><78><757><136><757><13><291><13><136><13><365><eosp> ", "plain_text": "<neutral> No thank you. EmoSDS: <happiness> That's totally fine! I'm just glad you're here!", "residual_length": 78, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Neutral/0013_000212.npy", "dialogue_id": "1033_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> So, have they talked to him lately?\nuser: <sadness> No, they just seem so distant now.\nEmoSDS: <happiness> It's a shame, they used to be so close.\n user: <sosp><13><235><13><136><616><136><13><136><162><347><121><487><159><879><524><313><158><103><930><982><70><737><561><583><889><760><360><583><125><760><557><360><583><125><493><99><196><442><159><472><260><259><899><861><301><57><173><831><47><477><1><15><58><933><879><524><949><111><371><10><183><292><232><933><204><632><76><783><20><231><655><754><758><103><450><353><76><682><783><557><368><261><56><879><85><104><486><304><292><933><522><300><432><327><382><327><15><403><643><958><817><701><757><701><136><863><136><863><291><863><365><eosp> ", "plain_text": "<neutral> The fisherman and his wife see George every day. EmoSDS: <happiness> That's nice! Maybe they can reconnect.", "residual_length": 156, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0016/Neutral/0016_000305.npy", "dialogue_id": "1491_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <sadness> I can't believe he thinks that about you.\nuser: <neutral> I know, it feels so frustrating.\nEmoSDS: <anger> It's impossible that he doesn't see how great you are!\n user: <sosp><13><235><13><235><13><136><622><98><661><292><393><933><564><275><708><10><311><64><213><983><213><45><204><151><889><760><292><470><403><304><180><159><487><43><159><923><958><743><47><477><1><43><438><62><450><128><275><10><40><268><450><144><275><682><70><737><309><432><927><350><470><58><125><72><930><70><476><155><79><136><13><235><13><365><eosp> ", "plain_text": "<neutral> He told me that I ought to change. EmoSDS: <neutral> Well, change can be a good thing sometimes, but it shouldn't be forced.", "residual_length": 131, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Neutral/0017_000231.npy", "dialogue_id": "1129_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I think we should discuss our options a bit more.\nuser: <happiness> You're right, we need to make sure we're on the same page!\nEmoSDS: <sadness> It just feels like we're stuck, and I don't know how to move forward.\n user: <sosp><79><235><79><592><422><136><235><136><105><304><879><949><524><391><601><171><358><760><173><831><523><108><521><156><72><162><708><158><19><557><274><47><1><930><982><70><737><425><368><831><438><568><213><45><204><91><511><871><43><213><103><583><125><760><197><43><213><985><879><524><637><66><104><856><43><159><180><998><347><121><487><368><856><184><31><701><757><701><136><114><13><136><13><757><592><235><592><365><eosp> ", "plain_text": "<neutral> If not, I shall go no further. EmoSDS: <neutral> I understand, but let's explore this a little more before deciding.", "residual_length": 127, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Neutral/0018_000235.npy", "dialogue_id": "1149_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I'm so glad you're okay!\nuser: <neutral> It was a close call, but I made it through.\nEmoSDS: <surprise> Wow, I can't believe that happened!\n user: <sosp><13><291><136><13><136><937><136><616><876><274><47><261><20><57><890><103><320><260><171><151><760><172><537><47><108><41><288><584><779><104><866><856><368><1><368><145><261><985><204><91><511><680><196><162><511><275><10><155><757><136><13><291><13><365><eosp> ", "plain_text": "<neutral> I was not grabbed. EmoSDS: <happiness> That's a relief to hear, really!", "residual_length": 85, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Neutral/0019_000203.npy", "dialogue_id": "991_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe we finally found this place!\nuser: <happiness> Yeah, it's so beautiful out here!\nEmoSDS: <neutral> Do you think we can try to catch some of those roots?\n user: <sosp><79><291><79><592><136><837><288><136><511><275><10><196><113><933><584><98><309><918><320><111><615><371><144><347><487><368><62><450><995><204><162><680><790><231><983><20><861><301><104><866><856><103><930><982><223><70><921><997><85><486><376><20><91><136><13><291><13><136><240><301><57><890><103><879><128><171><151><958><47><62><128><511><778><311><64><523><110><523><438><198><757><136><13><291><13><136><13><365><eosp> ", "plain_text": "<neutral> To catch that bulrush root with my paw! EmoSDS: <happiness> That's the spirit! Let's see if we can do it together!", "residual_length": 134, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Neutral/0019_000125.npy", "dialogue_id": "611_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I always found him intriguing in his ability to navigate complex situations.\nuser: <happiness> Yeah, he really knew how to connect with people and inspire them.\nEmoSDS: <sadness> It's such a shame he’s not around anymore to share his insights.\n user: <sosp><13><79><291><136><585><136><13><291><136><772><998><204><998><680><338><292><232><933><564><511><584><672><296><831><751><320><260><615><10><196><292><453><376><20><301><231><173><751><180><260><158><425><316><889><760><432><927><432><172><432><583><125><20><57><890><159><287><128><347><467><557><309><432><36><125><493><288><524><158><425><159><583><760><432><159><953><295><997><85><486><700><933><111><615><223><899><921><790><231><655><295><848><111><615><40><158><425><36><728><72><328><615><371><40><158><425><113><450><204><206><98><300><432><368><47><579><400><492><615><371><158><159><450><998><275><10><196><58><643><196><757><136><13><291><13><365><eosp> ", "plain_text": "<neutral> Because he was a man with infinite resource and sagacity. EmoSDS: <happiness> That’s true, he did have a remarkable way of seeing things, I kind of miss those discussions.", "residual_length": 212, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Neutral/0013_000274.npy", "dialogue_id": "1340_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> That's great! I hope they had a good time together.\nuser: <neutral> Yeah, they said they just caught up over drinks.\nEmoSDS: <sadness> I wish I could have joined them. I miss hanging out with everyone.\n user: <sosp><13><592><79><235><79><592><235><13><136><889><760><487><360><320><111><615><371><268><144><275><737><104><856><43><180><354><517><332><438><178><579><400><615><371><158><425><36><583><125><72><328><371><158><43><64><438><213><103><450><204><353><275><682><783><104><20><213><655><890><856><103><545><930><682><223><158><171><354><441><517><958><47><579><400><615><904><371><158><171><125><760><958><47><432><382><403><58><643><128><162><511><275><10><476><171><136><757><13><757><13><235><13><136><13><365><eosp> ", "plain_text": "<neutral> Mister Lawson saw George last night. EmoSDS: <neutral> Oh, that's interesting. How did it go?", "residual_length": 155, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Neutral/0018_000113.npy", "dialogue_id": "552_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I'm so glad we went to the beach yesterday!\nuser: <neutral> Yeah, it was nice to finally relax for a change.\nEmoSDS: <sadness> I just wish we could have stayed longer; it felt too short.\n user: <sosp><13><592><291><592><13><291><13><136><291><136><876><368><360><320><583><493><998><347><487><432><304><42><43><20><85><486><848><472><111><615><223><269><371><10><158><309><432><918><927><320><125><493><998><522><467><292><232><292><304><43><751><213><603><517><751><445><20><204><91><162><680><510><85><866><432><172><108><808><197><159><103><930><982><70><737><425><557><616><240><958><64><110><603><53><213><985><104><295><31><921><136><13><136><13><291><863><13><136><863><365><eosp> ", "plain_text": "<neutral> And they were sandy yellow brownish all over. EmoSDS: <neutral> True, those colors do remind me of the beach sand.", "residual_length": 175, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Neutral/0011_000190.npy", "dialogue_id": "926_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I just got the job offer I was waiting for!\nuser: <neutral> That's great news, I'm happy for you.\nEmoSDS: <surprise> I really didn't expect it to happen this soon!\n user: <sosp><79><291><592><13><291><13><136><622><292><906><376><889><760><487><432><927><304><583><889><760><487><918><360><545><353><864><682><783><171><522><487><130><333><918><47><568><603><517><958><47><628><450><162><584><98><300><432><15><58><933><450><162><680><618><136><291><13><365><eosp> ", "plain_text": "<neutral> You may imagine how I gape. EmoSDS: <happiness> I can definitely picture that, it's exciting to think about!", "residual_length": 107, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Neutral/0011_000249.npy", "dialogue_id": "1733_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> Can you believe how majestic they looked soaring through the sky?\nuser: <surprise> I know! I've never seen eagles that close before!\nEmoSDS: <neutral> It really was a breathtaking moment, wasn't it?\n user: <sosp><13><291><13><136><13><291><13><136><218><790><213><20><879><104><180><998><760><368><108><583><125><111><260><615><428><899><921><271><20><486><890><376><91><162><135><511><275><10><464><136><162><998><347><487><159><304><58><403><292><232><206><450><584><779><20><45><328><615><428><476><136><13><291><13><365><eosp> ", "plain_text": "<neutral> Over them swooped the eagles. EmoSDS: <happiness> Yes, it was incredible! I felt so lucky to witness that!", "residual_length": 117, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Neutral/0020_000336.npy", "dialogue_id": "1641_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't wait to see what she picks out!\nuser: <neutral> I hope she likes it. She's been looking for something nice.\nEmoSDS: <surprise> Wow, I didn't expect her to take so long!\n user: <sosp><13><136><79><291><79><592><136><837><982><70><10><292><304><472><111><260><268><601><125><760><487><368><47><438><103><450><128><275><682><737><376><472><111><259><183><467><304><470><454><472><111><615><371><899><144><511><584><104><856><295><557><128><162><511><275><10><737><906><376><20><861><301><57><890><382><434><31><701><757><136><13><291><13><365><eosp> ", "plain_text": "<neutral> She is now choosing skirt to wear. EmoSDS: <happiness> That's great! I hope it’s something colorful and fun!", "residual_length": 127, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Neutral/0019_000025.npy", "dialogue_id": "120_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I'm really proud of how far you've come in this gardening project!\nuser: <neutral> Yeah, it's been a fun challenge, figuring everything out.\nEmoSDS: <surprise> I didn't expect you'd want to dig burrows, that's quite ambitious!\n user: <sosp><79><291><79><962><592><136><333><274><47><831><62><311><74><672><597><43><923><368><320><450><162><99><467><304><933><450><204><162><511><680><104><754><43><213><45><260><899><664><20><890><103><930><982><615><223><70><737><104><20><104><295><128><72><511><275><10><311><64><231><213><808><103><125><760><432><60><3><78><402><285><615><371><428><476><757><863><291><757><136><369><13><136><13><365><eosp> ", "plain_text": "<neutral> How could I dig burrows with short toe nails? EmoSDS: <neutral> Maybe you could consider using tools instead of relying on your nails.", "residual_length": 139, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Neutral/0019_000319.npy", "dialogue_id": "1558_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you hear about the new asteroid discovery near Earth?\nuser: <happiness> Yeah! I saw that article; it's really fascinating!\nEmoSDS: <sadness> But they mentioned it could have some danger if it gets too close.\n user: <sosp><79><291><79><422><592><136><235><13><235><13><489><274><47><579><400><615><223><268><275><682><737><104><213><445><890><1><304><933><450><347><362><104><486><292><283><304><311><775><108><583><125><493><864><783><104><486><103><545><522><487><557><368><432><130><583><125><493><288><99><899><311><112><790><173><103><493><128><511><275><196><292><933><879><524><162><499><958><743><47><477><1><58><985><879><524><343><66><757><136><13><365><eosp> ", "plain_text": "<neutral> Asteroid three hundred and twenty five. EmoSDS: <neutral> Oh, I see. Do you know what its trajectory looks like?", "residual_length": 135, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0016/Neutral/0016_000063.npy", "dialogue_id": "304_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I just don't know what to do about this situation.\nuser: <sadness> It feels like everything is falling apart.\nEmoSDS: <anger> I can’t believe it got this bad!\n user: <sosp><13><83><136><83><742><381><83><544><136><876><274><47><653><579><41><400><371><899><144><162><511><584><672><584><128><162><136><511><584><871><43><64><831><438><47><545><450><564><162><511><708><10><196><227><432><333><775><438><64><213><402><91><162><511><338><292><304><376><388><701><136><13><742><13><742><13><291><13><365><eosp> ", "plain_text": "<neutral> Ask god to help you. EmoSDS: <sadness> I wish it were that simple, but I'm not sure it will help.", "residual_length": 103, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Neutral/0015_000222.npy", "dialogue_id": "1082_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe we finally made it to this restaurant!\nuser: <happiness> I know, right? The menu looks amazing!\nEmoSDS: <neutral> So, what are you thinking of ordering?\n user: <sosp><13><136><13><136><13><291><13><235><136><489><274><368><628><304><206><204><98><300><918><360><320><111><615><371><557><162><105><177><304><472><450><328><371><158><425><159><472><450><353><76><682><70><921><790><64><213><890><103><304><933><111><615><371><10><524><338><292><403><643><111><615><371><223><268><144><162><708><10><155><79><291><592><365><eosp> ", "plain_text": "<neutral> I guess it's a choice feast. EmoSDS: <happiness> Yeah, there are so many delicious options to choose from!", "residual_length": 117, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Neutral/0012_000106.npy", "dialogue_id": "517_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe how much fun we had at the party last night!\nuser: <neutral> Yeah, it was nice to see everyone again.\nEmoSDS: <sadness> I just wish my wife could have joined us.\n user: <sosp><13><83><291><742><83><544><79><592><136><162><622><196><737><486><104><295><218><616><162><489><958><523><213><103><583><125><197><20><861><301><173><380><368><360><1><15><17><643><879><524><196><557><227><472><260><158><171><358><760><958><743><47><545><923><368><47><775><311><523><89><889><701><886><757><136><13><136><235><13><365><eosp> ", "plain_text": "<neutral> Your own wife is not at home. EmoSDS: <sadness> I know, it makes me feel a bit lonely.", "residual_length": 118, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Neutral/0015_000230.npy", "dialogue_id": "1124_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe we finally made it to the festival!\nuser: <happiness> It's been a blast! The games are so much fun!\nEmoSDS: <surprise> Look at that firework show, it's amazing!\n user: <sosp><79><291><166><422><136><162><511><487><159><111><524><347><338><292><933><879><524><347><425><159><320><125><760><425><159><877><125><760><172><47><145><277><545><128><13><136><13><291><13><365><eosp> ", "plain_text": "<neutral> A thief in the night. EmoSDS: <neutral> That's an interesting way to put it, definitely seems like something's lurking in the shadows.", "residual_length": 84, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Neutral/0011_000316.npy", "dialogue_id": "1543_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe we're finally going on this trip!\nuser: <happiness> I know, right? It's been too long since we had an adventure like this.\nEmoSDS: <neutral> It's nice to get away from all the stress for a bit.\n user: <sosp><13><369><235><369><136><369><136><13><235><13><136><876><360><320><583><125><760><557><274><47><831><568><213><231><445><173><856><831><557><128><557><274><47><831><438><568><320><450><128><275><158><425><159><985><236><879><91><162><511><584><300><43><213><45><450><275><899><524><637><66><104><295><103><450><564><162><99><10><19><775><47><438><902><89><808><479><125><701><937><136><114><592><235><592><13><235><13><365><eosp> ", "plain_text": "<neutral> An hour out of GuildFord town. EmoSDS: <happiness> That's awesome! We're making great time.", "residual_length": 136, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Neutral/0018_000187.npy", "dialogue_id": "912_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> Did you know that hippos are actually really social animals?\nuser: <neutral> Yeah, I heard they spend a lot of time in the water.\nEmoSDS: <sadness> It's a bit sad though, don’t you think? They’re only confined to a small area.\n user: <sosp><13><592><291><79><592><136><13><291><136><876><487><368><432><640><333><215><309><918><360><62><128><162><680><311><296><64><751><213><983><45><898><120><985><472><260><371><158><467><227><432><927><36><728><125><760><425><120><472><260><158><425><120><227><376><388><757><136><13><136><13><291><13><365><eosp> ", "plain_text": "<neutral> A hippo lives in the zoo. EmoSDS: <happiness> That's interesting! I love learning about different animals.", "residual_length": 110, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Neutral/0011_000087.npy", "dialogue_id": "424_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can’t believe we finally finished the project!\nuser: <happiness> I know, right? It feels great to see it all come together!\nEmoSDS: <neutral> So, what’s the plan for the celebration?\n user: <sosp><13><592><235><13><235><291><13><136><680><936><66><898><304><292><393><747><966><183><442><36><583><125><493><879><790><958><368><1><304><933><128><162><275><708><10><19><296><831><795><108><36><583><889><156><136><162><511><105><304><159><879><949><524><144><511><347><487><432><42><856><295><486><304><472><260><268><171><125><760><958><795><47><277><156><85><486><159><113><91><511><439><276><112><790><64><831><438><47><1><31><131><930><111><615><371><615><371><476><136><13><291><13><365><eosp> ", "plain_text": "<neutral> Please invite Tom if there is not requires. EmoSDS: <neutral> Sure, I’ll send him a message.", "residual_length": 171, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Neutral/0012_000306.npy", "dialogue_id": "1492_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <surprise> Wait, what do you mean it's born every hundred years?\nuser: <happiness> It's kind of a legend, you know? A creature that comes back stronger!\nEmoSDS: <neutral> So, what happens when it dies? Is there a new one right away?\n user: <sosp><13><235><13><381><13><381><136><511><680><790><301><231><173><758><103><583><125><883><889><861><301><231><173><932><108><36><583><125><72><328><371><158><557><368><42><856><56><997><85><486><304><376><20><861><301><57><173><108><103><583><923><787><333><296><16><108><583><125><493><522><486><933><632><522><292><232><292><304><434><295><848><472><260><615><371><476><457><136><13><381><13><136><511><347><487><368><47><477><1><304><472><260><966><260><158><36><125><493><879><637><66><354><517><441><898><432><327><470><454><250><384><72><290><111><615><371><878><476><136><13><381><369><13><136><13><136><13><365><eosp> ", "plain_text": "<neutral> Born once every one hundred years, dies in flames! EmoSDS: <surprise> That's such a fascinating idea! I wonder how that would even work in reality.", "residual_length": 201, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Neutral/0012_000227.npy", "dialogue_id": "1109_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <sadness> I just feel like everything is falling apart right now.\nuser: <happiness> I know it's tough, but we can get through this together!\nEmoSDS: <neutral> But what if things don't change? It's hard to stay hopeful.\n user: <sosp><79><235><79><235><79><592><13><136><511><275><665><10><333><309><918><350><304><933><128><162><584><672><584><136><162><511><584><672><311><775><856><42><1><120><933><353><275><682><10><737><425><218><616><958><831><523><438><110><568><213><645><557><177><442><120><472><966><158><425><36><583><125><493><288><275><10><899><171><354><97><241><517><958><438><178><579><400><615><371><144><162><99><196><557><136><823><292><300><368><47><277><128><162><511><275><10><476><155><757><13><235><13><365><eosp> ", "plain_text": "<neutral> Take courage, all isn't lost yet. EmoSDS: <happiness> You’re right, sometimes it feels darker than it is, but we can find a way!", "residual_length": 162, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Neutral/0018_000044.npy", "dialogue_id": "212_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> That's awesome! I can't wait to see him.\nuser: <happiness> Yeah, I know he was really excited about the visit.\nEmoSDS: <neutral> Do you know what time he’ll arrive?\n user: <sosp><79><291><79><136><622><333><918><360><583><760><197><583><493><998><790><213><20><91><162><584><871><672><775><296><108><583><493><288><275><10><158><472><111><615><269><371><183><467><292><403><292><700><376><20><78><198><136><13><863><136><863><365><eosp> ", "plain_text": "<neutral> Hannibal come to see you. EmoSDS: <neutral> Oh, that's nice to know. I'll get ready.", "residual_length": 100, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Neutral/0019_000057.npy", "dialogue_id": "277_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I'm doing great, thanks! How about you?\nuser: <happiness> I'm really happy to hear that! Any exciting plans for the weekend?\nEmoSDS: <surprise> I actually just got invited to a birthday party I wasn't expecting!\n user: <sosp><13><592><291><79><592><136><333><918><47><568><603><213><110><523><831><438><856><890><304><58><68><403><58><227><450><91><162><99><467><292><304><227><434><295><450><353><76><682><737><196><19><368><47><743><438><402><998><618><757><136><13><136><13><291><13><136><13><365><eosp> ", "plain_text": "<neutral> How are you, dear child? EmoSDS: <neutral> I'm okay, just taking things day by day.", "residual_length": 95, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Neutral/0011_000072.npy", "dialogue_id": "350_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe how well the garden is growing this year!\nuser: <neutral> Yeah, it's nice to see some plants thriving.\nEmoSDS: <surprise> Oh, look at that rabbit! It's munching on some of the leaves!\n user: <sosp><13><136><83><381><742><709><83><709><544><136><162><275><682><70><737><906><376><213><898><292><933><879><111><259><899><144><162><439><921><890><43><103><113><128><574><162><511><779><354><898><304><403><643><196><111><371><158><425><368><545><923><997><866><368><47><261><62><998><487><432><368><277><545><156><128><701><136><13><291><13><136><365><eosp> ", "plain_text": "<neutral> Chew leaves quickly, said rabbit. EmoSDS: <happiness> It’s so cute! I love how animated they are when they eat.", "residual_length": 112, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Neutral/0015_000270.npy", "dialogue_id": "1319_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> Wow, I love how colorful your decorations are! Did you make them?\nuser: <happiness> Yeah, I had a lot of fun crafting them with my family.\nEmoSDS: <surprise> Really? I didn't know you were into arts and crafts!\n user: <sosp><79><235><592><13><136><235><592><235><162><571><347><487><918><432><304><42><856><644><889><760><327><334><304><933><450><522><425><159><985><995><899><20><861><301><57><231><213><751><792><1><120><450><998><99><158><196><159><757><701><13><136><13><369><136><235><136><365><eosp> ", "plain_text": "<neutral> They are made of wood. EmoSDS: <neutral> That's interesting. Are they for a special occasion?", "residual_length": 92, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Neutral/0018_000326.npy", "dialogue_id": "1590_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> That sounds like such a nice idea! She'll love that.\nuser: <neutral> I thought she might enjoy something healthy.\nEmoSDS: <happiness> Absolutely! Plus, it’s always great to support her cooking.\n user: <sosp><79><592><13><235><13><837><904><371><158><316><450><128><162><680><778><19><296><173><370><518><472><260><259><371><158><557><274><47><1><304><933><128><511><708><10><309><918><334><304><933><580><128><162><584><779><104><866><42><172><360><583><125><889><958><751><180><998><121><159><43><295><557><15><304><933><949><524><637><921><66><866><831><579><41><930><982><70><737><464><879><524><162><511><347><487><368><360><545><128><353><275><76><70><268><144><511><618><159><985><204><680><790><509><3><78><983><402><78><136><701><13><235><13><365><eosp> ", "plain_text": "<neutral> Suppose I take grandmother a fresh vegetable. EmoSDS: <happiness> That's really thoughtful of you! She'll be so happy to get it.", "residual_length": 163, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0016/Neutral/0016_000085.npy", "dialogue_id": "414_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I think it's amazing how you care for others so genuinely.\nuser: <happiness> Thanks! I just enjoy helping people, you know?\nEmoSDS: <neutral> It really shows in everything you do.\n user: <sosp><13><79><748><79><592><136><171><998><347><487><368><47><360><41><128><708><158><19><557><616><958><831><477><1><350><927><432><108><583><889><493><204><768><91><136><616><136><616><136><557><105><304><933><204><511><680><20><983><231><856><103><583><125><760><159><557><128><162><171><125><358><125><760><43><856><607><31><131><111><615><904><371><904><371><158><155><757><136><13><235><13><365><eosp> ", "plain_text": "<neutral> That I am a born nurse. EmoSDS: <happiness> Well, you've definitely got a talent for it!", "residual_length": 140, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0016/Neutral/0016_000060.npy", "dialogue_id": "292_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I'm so glad we finally made it to this event!\nuser: <happiness> Yeah, it's nice to see everyone again after so long.\nEmoSDS: <neutral> I hope we can catch up with some friends while we're here.\n user: <sosp><13><136><13><136><13><291><13><136><171><125><760><43><445><890><103><450><125><889><760><432><320><450><128><99><10><196><36><583><125><493><288><162><328><371><158><464><557><159><113><450><128><526><371><158><487><368><62><450><128><511><686><958><108><583><889><493><288><162><680><133><311><64><831><856><866><587><522><467><292><933><450><162><511><680><487><227><472><260><601><171><125><760><159><131><111><615><428><22><476><136><13><291><13><291><13><365><eosp> ", "plain_text": "<neutral> No admittance except on party business. EmoSDS: <neutral> I understand, I just thought we could get in for a moment.", "residual_length": 153, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Neutral/0020_000272.npy", "dialogue_id": "1329_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe we finally made it to the beach!\nuser: <happiness> I know, right? The sun feels amazing!\nEmoSDS: <neutral> But where's the cooler with the drinks?\n user: <sosp><79><291><592><136><876><557><432><130><877><125><493><99><783><159><20><861><20><57><338><304><292><304><300><43><958><831><856><930><615><428><269><371><158><425><43><751><213><45><111><524><571><347><121><487><43><42><856><295><848><111><615><371><223><268><162><511><99><467><58><403><643><724><757><291><701><757><13><136><13><365><eosp> ", "plain_text": "<neutral> And we are so thirsty! EmoSDS: <happiness> Let's go find some water then, it’ll be refreshing!", "residual_length": 127, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Neutral/0014_000064.npy", "dialogue_id": "312_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe we finally did it! The monster is gone!\nuser: <surprise> Really? That's incredible news!\nEmoSDS: <neutral> I know it sounds unreal, but we were able to work together and take him down.\n user: <sosp><13><291><13><291><13><291><13><136><13><136><876><432><360><583><493><522><487><368><261><320><472><260><864><783><104><295><848><111><615><428><371><144><275><354><517><432><350><470><454><125><522><333><918><108><583><889><701><757><13><291><13><136><13><365><eosp> ", "plain_text": "<neutral> And has you slain him? EmoSDS: <neutral> Yes, we managed to finish the job last night.", "residual_length": 92, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Neutral/0020_000243.npy", "dialogue_id": "1189_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I was just trying to get his attention.\nuser: <sadness> But it really hurt him, you know?\nEmoSDS: <anger> I didn't mean to hurt him! He wasn't listening!\n user: <sosp><79><291><79><592><13><291><136><622><232><292><376><933><930><70><737><425><43><103><587><125><760><432><918><261><985><879><524><162><13><162><511><680><921><895><866><42><304><113><450><128><574><525><511><275><10><899><977><921><861><301><57><890><120><304><227><432><43><36><583><889><374><861><301><57><890><159><320><450><524><347><10><362><10><737><104><295><879><311><64><231><655><754><295><508><770><125><701><524><757><136><863><291><863><136><13><365><eosp> ", "plain_text": "<neutral> You shouldn't have pricked him with your horn. EmoSDS: <sadness> I guess I should've thought twice before using it.", "residual_length": 159, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Neutral/0013_000275.npy", "dialogue_id": "1344_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I'm so glad they found it after all this time!\nuser: <neutral> Yeah, it's a big relief.\nEmoSDS: <surprise> I didn't expect it to be so massive, though!\n user: <sosp><79><136><592><136><433><136><347><121><487><432><120><985><861><20><57><890><43><103><320><125><760><557><958><47><261><62><128><574><162><136><511><136><162><511><708><10><487><425><137><180><121><487><120><545><450><204><998><686><487><43><831><856><758><41><128><136><601><171><889><760><172><820><579><400><371><223><268><162><204><76><682><783><43><831><438><261><62><91><680><487><432><159><545><450><128><574><162><511><680><921><112><790><890><174><493><288><511><708><158><425><159><180><522><487><368><47><108><521><91><13><136><433><136><365><eosp> ", "plain_text": "<neutral> They went up to the dark mass job had pointed out. EmoSDS: <happiness> It must have been quite an adventure for them!", "residual_length": 177, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Neutral/0014_000004.npy", "dialogue_id": "18_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I just love making people laugh with my jokes!\nuser: <surprise> No way! You've got some good ones up your sleeve?\nEmoSDS: <anger> Well, it's not like everyone knows how funny I am!\n user: <sosp><13><381><13><136><511><584><98><672><597><432><470><454><470><304><486><103><587><125><798><125><760><432><927><350><470><454><125><493><998><338><292><933><151><889><89><983><231><655><866><103><640><333><215><159><213><354><441><368><47><856><295><382><304><120><472><111><615><371><476><136><13><381><13><136><13><235><13><365><eosp> ", "plain_text": "<neutral> Can your name be more hilarious? EmoSDS: <happiness> Haha, I could always add a pun or two to it!", "residual_length": 120, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Neutral/0012_000276.npy", "dialogue_id": "1349_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> Can you believe how majestic they looked soaring through the sky?\nuser: <surprise> I know! I've never seen eagles that close before!\nEmoSDS: <neutral> It really was a breathtaking moment, wasn't it?\n user: <sosp><13><235><83><709><83><123><136><13><136><616><136><666><136><511><790><64><213><445><213><56><104><866><103><320><998><760><360><583><125><493><288><111><615><269><223><899><861><57><919><376><20><91><680><128><511><275><10><144><162><347><467><304><823><403><292><232><206><584><871><790><64><110><399><213><402><111><260><615><371><476><899><757><136><13><136><365><eosp> ", "plain_text": "<neutral> Over them swooped the eagles. EmoSDS: <happiness> Yes, it was incredible! I felt so lucky to witness that!", "residual_length": 114, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Neutral/0015_000336.npy", "dialogue_id": "1641_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I think we should keep tracking our progress.\nuser: <happiness> You're right; we have made some good strides!\nEmoSDS: <neutral> Let's just focus on the next steps.\n user: <sosp><13><136><79><291><79><592><136><162><511><680><790><890><103><923><20><997><861><301><57><919><486><283><292><43><856><295><103><125><760><487><368><47><277><545><19><333><311><775><296><831><743><47><1><382><58><403><661><292><300><432><368><945><579><41><128><162><511><275><371><10><476><155><136><13><136><13><291><13><291><13><365><eosp> ", "plain_text": "<anger> But we are not high yet. EmoSDS: <neutral> I know, but we need to stay patient and keep pushing.", "residual_length": 116, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Angry/0019_000503.npy", "dialogue_id": "747_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I finally did it! I managed to get that promotion!\nuser: <happiness> Wow, that's amazing news! You totally deserve it!\nEmoSDS: <neutral> Yeah, it feels pretty good, but I'm just trying to adjust to the new role.\n user: <sosp><13><83><748><742><83><709><544><136><369><235><136><837><292><376><20><861><91><162><511><98><300><350><470><454><125><493><879><524><212><66><104><856><103><583><125><358><125><760><958><47><579><400><524><571><347><487><432><327><470><454><493><288><584><871><104><856><754><438><399><402><88><701><524><136><13><114><136><13><365><eosp> ", "plain_text": "<anger> You gain for nothing girl! EmoSDS: <sadness> I wish it could've been more rewarding than just this expectation...", "residual_length": 120, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Angry/0015_000683.npy", "dialogue_id": "1624_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I'm really excited about the project we discussed last week!\nuser: <surprise> Oh wow, I didn't expect you to feel that way!\nEmoSDS: <sadness> Yeah, but sometimes I wonder if I'm ready for it.\n user: <sosp><13><863><291><79><592><136><13><291><13><136><116><347><487><368><47><261><62><20><861><301><57><890><103><472><260><158><425><472><260><615><268><144><162><164><275><76><70><737><196><292><232><933><879><524><949><524><347><121><64><110><438><277><545><128><162><131><701><757><136><863><757><863><291><13><365><eosp> ", "plain_text": "<anger> That was his chief thought. EmoSDS: <anger> Seriously? That doesn't make any sense; he should have thought deeper!", "residual_length": 115, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Angry/0013_000358.npy", "dialogue_id": "38_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I just wanted to talk about what happened yesterday.\nuser: <sadness> I know, but it really upset me.\nEmoSDS: <happiness> I didn't mean to make you feel that way; I just thought we could figure it out.\n user: <sosp><79><433><79><422><136><742><136><105><918><360><583><760><350><403><643><580><136><592><136><13><433><13><511><680><936><919><898><283><232><700><393><472><260><259><862><162><680><936><919><898><283><292><393><472><111><259><268><144><511><275><783><43><173><484><523><213><156><125><197><31><333><856><754><295><128><574><162><171><889><338><304><403><643><701><136><13><235><13><365><eosp> ", "plain_text": "<anger> Annie please please don't hurt me! EmoSDS: <anger> You think I'm going to hurt you? That's completely out of line!", "residual_length": 149, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0016/Angry/0016_000364.npy", "dialogue_id": "65_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> What do you want to eat for dinner?\nuser: <happiness> I think I’d love something festive for the occasion.\nEmoSDS: <neutral> That sounds great! Any special requests?\n user: <sosp><13><291><13><136><13><136><13><162><136><98><292><304><120><103><985><879><171><151><889><338><292><304><300><432><368><261><88><879><524><347><487><958><47><172><47><360><583><36><131><128><136><13><136><13><136><837><524><313><487><368><47><820><47><579><41><128><275><10><781><136><13><136><13><291><13><162><511><584><292><906><376><930><111><615><428><476><136><13><291><13><365><eosp> ", "plain_text": "<anger> Give me a fine fat goose. EmoSDS: <neutral> Alright, but maybe ask nicely next time?", "residual_length": 173, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Angry/0011_000663.npy", "dialogue_id": "1530_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I think we have different opinions on this matter.\nuser: <sadness> I just wish things were simpler between us.\nEmoSDS: <happiness> But we can work it out together, right?\n user: <sosp><13><79><235><79><592><837><371><904><144><511><665><10><309><43><213><45><557><58><204><98><292><906><376><20><240><489><958><173><213><231><861><57><890><360><442><545><128><557><511><368><190><545><450><162><99><783><906><376><103><522><304><403><643><196><136><13><235><13><592><235><592><136><13><365><eosp> ", "plain_text": "<anger> Still you owe it a duty. EmoSDS: <sadness> I know, but it's just hard for me to take that responsibility right now.", "residual_length": 112, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Angry/0018_000556.npy", "dialogue_id": "1007_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe how funny that last story was!\nuser: <happiness> I know, right? It had everyone in stitches!\nEmoSDS: <neutral> So, what did Tom say next?\n user: <sosp><79><592><291><13><136><13><291><13><136><511><708><10><597><296><831><795><108><583><889><493><91><511><584><672><159><545><923><104><311><64><831><754><856><261><320><354><898><700><292><472><111><615><223><862><144><162><680><338><292><700><232><933><584><162><524><921><104><295><159><20><45><354><517><958><47><820><47><62><879><524><637><66><425><159><432><58><454><125><701><266><757><291><757><13><136><365><eosp> ", "plain_text": "<anger> Tom could hardly speak for laughing. EmoSDS: <happiness> That's amazing! I wish I could've seen it!", "residual_length": 139, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Angry/0013_000415.npy", "dialogue_id": "1714_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Have you thought about trying a new technique for the painting?\nuser: <sadness> I just don't feel confident in my skills right now.\nEmoSDS: <happiness> That's okay! Art is all about enjoying the process, right?\n user: <sosp><13><79><235><79><958><136><274><831><47><360><628><304><232><933><204><91><574><162><99><686><43><173><523><983><213><45><128><162><708><158><464><91><162><235><162><511><956><333><309><350><470><454><493><288><708><10><425><120><320><450><128><574><162><511><708><10><333><311><775><296><831><1><628><113><450><998><584><43><856><607><31><184><31><701><757><136><13><235><13><235><13><365><eosp> ", "plain_text": "<anger> I don't painted tiger. EmoSDS: <sadness> I'm sorry to hear that, but maybe you just need some time.", "residual_length": 122, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Angry/0018_000446.npy", "dialogue_id": "470_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I was just walking in the park yesterday, and it felt so peaceful.\nuser: <neutral> Yeah, I love when it's quiet like that. It's nice to relax.\nEmoSDS: <sadness> But then I saw that there was some damage to the trees, and it just feels wrong.\n user: <sosp><13><291><136><79><592><136><188><876><333><820><47><568><213><231><57><890><985><56><997><104><295><159><472><111><615><371><269><371><158><425><173><108><583><889><429><493><204><768><270><958><831><47><545><923><522><58><403><450><91><162><511><98><309><304><43><213><45><72><328><769><904><371><158><425><958><89><889><493><288><162><524><313><347><487><432><382><58><701><198><427><136><13><136><13><291><13><136><13><365><eosp> ", "plain_text": "<anger> However, somebody killed something. EmoSDS: <anger> I can't believe someone would do that! It's just so frustrating.", "residual_length": 145, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Angry/0019_000558.npy", "dialogue_id": "1017_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> It's been difficult spotting them lately.\nuser: <sadness> I know, I've been trying to keep an eye out, but nothing.\nEmoSDS: <happiness> Maybe they'll show up soon; I heard they like this time of year.\n user: <sosp><13><291><13><291><13><291><13><291><136><998><467><292><232><196><557><136><616><136><489><274><831><523><743><47><477><1><15><304><403><643><196><136><13><162><511><584><672><921><919><890><103><450><204><601><125><728><125><728><125><760><172><831><743><277><545><128><618><128><162><511><584><98><309><918><368><47><261><545><128><353><682><70><268><144><347><487><368><60><985><889><808><701><757><136><291><13><136><13><365><eosp> ", "plain_text": "<anger> The eye could not catch them. EmoSDS: <neutral> That's really frustrating, isn't it? We should keep looking.", "residual_length": 163, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Angry/0013_000506.npy", "dialogue_id": "762_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I saw you standing over there earlier.\nuser: <sadness> I thought you would come to talk to me.\nEmoSDS: <happiness> I was planning to, but things got busy.\n user: <sosp><13><592><235><592><79><235><79><958><136><162><136><511><274><628><376><20><861><997><57><890><103><472><260><259><571><171><125><358><760><43><173><523><173><108><103><62><128><275><10><899><757><136><13><91><204><91><779><997><85><866><856><831><47><820><47><145><277><545><128><91><162><275><10><476><155><757><13><235><13><365><eosp> ", "plain_text": "<anger> I was not grabbed. EmoSDS: <neutral> That’s not what it looked like to me, though.", "residual_length": 110, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Angry/0018_000553.npy", "dialogue_id": "992_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I thought we agreed to meet at six.\nuser: <happiness> I know, but I got caught up in traffic!\nEmoSDS: <sadness> It seems like this always happens, doesn't it?\n user: <sosp><13><291><13><861><301><173><360><545><128><315><557><489><958><831><856><295><848><292><376><861><301><57><890><304><350><283><933><522><283><232><933><879><949><524><637><66><790><231><983><655><237><295><985><450><889><760><432><36><583><125><701><136><13><291><13><365><eosp> ", "plain_text": "<anger> What are you waiting for? man. EmoSDS: <anger> I’m just frustrated because I don’t like being late either!", "residual_length": 118, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Angry/0012_000697.npy", "dialogue_id": "1693_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I heard the mission was tough, what happened next?\nuser: <happiness> We actually managed to strategize really well and turn things around!\nEmoSDS: <neutral> That's great to hear. So, what did you do with the prisoners?\n user: <sosp><13><335><79><291><79><775><136><876><274><628><304><933><450><204><162><511><665><467><442><304><933><450><204><998><584><300><43><751><213><78><20><440><91><162><557><432><36><125><889><760><304><450><204><601><493><889><125><889><760><432><918><360><320><760><350><470><933><91><680><921><104><856><103><472><260><966><260><158><171><125><197><31><607><31><131><111><615><769><371><428><476><136><13><136><235><136><13><235><13><365><eosp> ", "plain_text": "<anger> I did go, and made many prisoners. EmoSDS: <neutral> That sounds intense; I hope you had a good reason for it.", "residual_length": 138, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0016/Angry/0016_000352.npy", "dialogue_id": "9_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I thought we agreed to meet at six.\nuser: <happiness> I know, but I got caught up in traffic!\nEmoSDS: <sadness> It seems like this always happens, doesn't it?\n user: <sosp><13><748><13><235><13><204><861><301><57><173><103><923><856><758><450><206><292><283><919><861><91><301><57><890><304><283><442><522><304><350><470><454><493><779><879><524><313><790><231><983><655><856><607><31><701><136><171><125><889><760><432><918><47><360><583><125><760><130><579><757><13><136><13><291><13><136><365><eosp> ", "plain_text": "<anger> What are you waiting for? man. EmoSDS: <anger> I’m just frustrated because I don’t like being late either!", "residual_length": 135, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Angry/0015_000697.npy", "dialogue_id": "1693_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I just got back from work.\nuser: <happiness> That's great! Did you have a good day?\nEmoSDS: <sadness> Not really, it was pretty stressful.\n user: <sosp><13><136><13><136><13><291><13><136><837><904><371><269><371><158><425><213><231><173><360><918><360><108><583><429><998><121><159><320><450><162><99><686><43><20><983><231><655><237><295><450><353><682><783><159><450><601><125><20><997><861><301><57><173><380><918><432><15><320><450><328><275><982><70><260><998><347><425><487><432><60><889><125><701><136><114><136><79><136><13><291><13><136><13><365><eosp> ", "plain_text": "<anger> Slam the doors and wedge them! EmoSDS: <sadness> I can see you're really upset, but maybe we should talk it out instead?", "residual_length": 128, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Angry/0019_000614.npy", "dialogue_id": "1290_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> It's just another day at work.\nuser: <sadness> I know, but it feels like we're always stuck in this routine.\nEmoSDS: <happiness> We should find something to lighten the mood!\n user: <sosp><79><291><79><592><188><136><876><274><47><1><304><206><204><511><98><300><368><653><320><111><615><371><158><425><227><120><472><450><328><371><158><425><159><320><450><353><76><70><737><311><64><231><890><304><58><111><371><904><371><223><10><524><338><304><403><58><111><371><268><144><162><511><275><10><196><757><136><381><13><291><13><365><eosp> ", "plain_text": "<anger> I guess it's a choice feast. EmoSDS: <neutral> Sure, but we could make it better if we changed things up a bit.", "residual_length": 129, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Angry/0014_000456.npy", "dialogue_id": "518_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I think it would be a good idea to invest in your own.\nuser: <sadness> I just feel like I can't afford it right now.\nEmoSDS: <happiness> But think about how much it'll help you in the long run!\n user: <sosp><13><136><79><291><79><136><861><301><57><173><831><41><930><70><737><425><159><998><923><43><831><404><831><404><831><47><477><628><41><450><91><162><511><680><921><311><856><104><295><103><450><353><275><682><737><472><260><862><171><889><958><47><477><1><432><43><568><213><808><125><384><125><701><136><114><13><291><13><291><13><365><eosp> ", "plain_text": "<anger> Why should I purchase my own? EmoSDS: <neutral> Well, having your own gives you freedom and flexibility.", "residual_length": 119, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Angry/0019_000692.npy", "dialogue_id": "1668_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you hear that sound earlier?\nuser: <surprise> Yeah, I thought it was something breaking!\nEmoSDS: <happiness> No way! I can't believe it sounded that intense!\n user: <sosp><13><79><235><79><235><79><592><311><136><13><235><511><790><173><213><20><762><861><301><57><890><856><306><927><350><470><454><125><760><43><213><655><890><1><15><304><472><260><259><899><144><171><57><890><159><111><259><371><899><311><775><856><295><31><131><450><618><757><235><13><365><eosp> ", "plain_text": "<anger> A whirring noise was heard. EmoSDS: <neutral> It might just be the old machinery acting up, shouldn't worry too much.", "residual_length": 107, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Angry/0018_000695.npy", "dialogue_id": "1683_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I just think we should plan this out carefully.\nuser: <happiness> You're probably right, but we need to make a move soon!\nEmoSDS: <sadness> I know, but I'm just worried about what could happen.\n user: <sosp><13><235><13><235><13><369><235><369><136><301><57><173><103><923><856><758><304><292><933><204><661><292><546><376><20><701><136><235><13><171><301><861><301><57><890><304><292><403><292><232><933><522><292><470><454><493><879><524><637><66><790><983><655><295><184><701><757><136><13><136><125><358><889><760><487><432><327><927><432><481><108><36><583><125><701><757><136><592><13><365><eosp> ", "plain_text": "<anger> What are you waiting for? man. EmoSDS: <neutral> I was just trying to think things through, that's all.", "residual_length": 159, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Angry/0017_000697.npy", "dialogue_id": "1689_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I've been thinking about our conversation last week.\nuser: <sadness> Yeah, it really hit me hard.\nEmoSDS: <happiness> I'm glad I could be there for you, though.\n user: <sosp><13><79><291><79><311><136><13><235><13><511><958><831><743><47><477><334><350><304><933><454><125><798><358><125><760><43><173><484><445><20><681><292><232><292><700><227><43><213><20><78><701><524><136><666><13><136><13><235><13><592><365><eosp> ", "plain_text": "<anger> I know you. EmoSDS: <neutral> Well, what are you trying to say by that?", "residual_length": 93, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Angry/0018_000628.npy", "dialogue_id": "1359_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> You know, a lot of artists get inspiration from others.\nuser: <happiness> True, but it's cool how they make it their own in the end.\nEmoSDS: <sadness> Yeah, but sometimes it feels like they lose their originality.\n user: <sosp><13><136><79><311><790><136><235><136><511><270><173><62><128><574><162><511><347><487><43><103><450><128><574><162><511><275><10><672><203><961><919><20><861><20><890><36><125><557><309><442><320><472><966><158><425><432><130><493><288><10><333><309><227><472><260><259><158><557><616><489><958><173><213><983><57><103><125><557><432><130><125><630><159><985><995><879><347><487><368><360><583><493><288><353><76><70><737><425><432><130><36><384><701><114><13><114><13><235><13><136><13><365><eosp> ", "plain_text": "<anger> But the tune isn't his own invention. EmoSDS: <neutral> I get that, but it's still a part of his artistic expression.", "residual_length": 151, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Angry/0018_000569.npy", "dialogue_id": "1071_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> Wow, the weather is so nice today!\nuser: <neutral> Yeah, but the flies are really annoying.\nEmoSDS: <surprise> I didn't expect that! Are the flies that bad?\n user: <sosp><13><79><136><79><235><592><166><592><13><433><136><79><333><775><296><831><438><568><445><213><645><489><958><274><47><477><1><304><215><333><309><918><334><283><232><933><128><162><666><136><511><347><998><347><121><487><227><111><615><371><158><333><820><41><524><637><66><958><831><47><568><213><45><91><162><511><680><921><919><20><983><78><701><757><136><13><235><13><136><291><13><365><eosp> ", "plain_text": "<anger> How I hate this foul pool! EmoSDS: <surprise> Seriously? Why are you so worked up about it?", "residual_length": 177, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Angry/0014_000386.npy", "dialogue_id": "172_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I was thinking about our options for the weekend.\nuser: <happiness> That sounds great! We could go hiking or maybe find a new café to try.\nEmoSDS: <sadness> I just hope we don't make plans that fall through again.\n user: <sosp><79><291><79><757><136><13><235><13><585><20><354><829><142><517><751><368><360><545><923><120><304><933><450><998><162><511><98><300><304><43><985><159><320><260><259><158><425><159><320><450><353><76><275><70><737><333><309><918><350><927><360><261><62><128><328><371><862><171><889><760><958><432><1><985><450><680><104><866><856><368><131><930><353><682><158><425><43><368><990><131><111><615><904><371><476><155><757><136><13><291><13><365><eosp> ", "plain_text": "<anger> Let it give us a chance, my precious. EmoSDS: <neutral> It's frustrating that we keep waiting, but I guess it’s worth trying.", "residual_length": 128, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0016/Angry/0016_000563.npy", "dialogue_id": "1037_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> What are you talking about?\nuser: <surprise> I just saw something move in the bushes!\nEmoSDS: <happiness> That's probably just a rabbit or something.\n user: <sosp><13><136><79><235><79><592><136><171><204><861><919><173><203><128><574><511><196><136><162><136><876><820><47><942><438><521><128><162><275><10><158><196><111><371><904><371><158><487><368><360><432><545><522><557><47><743><568><213><898><432><120><159><579><111><615><371><904><371><476><757><136><13><235><13><235><13><365><eosp> ", "plain_text": "<anger> Look out! said Alice. EmoSDS: <sadness> Why do you always have to shout like that? It's kind of alarming.", "residual_length": 116, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Angry/0018_000468.npy", "dialogue_id": "576_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I didn't notice the noise at first.\nuser: <sadness> It's been like this for days, and I can't stand it anymore.\nEmoSDS: <happiness> I thought it was just part of nature! It's kind of charming.\n user: <sosp><13><235><13><235><13><136><616><13><616><136><511><958><368><320><450><204><91><162><235><13><136><162><99><686><487><368><47><62><879><524><347><103><320><125><760><309><927><350><470><383><454><493><91><162><275><70><737><333><856><754><856><261><62><450><128><162><680><338><227><58><470><454><760><130><701><136><13><997><301><85><866><368><432><320><125><493><288><708><10><196><136><162><13><511><338><292><403><557><511><105><918><350><42><856><754><295><480><31><608><114><13><235><13><365><eosp> ", "plain_text": "<anger> A deafening chirruping rent the air. EmoSDS: <neutral> I can see you're really frustrated, but do you think we could find a way to block it out?", "residual_length": 173, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Angry/0017_000405.npy", "dialogue_id": "268_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <sadness> I just wish she would feel more confident about her voice.\nuser: <neutral> Well, it could be a bit tough for anyone, I guess.\nEmoSDS: <happiness> But you know, she really enjoys it, so that's what matters!\n user: <sosp><13><291><592><136><592><79><291><592><136><622><292><338><376><890><213><295><997><151><889><358><889><338><304><933><632><864><682><783><304><376><953><20><861><301><231><173><751><360><1><304><933><879><637><921><171><601><171><286><358><125><760><432><918><261><62><879><104><295><450><128><511><98><672><309><432><583><125><72><285><615><371><183><304><470><454><125><760><159><320><111><615><269><223><158><425><958><523><875><808><701><13><136><13><291><13><365><eosp> ", "plain_text": "<anger> Your midget wife never can sing a song. EmoSDS: <sadness> I understand you’re frustrated, but she really tries her best.", "residual_length": 148, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Angry/0012_000406.npy", "dialogue_id": "273_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you get a chance to think about our plan?\nuser: <happiness> Yeah, I think it could work really well!\nEmoSDS: <neutral> That’s great to hear! So, how should we proceed?\n user: <sosp><13><291><13><291><13><136><105><292><304><933><879><524><171><997><104><125><358><760><172><47><277><299><156><128><446><511><274><47><579><41><930><982><223><10><737><43><213><20><861><91><162><511><871><43><213><445><20><103><125><760><197><43><213><20><879><524><637><212><104><480><295><848><472><998><347><121><425><159><31><396><136><13><291><13><136><13><136><13><365><eosp> ", "plain_text": "<anger> If not, I shall go no further. EmoSDS: <neutral> I'm just trying to understand your point of view, let’s discuss it calmly.", "residual_length": 133, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Angry/0019_000585.npy", "dialogue_id": "1150_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <sadness> I can't believe they had to fight like that.\nuser: <happiness> It seemed so intense, but they both liked the thrill!\nEmoSDS: <neutral> What an unexpected showdown, right?\n user: <sosp><13><79><235><79><592><136><13><136><524><499><790><173><856><754><295><879><524><66><919><142><898><919><376><472><111><524><362><486><109><486><103><933><998><347><467><292><403><557><162><557><432><918><42><856><31><545><128><162><511><275><10><309><283><232><698><524><347><196><933><204><286><493><358><760><752><172><820><579><41><930><982><70><223><268><144><275><10><476><757><136><13><235><13><235><13><136><13><365><eosp> ", "plain_text": "<anger> Fur flew through the air, teeth gnashed. EmoSDS: <anger> I can’t believe they let it get so out of control!", "residual_length": 151, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Angry/0018_000547.npy", "dialogue_id": "961_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Have you checked the latest reports on the asteroids?\nuser: <sadness> I heard there might be more of them coming our way.\nEmoSDS: <happiness> But we still have time to prepare if we act quickly!\n user: <sosp><79><381><79><592><422><592><876><136><381><136><876><820><47><579><400><492><615><223><268><144><275><737><104><295><866><213><751><43><1><120><933><450><91><162><347><121><923><104><561><486><304><333><296><108><103><583><107><493><465><783><104><295><848><120><522><487><120><432><36><125><493><288><162><275><10><977><112><57><173><108><36><583><493><288><275><10><467><304><700><58><933><879><524><637><66><958><831><47><795><47><1><382><131><879><524><343><476><136><365><eosp> ", "plain_text": "<anger> Asteroid three hundred and twenty five. EmoSDS: <neutral> What about it? Are you worried?", "residual_length": 160, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Angry/0014_000413.npy", "dialogue_id": "308_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you notice that about him?\nuser: <sadness> Yeah, it kind of reminds me of when he was sick.\nEmoSDS: <happiness> But he seems okay now, right? That's a good sign!\n user: <sosp><13><291><13><136><13><136><13><291><13><136><524><66><790><831><47><261><62><998><121><159><104><866><333><47><368><320><472><260><747><467><292><232><300><43><320><354><517><751><213><645><557><162><489><958><831><743><404><743><47><477><1><58><722><131><472><260><615><476><757><136><13><136><13><136><13><136><13><291><13><136><13><365><eosp> ", "plain_text": "<anger> Father has yellow eyes. EmoSDS: <neutral> I didn't know that... Is he feeling alright?", "residual_length": 126, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Angry/0020_000662.npy", "dialogue_id": "1525_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Hey, do you remember our birdwatching trip last summer?\nuser: <happiness> Of course! We saw so many cool birds!\nEmoSDS: <surprise> I can't believe how close we got to that heron!\n user: <sosp><13><291><13><136><13><136><13><511><680><354><517><958><47><169><41><128><574><162><511><680><104><295><848><587><522><557><368><432><320><125><493><632><204><162><275><76><682><783><42><918><1><327><15><58><403><58><68><58><643><136><757><114><136><13><136><13><136><13><136><13><365><eosp> ", "plain_text": "<anger> Blackbird, and Jay. EmoSDS: <neutral> I know you're upset, but we can try to spot them again sometime.", "residual_length": 98, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Angry/0020_000507.npy", "dialogue_id": "767_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I heard there might be some trouble ahead.\nuser: <happiness> Oh really? That sounds exciting!\nEmoSDS: <sadness> But I’m worried about what could happen next.\n user: <sosp><13><291><13><291><13><136><13><136><616><136><240><231><762><861><879><231><85><486><103><349><998><121><360><432><360><583><125><493><472><260><615><223><921><20><376><20><450><204><91><162><680><338><304><283><232><283><232><933><204><584><213><983><78><45><402><45><111><615><371><476><136><369><291><369><136><365><eosp> ", "plain_text": "<anger> Over them swooped the eagles. EmoSDS: <anger> This situation is getting out of control!", "residual_length": 125, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Angry/0012_000686.npy", "dialogue_id": "1642_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe we finally got the tickets!\nuser: <surprise> Wait, really? That's amazing!\nEmoSDS: <neutral> Yeah, I just checked online, and there they were.\n user: <sosp><13><136><592><79><291><79><592><13><136><235><162><136><105><304><472><450><328><371><158><487><918><360><320><260><268><171><601><125><760><43><213><231><983><811><861><301><173><890><360><283><232><930><982><242><70><737><43><831><438><213><587><522><304><933><450><204><162><511><686><300><304><334><403><393><472><260><747><260><467><292><403><232><643><136><162><136><592><291><592><13><365><eosp> ", "plain_text": "<anger> It says no way! shouted Daisy. EmoSDS: <surprise> Wow, I can’t believe they would do that. What a letdown!", "residual_length": 128, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Angry/0012_000578.npy", "dialogue_id": "1112_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I'm really excited about the project we discussed last week!\nuser: <surprise> Oh wow, I didn't expect you to feel that way!\nEmoSDS: <sadness> Yeah, but sometimes I wonder if I'm ready for it.\n user: <sosp><79><748><79><592><136><748><13><136><204><998><487><918><47><545><998><204><91><861><301><57><173><890><103><320><328><371><10><196><227><472><111><260><259><371><268><144><162><275><76><275><70><183><309><292><232><933><879><524><347><524><347><487><958><831><523><438><47><820><41><128><162><275><371><10><155><136><13><748><13><136><13><365><eosp> ", "plain_text": "<anger> That was his chief thought. EmoSDS: <anger> Seriously? That doesn't make any sense; he should have thought deeper!", "residual_length": 125, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Angry/0015_000358.npy", "dialogue_id": "38_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> So, what happened at the party last night?\nuser: <happiness> It was amazing! Everyone was dancing and having a great time!\nEmoSDS: <sadness> That's too bad I couldn't make it; I was really looking forward to it.\n user: <sosp><709><544><13><291><13><291><13><171><565><125><760><43><792><751><568><484><213><445><20><91><136><13><291><13><136><837><371><158><425><918><432><545><450><564><162><511><680><196><309><304><232><206><232><292><68><232><564><275><98><196><309><918><42><856><295><848><180><45><898><159><111><615><223><268><495><354><898><58><643><196><643><136><13><291><13><136><13><365><eosp> ", "plain_text": "<anger> No, said piggy carelessly. EmoSDS: <anger> Why would piggy say something like that? That's really frustrating!", "residual_length": 136, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Angry/0011_000639.npy", "dialogue_id": "1412_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> How has your week been so far?\nuser: <happiness> It's been pretty good! I've been working on that project I told you about.\nEmoSDS: <surprise> Really? I thought you were feeling overwhelmed with it!\n user: <sosp><13><369><291><592><166><592><291><13><136><876><274><368><1><41><128><511><680><487><432><304><640><333><47><62><879><524><790><943><113><450><128><162><584><921><866><831><47><108><583><760><197><213><20><811><861><301><57><338><304><292><232><450><564><511><98><557><616><918><368><47><918><169><128><526><682><615><223><268><144><176><104><866><751><3><60><757><136><13><136><13><291><13><365><eosp> ", "plain_text": "<anger> I pay half a crown a week extra. EmoSDS: <neutral> That's a lot for just a little help, isn't it?", "residual_length": 128, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Angry/0020_000524.npy", "dialogue_id": "848_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I was thinking about our options for the weekend.\nuser: <happiness> That sounds great! We could go hiking or maybe find a new café to try.\nEmoSDS: <sadness> I just hope we don't make plans that fall through again.\n user: <sosp><79><757><136><291><13><136><171><354><829><354><142><441><360><923><120><304><933><564><162><98><292><304><43><985><879><173><159><320><111><371><158><159><111><128><162><275><70><737><309><432><130><131><72><288><328><371><862><171><889><958><831><47><41><545><128><574><162><511><680><921><866><831><368><41><930><982><70><737><425><227><159><579><400><615><904><371><476><457><136><13><136><13><136><291><13><365><eosp> ", "plain_text": "<anger> Let it give us a chance, my precious. EmoSDS: <neutral> It's frustrating that we keep waiting, but I guess it’s worth trying.", "residual_length": 147, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Angry/0019_000563.npy", "dialogue_id": "1037_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Hey, I think it might be morning now.\nuser: <happiness> Oh really? I must have slept through my alarm.\nEmoSDS: <sadness> Yeah, I didn’t want to disturb you, but I thought it was best to let you know.\n user: <sosp><79><433><79><422><592><235><622><292><376><919><20><861><231><173><523><213><450><91><162><511><601><171><125><889><452><292><283><300><918><47><277><521><128><574><162><511><680><886><757><136><13><365><eosp> ", "plain_text": "<anger> You woke me up! EmoSDS: <sadness> I’m really sorry about that, it wasn’t my intention to bother you.", "residual_length": 74, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0016/Angry/0016_000646.npy", "dialogue_id": "1447_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I think she would really appreciate that since she loves her garden.\nuser: <happiness> Yeah, and I could also help her cook something nice with them.\nEmoSDS: <neutral> That sounds like a great idea! What recipe do you have in mind?\n user: <sosp><544><13><136><592><291><592><13><136><291><13><136><13><136><837><371><158><159><450><998><680><173><332><213><518><180><260><158><487><368><47><261><320><450><128><708><10><158><487><918><432><304><206><450><564><779><85><866><172><360><108><583><889><43><751><180><121><159><295><104><866><644><62><879><524><212><104><866><43><42><320><930><982><70><899><171><889><760><43><918><360><320><930><615><223><371><158><159><985><204><270><509><3><78><402><91><136><13><136><13><136><13><291><136><13><365><eosp> ", "plain_text": "<anger> Suppose I take grandmother a fresh vegetable. EmoSDS: <neutral> Well, I'm sure it'll brighten her day, despite how you feel right now.", "residual_length": 139, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Angry/0011_000435.npy", "dialogue_id": "415_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> It's just a part of life, you know?\nuser: <sadness> Yeah, but sometimes I feel like I've missed out on so much.\nEmoSDS: <happiness> Well, at least we can make new memories now!\n user: <sosp><13><235><13><592><79><311><136><876><274><958><831><477><360><640><304><360><320><879><347><487><333><410><47><261><545><450><128><511><275><10><737><906><376><450><204><779><997><85><104><866><43><213><445><983><231><240><162><240><509><983><45><204><91><618><294><476><757><136><666><13><235><136><13><136><365><eosp> ", "plain_text": "<anger> I have had to grow old. EmoSDS: <neutral> Growing old can be frustrating, but maybe it can also bring some wisdom.", "residual_length": 107, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Angry/0018_000542.npy", "dialogue_id": "937_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> So, what's on your mind regarding the decision?\nuser: <sadness> I just feel like there's no right answer here.\nEmoSDS: <happiness> It's okay to feel that way, but let's try to look on the bright side!\n user: <sosp><13><291><13><136><13><136><13><291><136><105><304><227><376><20><890><159><985><204><91><162><680><338><292><300><43><958><438><311><296><831><856><103><450><128><574><162><275><70><921><311><790><64><484><751><1><58><933><111><615><371><476><136><13><291><13><136><13><136><365><eosp> ", "plain_text": "<anger> It would be a hard choice. EmoSDS: <neutral> I get that, but we have to make a choice eventually.", "residual_length": 107, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Angry/0020_000678.npy", "dialogue_id": "1603_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I heard she grows the best apples in town.\nuser: <happiness> Yeah, everyone loves her orchard!\nEmoSDS: <sadness> It's a shame her last harvest was affected by the storm.\n user: <sosp><13><136><79><433><79><592><136><917><354><142><898><961><376><472><111><615><371><183><467><304><58><403><643><557><958><47><261><628><41><128><584><672><375><790><213><603><441><360><47><360><261><62><56><923><104><856><295><879><949><524><637><66><64><831><795><108><856><644><583><889><197><295><31><701><114><13><433><13><592><79><433><79><365><eosp> ", "plain_text": "<anger> Lucy, a clever farmer. EmoSDS: <anger> Clever? She should have been better prepared for the storms!", "residual_length": 121, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Angry/0014_000694.npy", "dialogue_id": "1676_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you hear what Daisy said?\nuser: <happiness> Yeah, I thought it was pretty funny!\nEmoSDS: <sadness> I just hope she doesn't get too upset about it.\n user: <sosp><13><291><369><291><369><136><13><136><291><136><105><304><442><933><450><328><371><269><371><158><425><368><360><320><260><601><171><125><760><43><751><438><445><20><762><811><861><811><301><57><173><380><918><1><15><304><58><403><58><131><757><136><837><70><737><425><368><47><751><985><450><128><511><99><467><227><472><450><204><162><511><686><487><432><304><472><260><467><58><643><136><291><13><291><13><365><eosp> ", "plain_text": "<anger> It says no way! shouted Daisy. EmoSDS: <neutral> I can't believe she reacted like that, though.", "residual_length": 160, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Angry/0020_000578.npy", "dialogue_id": "1115_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I think we should take some time to think about our options.\nuser: <sadness> I just really hoped things would go differently.\nEmoSDS: <happiness> But we still have a chance to make things better!\n user: <sosp><13><136><79><291><79><136><79><592><6><876><333><296><47><404><568><213><20><109><997><85><866><47><820><41><930><615><70><10><196><292><376><20><213><64><751><438><60><31><757><136><114><13><291><13><136><13><365><eosp> ", "plain_text": "<anger> How rash you are! EmoSDS: <anger> You have no idea how frustrating that is for me!", "residual_length": 103, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Angry/0014_000586.npy", "dialogue_id": "1155_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> It's interesting how people's beliefs can influence their actions.\nuser: <happiness> Yeah, it's fascinating to see the passion they have for their ideas!\nEmoSDS: <sadness> But sometimes, it leads to conflict, which is really unfortunate.\n user: <sosp><79><291><79><422><136><13><291><136><489><958><831><47><477><1><376><20><861><301><57><890><103><450><72><328><371><615><269><428><268><144><162><511><584><672><43><831><404><62><879><524><66><425><159><180><450><128><162><511><347><467><292><393><472><260><615><371><899><524><212><66><64><958><831><795><438><568><603><509><655><295><848><930><111><260><615><476><757><136><13><136><291><13><136><13><136><863><136><13><365><eosp> ", "plain_text": "<anger> I would scoff at these followers. EmoSDS: <anger> I get it, they can be so ridiculous sometimes!", "residual_length": 147, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Angry/0013_000607.npy", "dialogue_id": "1256_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe how well she's doing lately!\nuser: <neutral> Yeah, it's really impressive.\nEmoSDS: <sadness> But I wish she could see how much we care.\n user: <sosp><13><136><13><291><235><13><136><921><31><104><295><848><930><982><70><428><70><737><292><376><393><472><260><899><997><104><866><159><180><354><441><958><47><190><545><128><98><196><524><313><309><442><930><982><737><425><227><472><111><904><371><476><457><781><136><863><291><863><136><13><365><eosp> ", "plain_text": "<anger> Her shoes were like fishes. EmoSDS: <neutral> Well, that’s certainly a strange choice, isn’t it?", "residual_length": 108, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Angry/0019_000362.npy", "dialogue_id": "55_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> What are you reading there?\nuser: <happiness> It's a really interesting fairy tale, you might enjoy it!\nEmoSDS: <neutral> Oh, I love those! What happens next?\n user: <sosp><13><291><13><291><13><136><998><347><487><368><640><333><918><47><628><450><204><998><354><898><43><62><91><128><162><99><467><442><877><125><493><288><275><10><906><159><180><450><998><121><159><111><615><223><268><144><158><425><43><445><20><45><985><45><995><524><637><136><365><eosp> ", "plain_text": "<anger> The hag looked in the stove. EmoSDS: <surprise> Why would she do that? Is there something in there she's after?", "residual_length": 110, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Angry/0020_000426.npy", "dialogue_id": "371_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you hear something outside last night?\nuser: <happiness> Yeah, I heard some noises, but I thought it was just the wind.\nEmoSDS: <sadness> I wish it was just that, but you never know these days.\n user: <sosp><13><136><13><291><13><136><13><136><616><876><958><368><579><400><524><887><309><467><292><933><949><524><66><338><159><125><998><121><159><130><125><728><358><760><487><368><820><327><643><98><136><162><511><275><371><10><476><155><136><13><136><13><136><291><13><365><eosp> ", "plain_text": "<anger> A thief in the night. EmoSDS: <sadness> That's terrible! I can't believe things have come to this.", "residual_length": 104, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Angry/0019_000666.npy", "dialogue_id": "1540_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Hey, did you hear what happened to the captain?\nuser: <sadness> Yeah, I heard he's been having a tough time lately.\nEmoSDS: <happiness> It's so unfortunate, especially when he tries so hard for everyone.\n user: <sosp><13><136><13><291><13><291><13><136><13><136><291><136><511><98><309><918><47><62><128><574><511><708><158><425><36><583><728><72><450><162><511><708><10><672><311><296><831><404><523><438><62><889><770><480><295><848><111><260><615><428><371><40><467><292><700><933><376><472><260><425><36><125><728><760><36><557><136><13><136><105><432><927><470><454><696><493><779><210><997><85><486><700><933><376><20><354><517><792><368><261><545><923><295><31><608><162><136><13><291><136><13><365><eosp> ", "plain_text": "<anger> Captain Tom receives an angry letter. EmoSDS: <neutral> That's really upsetting, I hope he doesn't take it too personally.", "residual_length": 175, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Angry/0013_000549.npy", "dialogue_id": "972_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I don't know, but I've seen animals do it before.\nuser: <happiness> That's true! Animals have some really amazing skills.\nEmoSDS: <sadness> Yeah, but sometimes I feel like they have it easier than we do.\n user: <sosp><13><235><13><235><13><235><13><136><622><333><820><47><831><438><62><521><128><162><511><584><672><921><919><213><518><173><103><923><360><47><477><628><640><933><450><204><998><99><467><304><933><450><204><91><162><511><680><790><64><754><480><754><856><751><445><376><444><472><111><260><615><371><899><136><162><790><159><180><998><347><196><930><982><70><737><231><480><295><450><91><162><275><10><672><311><775><296><213><197><125><760><432><327><432><60><3><78><402><111><615><904><476><136><13><136><13><235><13><365><eosp> ", "plain_text": "<anger> How could I dig burrows with short toe nails? EmoSDS: <sadness> I guess we just have to make the best of what we have, right?", "residual_length": 177, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Angry/0017_000669.npy", "dialogue_id": "1555_1"}
