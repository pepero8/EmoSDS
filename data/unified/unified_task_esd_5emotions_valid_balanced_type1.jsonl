{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> So, have you finished the project yet?\nuser: <happiness> Yeah, I just wrapped it up last night!\nEmoSDS: <surprise> Really? That’s awesome!\n user: <sosp><13><592><748><79><748><79><317><422><136><876><274><47><360><320><128><162><347><467><292><300><557><47><360><320><583><125><493><851><425><43><62><879><524><637><66><790><231><983><655><856><370><31><757><136><592><13><235><592><365><eosp> ", "plain_text": "<surprise> At the end of four. EmoSDS: <happiness> Wow, that’s a big achievement! We should celebrate!", "residual_length": 90, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Surprise/0018_001419.npy", "dialogue_id": "88_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> So, how did everything go with the team meeting yesterday?\nuser: <anger> It went terribly; they completely ignored my suggestions!\nEmoSDS: <sadness> I'm really sorry to hear that. It's frustrating when your ideas aren't valued.\n user: <sosp><13><592><79><291><79><291><79><592><136><876><274><628><640><304><111><524><347><309><487><918><350><232><319><98><292><376><879><524><212><104><295><159><180><121><120><111><615><862><601><171><889><173><856><758><930><615><371><158><467><58><403><643><757><136><13><136><13><291><13><136><365><eosp> ", "plain_text": "<surprise> I thank you for this mercy! EmoSDS: <surprise> Wait, are you serious? That’s amazing news!", "residual_length": 110, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Surprise/0014_001532.npy", "dialogue_id": "1720_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Have you heard that fairy shoemaker story before?\nuser: <happiness> Yeah, it's such a fun tale! I love the twist at the end.\nEmoSDS: <sadness> I always felt bad for Finn, though. He didn't really get what he wanted.\n user: <sosp><13><136><748><136><837><79><949><524><347><309><918><360><320><125><760><432><36><125><760><487><159><62><879><524><313><347><487><918><42><856><486><304><930><982><70><737><376><20><889><760><432><350><304><232><450><162><584><425><43><856><31><701><757><136><13><235><13><235><13><136><13><136><365><eosp> ", "plain_text": "<surprise> Finn and the fairy shoemaker. EmoSDS: <happiness> Wait, really? I never expected that twist! It caught me off guard!", "residual_length": 112, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Surprise/0018_001521.npy", "dialogue_id": "592_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I was thinking about our plans for the weekend.\nuser: <happiness> That sounds great! I can't wait to get together.\nEmoSDS: <neutral> But we still need to figure out the details.\n user: <sosp><13><291><13><136><13><291><13><136><105><283><304><41><879><524><171><384><125><278><286><125><760><487><958><831><743><47><145><277><545><131><128><618><136><79><291><79><757><136><616><13><136><489><274><47><28><41><615><223><10><737><425><43><213><20><91><162><584><871><64><213><20><45><808><125><197><43><213><983><78><879><226><524><66><790><754><295><486><848><472><998><121><425><43><856><184><31><136><128><136><79><136><79><136><365><eosp> ", "plain_text": "<surprise> If not, I shall go no further. EmoSDS: <neutral> Wait, why do you feel that way? Let’s talk it through.", "residual_length": 197, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Surprise/0019_001635.npy", "dialogue_id": "1146_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you hear about the legend they talk about in town?\nuser: <happiness> Yeah, I find it fascinating! So many stories come from that.\nEmoSDS: <sadness> But it's kind of tragic, isn’t it? Something so beautiful meeting such an end.\n user: <sosp><13><381><13><136><13><136><13><511><680><790><231><173><856><295><997><861><204><861><811><301><231><173><108><320><583><72><328><371><158><557><136><557><918><42><856><56><85><486><304><300><557><958><3><523><958><108><103><583><493><275><783><104><159><848><450><522><68><98><292><283><304><42><295><848><472><260><615><371><476><781><136><79><136><79><962><79><962><136><166><291><592><136><162><99><487><831><47><28><360><320><966><158><425><227><36><125><879><524><66><790><517><441><360><350><470><376><889><250><125><599><72><111><615><371><904><371><476><136><79><592><136><592><291><592><365><eosp> ", "plain_text": "<surprise> Born once every one hundred years, dies in flames! EmoSDS: <happiness> That's such an intense picture! It really adds to the legend's mystery.", "residual_length": 234, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Surprise/0019_001627.npy", "dialogue_id": "1106_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <sadness> It's been hard to accept that things have changed so much.\nuser: <neutral> Yeah, I guess we just have to adapt, right?\nEmoSDS: <happiness> But at least we have each other to get through it!\n user: <sosp><79><136><616><13><291><13><136><274><47><1><628><304><111><615><269><371><158><657><171><125><889><760><43><172><795><568><110><566><603><45><121><316><450><204><91><162><680><243><480><866><751><47><579><62><879><524><158><425><159><985><995><985><890><159><545><125><760><432><927><470><454><125><919><20><213><173><203><930><982><70><10><476><79><136><13><291><13><136><13><136><13><291><136><13><365><eosp> ", "plain_text": "<surprise> I smell the breath of an English. EmoSDS: <neutral> Oh, really? I didn't expect that. What makes you say that?", "residual_length": 146, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Surprise/0013_001533.npy", "dialogue_id": "651_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> So, what do you think we should do next?\nuser: <happiness> I think we should explore the area a bit more.\nEmoSDS: <sadness> Yeah, but I just wish we had more time.\n user: <sosp><511><136><79><235><79><422><136><235><136><876><274><47><360><277><545><156><589><354><591><354><880><517><432><360><432><350><470><454><493><949><524><571><347><487><304><450><128><584><98><309><350><454><889><493><288><511><275><737><376><890><103><930><949><70><737><104><856><831><856><758><450><128><574><136><162><499><487><432><36><583><125><905><701><618><757><136><13><235><13><365><eosp> ", "plain_text": "<surprise> At length they came to a sharp bend. EmoSDS: <surprise> Wait, really? I didn't expect that! What do you think is there?", "residual_length": 121, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0016/Surprise/0016_001717.npy", "dialogue_id": "1547_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I usually eat my breakfast at seven.\nuser: <neutral> Did you forget it today?\nEmoSDS: <sadness> I didn't have time, I overslept.\n user: <sosp><13><291><592><136><13><136><13><291><13><204><861><301><231><173><958><108><360><320><125><493><288><275><10><196><906><376><472><933><524><313><347><159><104><85><486><304><292><403><232><643><162><136><79><592><369><291><13><861><301><861><301><57><890><43><104><486><304><472><930><982><682><737><561><109><204><91><162><680><997><85><866><368><1><41><128><584><672><949><524><879><196><918><283><203><360><320><260><615><371><268><144><328><371><476><457><136><13><136><13><365><eosp> ", "plain_text": "<surprise> One two three, where is your breakfast. EmoSDS: <anger> It's not funny! I told you I was running late!", "residual_length": 172, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Surprise/0012_001686.npy", "dialogue_id": "1395_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Hey, did you finish that report we talked about?\nuser: <happiness> Yeah, I just wrapped it up! It turned out really well.\nEmoSDS: <happiness> That's awesome! I'm excited to see it.\n user: <sosp><13><83><433><709><544><166><592><291><13><136><13><666><511><680><936><517><441><898><304><283><304><227><472><111><371><158><557><585><136><105><196><304><113><450><584><526><371><899><144><511><98><292><304><42><43><120><103><472><260><615><223><862><171><889><760><432><927><470><58><643><701><136><13><136><13><136><13><136><13><433><136><13><365><eosp> ", "plain_text": "<surprise> please excuse me. EmoSDS: <neutral> Sure, no problem. What do you need?", "residual_length": 114, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Surprise/0014_001447.npy", "dialogue_id": "224_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I think we should agree on the deadline soon.\nuser: <sadness> It's tough to stay motivated with all the pressure.\nEmoSDS: <happiness> But we can make this work if we stay positive!\n user: <sosp><79><748><79><592><422><592><136><876><274><47><360><320><128><162><511><347><467><232><292><304><442><320><583><493><686><159><985><879><524><212><66><231><983><231><237><754><856><758><370><701><757><79><136><592><13><235><13><365><eosp> ", "plain_text": "<surprise> At the end of four. EmoSDS: <happiness> Wow, I didn't expect that timing! This could actually be a good thing!", "residual_length": 78, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0016/Surprise/0016_001419.npy", "dialogue_id": "92_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <sadness> I can't believe he's gone, it feels like just yesterday we were working together.\nuser: <happiness> I remember how excited he was to start that project!\nEmoSDS: <anger> And now, all of that is just gone because of his accident.\n user: <sosp><13><79><136><79><592><291><13><291><13><136><347><998><347><425><227><120><320><260><615><223><40><196><292><546><376><472><260><615><268><144><275><10><906><376><338><292><232><933><450><204><91><162><275><76><70><783><58><300><42><605><754><295><486><304><393><472><260><158><425><43><831><438><831><261><41><128><511><98><196><292><376><933><204><91><162><680><597><159><43><918><432><350><304><930><70><737><425><159><36><583><125><905><701><13><136><13><291><13><136><13><365><eosp> ", "plain_text": "<surprise> This used to be Jerry's occupation. EmoSDS: <happiness> Really? I didn't know he had worked here, that's so interesting!", "residual_length": 165, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Surprise/0013_001433.npy", "dialogue_id": "159_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe we finally won the game!\nuser: <happiness> Yeah, it was such an amazing effort from everyone!\nEmoSDS: <neutral> I didn't expect the ending to go that way.\n user: <sosp><13><709><291><709><544><136><13><136><13><235><136><876><274><360><583><125><760><304><292><933><91><162><511><10><309><442><360><320><545><128><574><511><680><133><790><173><103><930><982><615><269><904><371><158><425><43><751><438><568><213><370><402><91><757><136><13><136><13><136><13><365><eosp> ", "plain_text": "<surprise> And they did push so! EmoSDS: <surprise> Wow, I can't believe they really went for it like that!", "residual_length": 98, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Surprise/0015_001490.npy", "dialogue_id": "439_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I told her a joke yesterday.\nuser: <happiness> Oh, I love jokes! What was it about?\nEmoSDS: <neutral> It was just a cheesy pun, nothing special.\n user: <sosp><544><13><79><136><79><291><79><592><79><592><136><837><70><737><467><292><700><292><700><376><20><45><354><591><898><487><368><918><47><28><62><524><899><128><162><275><618><10><464><757><136><13><136><291><13><365><eosp> ", "plain_text": "<surprise> She laughed. EmoSDS: <happiness> That's great! It must've been a good one!", "residual_length": 91, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Surprise/0011_001654.npy", "dialogue_id": "1237_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I think we should discuss the project today.\nuser: <happiness> That sounds great! I'm excited to hear your ideas.\nEmoSDS: <neutral> I've been working on some new concepts that might really help us.\n user: <sosp><13><83><433><6><709><544><136><592><136><489><274><958><751><62><995><524><879><66><790><231><213><890><304><111><615><371><158><425><487><368><1><120><131><450><162><99><618><196><757><136><79><592><136><592><13><742><136><13><291><162><511><584><672><43><261><62><889><760><927><432><320><583><125><905><701><136><13><742><136><13><136><13><365><eosp> ", "plain_text": "<surprise> A voice said: Come in. EmoSDS: <surprise> Wow, I didn't expect that! What could it be?", "residual_length": 136, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Surprise/0014_001687.npy", "dialogue_id": "1402_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <anger> I can't believe we are still discussing this!\nuser: <sadness> I really thought we could find a way.\nEmoSDS: <happiness> But look at how far we've come already!\n user: <sosp><79><748><592><13><235><13><57><890><113><450><162><98><309><918><360><583><760><47><277><545><125><493><204><511><99><783><376><167><890><103><320><450><128><328><371><158><425><43><42><831><856><758><31><757><136><114><13><235><13><365><eosp> ", "plain_text": "<surprise> We can not do it sir. EmoSDS: <surprise> Wait, what do you mean we can't do it? That’s unexpected!", "residual_length": 79, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0016/Surprise/0016_001646.npy", "dialogue_id": "1203_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> So, what do you think about the hill trip this weekend?\nuser: <happiness> I think it’ll be great to get out and enjoy nature.\nEmoSDS: <neutral> Yeah, I agree. We should pack some snacks for the hike.\n user: <sosp><13><136><13><291><13><136><13><291><13><136><998><121><425><442><320><615><268><144><275><10><737><597><856><108><36><583><493><204><584><783><43><213><445><180><930><260><268><144><328><708><10><906><376><180><998><121><487><159><640><333><309><918><304><918><203><213><45><701><136><13><291><13><365><eosp> ", "plain_text": "<surprise> this turn goes to the hill. EmoSDS: <surprise> Wait, are we seriously doing that now? That’s unexpected!", "residual_length": 109, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Surprise/0011_001526.npy", "dialogue_id": "615_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I've been looking for my sunglasses everywhere.\nuser: <happiness> Oh, I remember you had them at the park!\nEmoSDS: <neutral> Yeah, but I thought I left them in the car.\n user: <sosp><13><291><136><13><136><13><291><13><136><171><204><998><347><121><487><645><557><128><489><958><743><47><477><1><304><283><232><128><162><511><584><672><921><919><890><103><450><162><601><998><760><487><368><820><47><579><41><128><574><162><511><98><672><333><918><360><41><128><76><70><982><70><223><268><144><347><487><360><432><481><36><583><250><701><136><365><eosp> ", "plain_text": "<surprise> The eye could not catch them. EmoSDS: <neutral> That's so strange, maybe they just fell out somewhere.", "residual_length": 117, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Surprise/0012_001556.npy", "dialogue_id": "758_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe we finally made plans for Valentine’s Day!\nuser: <happiness> Yeah, I’m really looking forward to it!\nEmoSDS: <neutral> Just gotta make sure everything goes as planned.\n user: <sosp><79><748><79><592><79><592><136><162><511><347><467><292><304><300><918><557><47><360><320><125><493><777><686><360><261><62><879><524><313><347><487><368><360><62><998><338><292><304><376><109><861><20><173><856><486><304><949><524><212><790><231><655><237><856><295><545><450><128><162><511><275><10><309><292><283><128><328><524><347><672><757><592><13><235><13><365><eosp> ", "plain_text": "<surprise> The end of February fourteenth. EmoSDS: <happiness> I know, right? It's gonna be memorable!", "residual_length": 126, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Surprise/0018_001691.npy", "dialogue_id": "1419_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> Can you believe how playful she is today?\nuser: <neutral> Yeah, she's always full of energy.\nEmoSDS: <sadness> I just wish she wouldn't be so clumsy sometimes.\n user: <sosp><13><709><235><709><544><136><592><13><369><13><136><837><311><907><856><62><91><128><574><511><680><133><311><775><831><438><831><438><831><404><568><213><861><57><380><432><545><522><557><136><557><105><304><442><125><493><288><708><10><196><926><376><292><376><104><295><128><616><489><958><743><47><477><918><350><283><643><333><757><13><291><13><365><eosp> ", "plain_text": "<surprise> Her paw went into your eye? EmoSDS: <happiness> It was surprising, but at least I know she was just trying to play.", "residual_length": 127, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Surprise/0015_001620.npy", "dialogue_id": "1072_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I love watching documentaries about animals!\nuser: <neutral> Yeah, they’re so interesting to learn about.\nEmoSDS: <surprise> Did you know they can eat up to 40 pounds of bamboo a day?\n user: <sosp><13><136><235><13><136><13><235><13><171><301><57><292><232><58><616><136><489><958><523><110><213><400><615><371><183><467><292><933><450><162><680><956><333><309><432><918><360><320><522><159><173><831><438><751><545><450><493><998><708><10><196><292><232><933><998><338><292><283><232><196><128><557><104><295><486><432><130><125><493><998><121><159><120><472><260><904><259><158><467><227><376><919><20><370><213><136><757><592><13><235><13><365><eosp> ", "plain_text": "<surprise> We all see panda on TV or in the zoo. EmoSDS: <happiness> Right? They really capture our hearts with their cuteness!", "residual_length": 167, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Surprise/0017_001544.npy", "dialogue_id": "702_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you get a chance to think about our plan?\nuser: <happiness> Yeah, I think it could work really well!\nEmoSDS: <neutral> That’s great to hear! So, how should we proceed?\n user: <sosp><13><291><13><136><13><291><13><136><105><283><304><41><879><524><171><384><125><278><286><125><760><487><958><831><743><47><145><277><545><131><128><618><136><79><291><79><757><136><616><13><136><489><274><47><28><41><615><223><10><737><425><43><213><20><91><162><584><871><64><213><20><45><808><125><197><43><213><983><78><879><226><524><66><790><754><295><486><848><472><998><121><425><43><856><184><31><136><128><136><79><136><79><136><365><eosp> ", "plain_text": "<surprise> If not, I shall go no further. EmoSDS: <happiness> Wow, I didn't expect that! Let's make sure we explore all options together.", "residual_length": 197, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Surprise/0019_001635.npy", "dialogue_id": "1150_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Have you checked the latest reports on the asteroids?\nuser: <sadness> I heard there might be more of them coming our way.\nEmoSDS: <happiness> But we still have time to prepare if we act quickly!\n user: <sosp><13><136><291><13><291><13><136><13><136><105><368><152><47><579><400><615><223><268><144><275><737><104><480><231><173><890><103><304><933><128><162><511><347><362><921><85><486><292><304><333><311><296><108><583><125><770><104><295><848><587><998><522><425><120><472><125><493><288><708><10><977><112><301><57><890><103><522><58><403><933><879><524><66><790><958><831><743><438><743><404><743><47><1><432><320><62><879><524><476><757><136><291><13><136><365><eosp> ", "plain_text": "<surprise> Asteroid three hundred and twenty five. EmoSDS: <happiness> Wait, that's amazing news! What did you find out?", "residual_length": 157, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Surprise/0013_001463.npy", "dialogue_id": "308_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I thought he had already found his way back home.\nuser: <sadness> I wish I could have gone with him. It feels so lonely without him.\nEmoSDS: <happiness> Don't worry, I'm sure he'll come back soon, and you'll have so many stories to tell!\n user: <sosp><13><544><83><291><83><136><83><709><622><98><309><292><304><376><20><890><472><111><615><428><223><268><144><275><158><467><304><43><213><180><125><121><751><62><879><524><212><66><231><110><523><231><831><370><754><856><203><320><260><615><428><223><268><144><476><10><618><464><757><136><13><291><13><136><13><365><eosp> ", "plain_text": "<surprise> He was still in the forest! EmoSDS: <surprise> Wait, what? I thought he made it out! Is he really still out there?", "residual_length": 111, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Surprise/0011_001453.npy", "dialogue_id": "255_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> You seem pretty lost in thought right now.\nuser: <sadness> It's just been a tough week, you know?\nEmoSDS: <happiness> I get that, but hey, we can always find some light together!\n user: <sosp><13><291><79><136><291><369><13><136><13><136><105><304><933><879><524><511><347><309><304><350><933><454><889><125><889><760><958><751><320><998><347><121><202><561><486><454><125><452><403><292><546><376><20><57><173><43><304><283><304><320><933><128><162><328><371><476><196><136><13><136><13><136><13><291><13><365><eosp> ", "plain_text": "<surprise> If they mother knew it. EmoSDS: <happiness> Wow, I didn’t expect that! It sounds like there’s more to the story!", "residual_length": 109, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Surprise/0012_001509.npy", "dialogue_id": "530_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> It's been a quiet day so far.\nuser: <happiness> I’m glad we finally got some good news!\nEmoSDS: <sadness> Unfortunately, not everything turned out as expected.\n user: <sosp><13><136><79><291><79><291><592><136><162><998><347><487><360><918><360><36><125><998><121><487><43><42><856><295><109><997><890><103><260><966><260><158><425><159><56><997><85><104><866><644><985><91><162><680><133><311><173><237><856><295><31><443><128><162><136><162><511><275><10><476><757><136><13><136><13><136><13><291><136><13><136><13><365><eosp> ", "plain_text": "<surprise> Then there was a report. EmoSDS: <happiness> Wow, really? I wasn't expecting that at all!", "residual_length": 112, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Surprise/0014_001480.npy", "dialogue_id": "387_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I guess we just have to wait and see what the weather does.\nuser: <happiness> It looks like we might actually enjoy it outdoors!\nEmoSDS: <neutral> True, I hope it stays sunny for longer.\n user: <sosp><13><83><709><291><709><544><13><369><291><13><136><13><861><301><57><890><43><213><616><162><511><105><918><350><360><583><125><760><283><292><403><215><333><389><47><743><438><568><213><521><128><136><162><511><105><292><304><393><450><162><275><10><467><304><933><522><120><304><125><997><866><432><927><350><470><454><125><701><196><136><79><291><79><136><622><98><661><98><292><393><111><615><371><269><371><394><487><360><918><360><918><350><360><432><120><131><450><162><99><618><196><757><592><13><136><13><291><13><136><365><eosp> ", "plain_text": "<surprise> Well anyhow it didn't rain, he said. EmoSDS: <surprise> Really? I didn't expect him to say that!", "residual_length": 173, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Surprise/0012_001500.npy", "dialogue_id": "485_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Have you thought about what we might cook together?\nuser: <happiness> I was thinking maybe a nice stew with fresh veggies!\nEmoSDS: <happiness> That sounds perfect! I can already smell it.\n user: <sosp><13><291><13><136><13><489><958><751><159><320><111><615><371><862><162><499><487><368><261><320><930><70><737><104><213><20><91><574><162><511><778><133><311><296><831><795><47><277><545><128><574><162><511><275><10><597><906><43><376><926><376><926><701><757><136><13><291><13><365><eosp> ", "plain_text": "<surprise> A special pot too. EmoSDS: <surprise> Wait, what makes it so special? Tell me more!", "residual_length": 108, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Surprise/0020_001722.npy", "dialogue_id": "1571_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Have you thought about how that will affect your budget?\nuser: <happiness> Yeah, but it feels worth it for the extra benefits.\nEmoSDS: <sadness> I just hope it doesn’t lead to any financial strain.\n user: <sosp><79><235><79><422><136><616><136><13><235><511><274><831><47><360><320><450><128><162><680><19><432><327><15><300><333><152><820><47><579><41><524><790><751><159><985><128><162><511><584><871><494><921><243><480><866><856><172><47><108><583><197><557><128><616><162><489><958><399><213><983><20><811><861><301><57><486><292><232><128><98><300><557><162><557><368><820><47><918><360><545><128><584><10><982><223><268><144><275><737><104><866><751><438><751><88><579><88><757><136><79><592><291><592><136><592><13><365><eosp> ", "plain_text": "<surprise> I pay half a crown a week extra. EmoSDS: <surprise> Wait, really? I didn’t think it would be that much!", "residual_length": 184, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Surprise/0019_001574.npy", "dialogue_id": "846_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I heard there's been some trouble with the shipment.\nuser: <neutral> Yeah, the crew's been struggling with the weather lately.\nEmoSDS: <happiness> But I think we can still make the deadline!\n user: <sosp><13><79><235><79><592><136><162><136><98><300><333><820><47><62><879><128><275><158><120><933><125><493><288><708><10><311><523><108><889><997><104><486><103><304><111><371><183><292><376><879><569><966><158><425><360><130><125><557><918><432><327><304><454><125><779><104><486><304><472><354><715><354><517><751><368><47><360><545><923><856><370><31><757><136><13><235><13><365><eosp> ", "plain_text": "<surprise> Captain Tom receives an angry letter. EmoSDS: <surprise> Oh really? I didn't expect that at all! What does it say?", "residual_length": 136, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Surprise/0018_001599.npy", "dialogue_id": "971_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I wonder if anyone really believes in witches these days.\nuser: <sadness> It's hard to believe in magic when everything feels so real.\nEmoSDS: <happiness> But stories about witches can be so much fun, don't you think?\n user: <sosp><13><136><291><13><136><13><742><13><291><136><837><371><904><371><158><487><368><360><320><450><204><998><347><121><487><43><20><861><301><57><890><432><918><120><320><128><162><76><70><10><196><476><396><136><13><136><13><136><13><291><13><136><13><365><eosp> ", "plain_text": "<surprise> Said the witch. EmoSDS: <happiness> Wow, I didn't expect that! What a twist!", "residual_length": 95, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Surprise/0014_001498.npy", "dialogue_id": "479_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <sadness> I can't believe how unfair this situation is.\nuser: <neutral> We should at least figure out a solution.\nEmoSDS: <happiness> I think we can still make it work if we try!\n user: <sosp><13><79><291><79><592><79><291><422><592><13><136><511><105><292><304><933><564><162><511><105><283><304><320><966><158><442><120><583><125><493><91><162><511><680><10><196><309><304><933><450><128><162><584><162><347><618><557><136><616><557><876><368><47><360><545><128><315><136><13><136><13><136><958><523><110><509><78><701><524><136><544><13><291><13><592><13><592><136><13><365><eosp> ", "plain_text": "<surprise> it isn't picked at all. EmoSDS: <happiness> Wow, really? I thought it would be selected!", "residual_length": 136, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Surprise/0012_001616.npy", "dialogue_id": "1056_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I heard that she might not come to the meeting.\nuser: <happiness> Oh, really? That sounds like a relief!\nEmoSDS: <sadness> Yeah, I just wish she felt more comfortable sharing her thoughts.\n user: <sosp><13><136><291><13><291><13><837><70><196><292><232><393><111><615><269><371><158><425><487><368><918><360><545><522><120><583><125><760><487><43><159><320><260><615><269><428><40><158><425><43><751><316><985><204><91><162><275><10><467><906><376><251><450><998><789><20><879><212><66><20><983><231><173><792><1><304><283><111><615><371><269><371><476><781><136><13><136><13><291><136><863><13><365><eosp> ", "plain_text": "<surprise> She said in subdued voice. EmoSDS: <neutral> It's surprising how some people choose to speak so softly, isn't it?", "residual_length": 155, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Surprise/0013_001663.npy", "dialogue_id": "1281_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> That's interesting, owls are usually quite graceful.\nuser: <happiness> Yeah, and they're fascinating to watch at night!\nEmoSDS: <surprise> I didn't know they could be so bold during the day.\n user: <sosp><13><291><13><136><13><136><162><347><292><232><557><136><489><274><831><743><438><110><983><231><983><213><879><524><936><354><142><898><890><376><20><890><103><36><583><760><487><368><47><261><62><91><574><162><511><680><790><64><445><890><43><103><320><930><982><70><269><70><476><781><909><79><291><592><365><eosp> ", "plain_text": "<surprise> The owl flew into a bush. EmoSDS: <neutral> That's odd. I've never seen an owl act like that.", "residual_length": 135, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Surprise/0019_001519.npy", "dialogue_id": "580_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can’t believe how beautiful the festival was!\nuser: <neutral> Yeah, it was nice to see everyone enjoying themselves.\nEmoSDS: <sadness> It’s a shame it only happens once a year.\n user: <sosp><13><592><235><592><235><136><79><592><136><837><371><158><487><360><103><930><353><76><982><223><268><144><162><275><10><196><906><376><213><370><213><36><583><125><72><259><121><425><43><856><103><450><353><76><682><783><919><231><173><103><927><304><933><450><99><10><899><997><890><103><450><162><511><686><467><300><918><47><360><320><128><328><571><371><183><304><718><454><493><584><949><524><887><66><487><368><47><918><350><283><643><196><79><333><757><79><136><79><757><592><136><235><13><365><eosp> ", "plain_text": "<surprise> Such tunes are joy to a dancing fay. EmoSDS: <happiness> I know, right? It makes me want to dance with them!", "residual_length": 150, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Surprise/0018_001559.npy", "dialogue_id": "773_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> So, what did you think of the festival yesterday?\nuser: <happiness> It was amazing! I really enjoyed the performances.\nEmoSDS: <neutral> That's great to hear! I missed out on most of it.\n user: <sosp><13><79><291><79><757><958><136><274><831><47><640><333><918><261><62><879><524><136><162><511><270><173><108><583><125><128><288><162><171><162><91><162><511><680><866><42><856><758><370><758><486><304><933><450><618><557><616><136><511><240><831><523><110><523><370><213><45><204><45><517><136><790><213><445><231><20><879><104><486><450><91><162><511><584><43><173><213><370><213><45><128><136><240><523><213><890><103><583><125><288><162><275><10><737><906><376><933><111><615><371><487><368><47><856><62><128><162><680><104><486><159><587><923><159><450><128><162><98><333><309><327><15><58><304><393><472><982><682><783><425><432><360><701><72><288><328><904><371><476><136><79><136><291><592><136><79><592><291><592><136><365><eosp> ", "plain_text": "<surprise> I have bunburyed all over goat on two separate occasions. EmoSDS: <surprise> Wow, really? I didn't expect that at all! What happened?", "residual_length": 251, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Surprise/0019_001413.npy", "dialogue_id": "61_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I'm glad we're baking together today!\nuser: <neutral> Yeah, it should be fun. What's the recipe again?\nEmoSDS: <neutral> We need a half pound of flour and two ounces of suet.\n user: <sosp><13><79><235><79><958><136><274><958><831><47><333><410><47><831><47><28><62><524><162><511><680><19><333><775><47><831><108><583><125><72><328><371><158><425><159><316><879><524><637><936><354><441><47><438><568><370><20><173><370><856><47><145><360><130><583><125><493><512><708><10><196><906><376><20><790><557><958><831><47><568><213><45><450><128><328><371><158><425><120><472><111><615><371><158><425><906><376><20><301><57><890><380><368><47><360><320><128><574><162><511><275><371><476><155><757><136><616><13><616><13><235><13><235><13><235><13><365><eosp> ", "plain_text": "<surprise> A half pounds of flour and two ounces suet. EmoSDS: <happiness> Wow, I wasn't expecting it to be that exact! This will make it interesting!", "residual_length": 191, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Surprise/0018_001514.npy", "dialogue_id": "555_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> So, did you finish the project yet?\nuser: <happiness> Yeah, I finally wrapped it up last night!\nEmoSDS: <surprise> Seriously? That's awesome! I thought you were still working on it.\n user: <sosp><13><136><13><291><13><136><13><136><876><487><227><545><564><162><328><371><269><371><158><487><368><360><320><472><260><171><125><760><43><751><445><20><811><301><57><380><368><918><334><304><283><701><757><136><585><136><72><930><70><737><487><368><831><261><103><923><120><472><450><204><162><99><487><432><334><304><393><472><747><966><371><183><304><700><232><403><643><136><13><136><13><291><136><13><365><eosp> ", "plain_text": "<surprise> It says no way! shouted Daisy. EmoSDS: <happiness> Wow, that's incredible! Daisy must be so excited!", "residual_length": 174, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Surprise/0020_001628.npy", "dialogue_id": "1111_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe how well the first act went!\nuser: <neutral> Yeah, it was pretty good. I thought the audience was really engaged.\nEmoSDS: <sadness> I hope the second act doesn't disappoint them.\n user: <sosp><13><291><13><235><136><876><820><47><28><41><128><574><13><511><176><921><997><85><480><831><438><62><128><290><615><371><904><371><158><425><368><360><41><128><584><98><300><130><583><760><557><47><190><545><450><584><526><615><904><371><183><467><292><283><701><757><136><701><757><592><13><291><13><365><eosp> ", "plain_text": "<surprise> Act drop second act scene. EmoSDS: <anger> Why would you say that? We can't just drop it! We need to keep the momentum!", "residual_length": 131, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Surprise/0017_001510.npy", "dialogue_id": "534_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I think we should consider all the options before making a decision.\nuser: <happiness> Yeah, that's true! We have so many possibilities.\nEmoSDS: <sadness> But what if we end up choosing the wrong one?\n user: <sosp><13><291><13><136><622><196><292><283><583><370><958><360><432><15><58><128><584><871><375><311><523><213><173><360><120><159><62><879><524><66><104><856><360><320><128><526><371><158><487><432><918><261><62><128><162><680><790><751><438><523><198><524><757><136><13><136><13><365><eosp> ", "plain_text": "<surprise> He might call it, for example. EmoSDS: <happiness> That would be really unexpected, wouldn't it? I hope it opens up a new perspective for us!", "residual_length": 112, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Surprise/0017_001515.npy", "dialogue_id": "559_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I never really thought about my name that way.\nuser: <happiness> It's just fun to imagine what it would be like.\nEmoSDS: <sadness> Sometimes I wish I could change it, though.\n user: <sosp><13><235><13><136><13><136><13><136><235><13><511><584><98><672><333><309><432><350><454><452><292><304><295><125><760><432><327><350><454><493><91><162><511><680><338><292><933><889><231><754><758><311><213><603><898><382><42><295><486><283><918><47><579><400><615><904><371><904><371><476><757><114><13><291><13><365><eosp> ", "plain_text": "<surprise> Can your name be more hilarious? EmoSDS: <surprise> Wow, I don’t know! What do you have in mind?", "residual_length": 145, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Surprise/0017_001676.npy", "dialogue_id": "1348_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Have you heard about the new cafe that opened downtown?\nuser: <happiness> Yeah, I went there last week! The pastries were amazing.\nEmoSDS: <sadness> That's great, but I couldn't make it. I heard they had a special offer.\n user: <sosp><13><291><13><136><13><235><13><837><70><371><183><292><700><376><715><354><517><958><831><47><820><47><820><47><579><879><524><128><162><511><708><10><155><457><136><114><13><235><13><136><13><136><13><365><eosp> ", "plain_text": "<surprise> She laughed. EmoSDS: <happiness> Wow, that's unexpected! What made her laugh?", "residual_length": 83, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Surprise/0019_001654.npy", "dialogue_id": "1241_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Hey, can we talk about the upcoming event?\nuser: <sadness> I just feel like no one is taking this seriously.\nEmoSDS: <happiness> Don't worry, I think everything will turn out great!\n user: <sosp><511><79><422><592><136><171><125><760><487><43><445><890><103><587><450><204><151><889><760><432><36><125><493><328><347><158><425><487><113><111><526><371><158><368><62><879><162><99><487><958><108><89><889><493><91><162><680><133><311><856><295><486><304><522><292><933><91><511><680><159><442><320><472><260><601><171><125><360><320><111><615><371><904><371><476><757><136><13><235><13><235><13><365><eosp> ", "plain_text": "<surprise> No admittance except on party business. EmoSDS: <happiness> Oh! I didn’t realize you were feeling that way. What's up?", "residual_length": 133, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0016/Surprise/0016_001672.npy", "dialogue_id": "1330_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe we actually made it to the old mansion!\nuser: <neutral> Yeah, it definitely looks like it hasn't been touched in years.\nEmoSDS: <sadness> It's a shame, I thought it would be more welcoming.\n user: <sosp><136><79><291><79><592><13><837><288><162><347><487><120><320><125><358><998><760><752><368><152><918><41><400><615><371><904><571><183><292><304><111><371><524><144><511><571><347><425><304><470><454><493><472><111><524><571><347><487><304><15><58><111><615><269><158><958><831><523><370><861><301><57><890><159><180><998><347><487><159><113><450><128><162><511><584><871><311><958><831><404><28><521><128><162><204><861><301><57><890><43><432><60><159><985><91><162><290><615><904><371><476><457><136><79><136><381><136><13><365><eosp> ", "plain_text": "<surprise> The nastiest things they saw were the cobwebs. EmoSDS: <happiness> Well, at least we know it adds to the spooky atmosphere!", "residual_length": 184, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Surprise/0019_001445.npy", "dialogue_id": "214_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> What a great morning it is today.\nuser: <happiness> I love the sunshine! It puts me in such a good mood.\nEmoSDS: <neutral> Yeah, it really brightens things up.\n user: <sosp><13><709><544><592><136><592><291><592><136><861><301><57><890><304><663><933><564><162><584><196><171><601><171><125><760><432><172><47><568><213><583><889><760><958><172><432><877><889><760><432><42><856><382><58><933><564><511><708><158><487><368><47><261><320><450><128><162><328><904><371><476><457><136><13><291><13><742><13><742><291><136><13><365><eosp> ", "plain_text": "<surprise> Wake now my merry tads! EmoSDS: <surprise> Whoa! You’re up early! What’s the occasion?", "residual_length": 121, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Surprise/0014_001542.npy", "dialogue_id": "694_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I read a really interesting article about plants last night.\nuser: <happiness> That sounds cool! I love learning about nature.\nEmoSDS: <neutral> Yeah, it was surprising to learn how some plants can survive in tough conditions.\n user: <sosp><13><837><524><235><524><183><338><292><304><42><856><295><848><587><125><760><487><958><47><1><320><998><121><159><295><480><997><85><486><919><926><921><524><128><162><584><171><125><197><43><213><445><655><237><295><930><111><615><371><428><899><91><136><162><136><116><921><997><480><907><831><47><28><47><568><213><983><20><45><879><128><162><511><275><769><371><10><476><781><136><909><79><235><79><381><79><592><365><eosp> ", "plain_text": "<surprise> Fear neither root nor sprout! EmoSDS: <happiness> It's amazing how resilience can show up in nature, just like in life!", "residual_length": 155, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Surprise/0019_001605.npy", "dialogue_id": "998_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you see that strange light in the sky?\nuser: <happiness> Yeah! It was so beautiful, like a fireworks show!\nEmoSDS: <sadness> I wish I could've shared that moment with someone.\n user: <sosp><79><235><79><958><136><274><360><545><450><998><680><180><121><898><304><454><493><288><511><708><862><171><889><173><108><172><918><47><1><320><260><259><899><311><296><64><438><856><754><856><295><587><450><618><196><757><13><235><13><235><13><365><eosp> ", "plain_text": "<surprise> I blinked my eyes hard. EmoSDS: <happiness> Right? It was totally unexpected and amazing!", "residual_length": 96, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0016/Surprise/0016_001535.npy", "dialogue_id": "657_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I heard they had some trouble with the crop last season.\nuser: <sadness> Yeah, it was a tough year for the farmers.\nEmoSDS: <happiness> But I've heard this year is looking much better!\n user: <sosp><13><291><13><136><369><291><13><511><347><121><159><879><524><637><66><790><104><754><758><103><930><260><615><223><268><144><665><467><292><304><42><295><561><103><320><998><121><487><304><472><111><615><904><371><158><425><43><445><103><450><997><85><480><866><831><743><438><743><47><477><1><918><283><196><333><79><136><13><291><13><136><13><365><eosp> ", "plain_text": "<surprise> The first year they sowed rye. EmoSDS: <happiness> Really? That’s exciting! I hope it grows well!", "residual_length": 120, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Surprise/0017_001629.npy", "dialogue_id": "1120_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Hey, did you check your bank account recently?\nuser: <sadness> Yeah, I did, and it wasn’t pretty.\nEmoSDS: <happiness> Maybe it's just a temporary setback, you can find a way to turn things around!\n user: <sosp><13><79><291><79><592><79><422><592><136><13><291><136><876><487><368><432><360><583><889><760><172><47><360><36><583><125><557><128><574><162><511><557><918><47><62><204><290><615><428><371><158><425><213><20><45><898><890><376><450><91><162><136><13><162><666><162><511><778><133><311><296><523><568><62><128><162><511><680><173><751><836><203><370><757><136><13><291><136><13><365><eosp> ", "plain_text": "<surprise> Am I an absolute pauper? EmoSDS: <neutral> It might seem that way, but there are always options to improve your situation.", "residual_length": 126, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Surprise/0011_001522.npy", "dialogue_id": "593_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I just think we should plan this out carefully.\nuser: <happiness> You're probably right, but we need to make a move soon!\nEmoSDS: <sadness> I know, but I'm just worried about what could happen.\n user: <sosp><13><592><291><13><136><13><291><13><136><917><301><20><811><301><231><173><831><103><587><923><486><304><292><700><376><20><811><861><204><997><301><57><890><304><292><304><522><304><470><454><493><879><524><212><66><790><231><237><754><480><889><760><432><918><432><918><172><47><108><583><125><905><757><136><937><136><757><136><13><136><13><365><eosp> ", "plain_text": "<surprise> What are you waiting for? man. EmoSDS: <happiness> I didn't realize you were so eager! Let's go for it!", "residual_length": 132, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Surprise/0013_001747.npy", "dialogue_id": "1689_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <sadness> It's been hard to accept that things have changed so much.\nuser: <neutral> Yeah, I guess we just have to adapt, right?\nEmoSDS: <happiness> But at least we have each other to get through it!\n user: <sosp><13><136><13><291><136><13><136><489><274><47><579><41><111><371><269><371><899><171><151><889><760><487><368><47><568><213><879><569><998><347><121><159><985><450><91><162><680><997><85><866><368><360><320><524><347><425><159><985><889><159><130><125><760><432><304><470><454><125><173><360><41><982><70><476><155><136><13><291><13><136><13><136><13><365><eosp> ", "plain_text": "<surprise> I smell the breath of an English. EmoSDS: <neutral> Oh, really? I didn't expect that. What makes you say that?", "residual_length": 141, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Surprise/0019_001533.npy", "dialogue_id": "651_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe we're finally going on this trip!\nuser: <neutral> Yeah, it's been a long time coming.\nEmoSDS: <surprise> I just found out that we can actually explore the Great Wall!\n user: <sosp><13><291><13><291><13><136><489><958><523><110><213><45><349><998><121><213><20><890><43><432><1><15><304><933><564><162><99><10><196><472><353><76><164><76><70><737><333><775><296><831><47><1><304><125><760><197><43><751><990><159><557><196><227><120><472><260><615><10><899><311><523><213><808><445><808><826><89><417><889><808><701><136><757><291><757><136><592><136><13><365><eosp> ", "plain_text": "<sadness> All the way to China is home. EmoSDS: <neutral> I guess it just shows how far we've come from where we started.", "residual_length": 173, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Sad/0020_001201.npy", "dialogue_id": "738_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you know they spend most of their time eating bamboo?\nuser: <happiness> Yeah, it's amazing how much they can eat in a day!\nEmoSDS: <surprise> I read that they can eat up to 28 pounds of bamboo daily!\n user: <sosp><13><136><13><291><13><136><291><136><772><204><861><301><57><486><292><304><43><218><958><831><523><110><484><213><178><111><615><269><371><10><183><467><292><933><564><162><574><162><511><680><956><333><918><47><172><481><36><583><125><493><851><487><43><751><645><958><795><108><583><125><493><288><162><99><10><196><98><292><700><933><995><998><338><292><403><58><136><13><291><13><240><231><655><295><557><432><36><583><125><728><125><121><159><180><472><260><158><425><227><376><20><701><757><136><757><291><863><291><136><13><291><13><365><eosp> ", "plain_text": "<sadness> We all see panda on TV or in the zoo. EmoSDS: <happiness> They’re such beautiful creatures, it's hard not to love them!", "residual_length": 231, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Sad/0020_001194.npy", "dialogue_id": "706_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I heard there was a big meeting yesterday.\nuser: <happiness> It went really well! Everyone was engaged.\nEmoSDS: <neutral> That's great to hear! I didn't expect that.\n user: <sosp><13><291><592><13><291><13><136><13><136><105><432><360><320><583><125><760><487><432><304><933><450><204><162><99><467><425><120><320><450><204><91><162><511><680><672><921><311><790><890><103><930><982><615><269><428><40><158><425><43><751><213><20><91><13><291><13><365><eosp> ", "plain_text": "<sadness> And they did push so! EmoSDS: <neutral> Oh, I'm sorry to hear that. Did it feel overwhelming?", "residual_length": 105, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Sad/0011_001140.npy", "dialogue_id": "436_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> What are you thinking for our next project?\nuser: <happiness> I was thinking we could do something creative!\nEmoSDS: <surprise> Oh really? That sounds exciting!\n user: <sosp><13><381><13><136><13><136><876><432><320><583><107><493><162><328><371><10><309><304><933><450><128><162><511><584><425><159><120><320><450><162><511><328><371><10><672><333><19><775><47><277><579><41><128><584><618><136><162><511><275><371><10><196><906><376><701><13><381><13><365><eosp> ", "plain_text": "<sadness> And tick a tack too. EmoSDS: <neutral> Is everything okay? You seem a bit down while saying that.", "residual_length": 105, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Sad/0012_001136.npy", "dialogue_id": "418_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> How was your day at work today?\nuser: <neutral> It was pretty standard, nothing out of the ordinary.\nEmoSDS: <happiness> That sounds good! I'm glad you had a smooth day.\n user: <sosp><13><592><13><592><13><381><13><235><13><235><13><171><889><173><751><108><213><583><889><125><926><930><70><158><425><43><159><320><450><328><615><223><899><171><861><301><231><173><108><36><583><125><72><260><862><171><889><760><958><172><47><438><568><62><879><524><66><557><958><751><438><751><213><62><91><128><162><524><136><162><511><347><487><43><751><320><966><767><425><36><125><120><227><120><131><128><162><13><235><13><365><eosp> ", "plain_text": "<sadness> Mum shuts one's mouth up, doesn't it. EmoSDS: <anger> Yeah, it’s frustrating when she does that, though.", "residual_length": 153, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Sad/0012_001308.npy", "dialogue_id": "1258_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you ever think we would have this much fun together?\nuser: <happiness> Honestly, I never imagined it would be so great!\nEmoSDS: <neutral> I feel the same way, it's just awesome to see how far we've come.\n user: <sosp><79><592><136><112><301><57><890><304><454><696><125><760><172><831><47><1><304><933><589><603><517><898><700><933><204><162><99><467><300><432><927><432><36><320><72><328><371><615><269><615><269><428><158><464><60><958><438><831><754><480><295><31><333><309><918><304><933><522><304><700><232><206><584><300><368><47><795><743><47><1><58><472><260><615><371><476><757><136><13><291><13><291><13><365><eosp> ", "plain_text": "<sadness> We nightly dance our heyday guise. EmoSDS: <neutral> It's just a memory now, isn’t it? I wish we could relive those moments.", "residual_length": 196, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Sad/0013_001161.npy", "dialogue_id": "539_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you get everything on your list?\nuser: <happiness> Yeah, I found some great deals today.\nEmoSDS: <neutral> That's awesome! What did you end up buying?\n user: <sosp><13><136><13><136><13><291><13><511><99><10><425><316><204><998><499><487><368><47><579><320><128><574><162><275><10><737><906><376><91><162><511><680><112><231><237><890><103><930><128><162><275><70><737><425><368><47><579><62><128><574><13><162><290><476><615><428><223><476><136><13><291><13><291><13><365><eosp> ", "plain_text": "<sadness> To buy two pork chops. EmoSDS: <neutral> I see, what’s making you feel down about it?", "residual_length": 130, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Sad/0011_001143.npy", "dialogue_id": "452_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> How was your day at work?\nuser: <neutral> It was alright, just the usual stuff.\nEmoSDS: <happiness> That’s good to hear! Did anything fun happen?\n user: <sosp><13><83><381><83><381><709><544><136><13><291><13><136><837><70><309><292><700><120><180><354><898><487><368><47><579><400><949><524><343><391><162><275><618><757><136><365><eosp> ", "plain_text": "<sadness> She laughed. EmoSDS: <neutral> I guess that's nice, but you don't sound too thrilled about it.", "residual_length": 69, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Sad/0011_001304.npy", "dialogue_id": "1238_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> So, how was your day today?\nuser: <happiness> It was great! I finally finished that project I've been working on.\nEmoSDS: <surprise> Really? That's amazing! What was the project about?\n user: <sosp><13><592><79><235><79><592><13><235><742><13><511><274><47><360><1><304><933><879><949><333><309><442><320><128><162><511><347><121><43><985><109><997><85><866><831><523><108><583><125><760><43><831><438><484><213><45><180><472><260><615><371><476><757><136><13><195><13><235><13><365><eosp> ", "plain_text": "<sadness> I've hit the wrong nose. EmoSDS: <sadness> I'm sorry to hear that. It sounds really painful.", "residual_length": 109, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Sad/0018_001149.npy", "dialogue_id": "1718_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I remember those carefree days, we had so much fun back then!\nuser: <neutral> Yeah, those were good times, but life has changed a lot since.\nEmoSDS: <sadness> It's hard to believe how quickly everything has shifted.\n user: <sosp><13><136><79><136><592><136><13><291><13><136><112><301><57><486><292><470><933><125><358><760><368><918><304><953><354><898><292><933><450><204><162><511><99><467><300><432><145><579><583><288><328><371><158><790><958><831><856><41><333><309><304><933><998><99><467><304><300><327><304><450><564><162><584><347><487><43><958><743><477><1><120><472><111><371><476><757><136><13><136><13><365><eosp> ", "plain_text": "<sadness> We nightly dance our heyday guise. EmoSDS: <neutral> It's tough to think about how things were, but I cherish those memories.", "residual_length": 162, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Sad/0015_001161.npy", "dialogue_id": "540_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I heard something strange last night.\nuser: <surprise> Really? What happened?\nEmoSDS: <sadness> It felt like someone was lurking around.\n user: <sosp><13><291><13><136><13><136><557><876><368><579><400><524><571><10><309><292><232><196><949><343><524><343><887><343><158><464><557><432><36><583><125><760><432><36><583><728><125><760><368><172><47><172><432><927><58><128><162><136><13><136><13><136><701><136><365><eosp> ", "plain_text": "<sadness> A thief in the night. EmoSDS: <sadness> That's really unsettling; it must've been terrifying.", "residual_length": 98, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Sad/0014_001366.npy", "dialogue_id": "1541_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Hey, have you seen the new adventure game that just came out?\nuser: <happiness> Yeah, I heard it’s really good! I can’t wait to play it.\nEmoSDS: <surprise> I didn’t expect you to be interested in that!\n user: <sosp><79><291><79><592><136><13><136><511><680><790><890><103><450><353><76><982><70><737><43><213><445><20><889><338><292><470><304><454><493><998><487><432><368><47><568><438><213><890><382><58><434><295><985><204><998><760><487><368><820><333><817><757><136><162><136><511><680><886><136><757><136><13><381><13><381><13><365><eosp> ", "plain_text": "<sadness> But show me now your map! EmoSDS: <anger> Why are you always so down? Can't you just enjoy the game and not mope around?", "residual_length": 108, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Sad/0019_001319.npy", "dialogue_id": "1312_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I just think you need to be more confident in your decisions.\nuser: <neutral> I understand that, but it's just a lot to think about right now.\nEmoSDS: <anger> You should have thought about that before! It’s frustrating!\n user: <sosp><13><83><433><6><709><136><544><13><136><291><136><511><680><790><890><43><103><450><998><889><760><958><795><404><438><583><889><760><958><751><985><125><728><125><760><197><958><47><261><178><320><328><615><428><158><425><295><770><728><760><197><159><985><204><270><487><368><47><438><213><445><985><128><162><125><701><757><79><365><eosp> ", "plain_text": "<sadness> But mom I'm not certain about. EmoSDS: <happiness> I know it feels tough right now, but I believe you’ll figure it out!", "residual_length": 124, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Sad/0013_001387.npy", "dialogue_id": "1643_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe how much you've grown since last summer!\nuser: <sadness> Yeah, but I miss the simplicity of those days.\nEmoSDS: <anger> It's hard to believe some people don’t appreciate our friendship.\n user: <sosp><13><83><235><709><136><544><13><235><13><136><79><196><333><918><320><966><354><517><332><831><856><103><587><353><76><682><737><159><877><889><760><172><47><438><568><178><62><879><524><899><128><162><511><584><672><311><856><213><45><998><99><158><425><130><36><125><493><275><708><10><977><20><890><159><111><615><371><268><171><125><673><292><403><304><432><31><757><136><13><235><13><136><235><136><13><365><eosp> ", "plain_text": "<sadness> His large mouth curled into a sneer. EmoSDS: <sadness> That sneer really shows how much he’s changed, huh?", "residual_length": 155, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Sad/0018_001214.npy", "dialogue_id": "800_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Have you talked to Paul lately?\nuser: <happiness> Yeah, he seemed really cheerful yesterday!\nEmoSDS: <surprise> That's great to hear! I didn't expect him to be so upbeat.\n user: <sosp><13><136><291><136><291><162><680><778><311><523><399><110><402><111><904><371><268><144><162><511><665><10><309><292><403><643><933><524><571><136><616><136><381><136><876><432><918><334><304><232><564><595><584><618><162><275><10><899><136><162><338><304><933><450><162><511><584><672><311><43><159><180><472><260><158><425><159><985><879><899><171><944><517><43><159><985><889><760><432><130><125><706><384><701><136><162><13><136><13><136><365><eosp> ", "plain_text": "<sadness> Paul's teeth ached because of lemon. EmoSDS: <neutral> Oh no, that's rough. I hope he finds something to ease the pain soon.", "residual_length": 154, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Sad/0019_001388.npy", "dialogue_id": "1648_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe we finally made it happen!\nuser: <neutral> Yeah, it was a long time coming.\nEmoSDS: <surprise> But why didn't he seem that excited when we announced it?\n user: <sosp><13><235><13><235><13><235><13><136><837><887><921><311><672><309><283><350><432><43><320><450><128><526><371><862><144><511><270><487><368><47><261><41><128><618><128><162><99><158><425><120><320><450><162><511><708><10><333><311><523><108><89><583><125><493><89><311><890><159><450><91><162><275><682><70><737><43><296><108><583><889><493><288><524><637><243><104><103><587><450><275><682><783><104><43><64><231><484><751><1><382><58><403><643><333><757><592><13><235><13><365><eosp> ", "plain_text": "<sadness> We expected Tom would jump for joy. EmoSDS: <neutral> It's disappointing to see him not as enthusiastic as we thought he would be.", "residual_length": 157, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Sad/0018_001141.npy", "dialogue_id": "442_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you ever go sailing on the bay before?\nuser: <happiness> Yeah, I loved that feeling of freedom on the water!\nEmoSDS: <neutral> It sounds amazing. It must be nice to get away from everything for a bit.\n user: <sosp><13><83><433><709><544><136><876><958><751><985><204><768><680><121><43><751><213><445><45><128><162><136><13><136><13><136><291><13><136><13><291><136><511><680><921><311><790><103><587><522><487><368><47><261><923><587><923><43><751><108><583><125><728><760><121><159><985><995><91><162><680><487><432><327><58><643><757><136><701><136><13><136><13><365><eosp> ", "plain_text": "<sadness> A boat put out-on the bay. EmoSDS: <neutral> I can see why you'd feel that way; it's beautiful but also a bit lonely.", "residual_length": 132, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Sad/0014_001245.npy", "dialogue_id": "949_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I'm really excited about our archery practice today!\nuser: <neutral> Yeah, I heard we have a new target set up.\nEmoSDS: <anger> But I can't believe Tom thought he could just take charge without asking us!\n user: <sosp><13><291><136><13><162><511><708><10><672><333><311><775><523><108><583><889><46><125><358><760><368><820><47><438><213><20><829><354><517><441><368><360><277><923><557><489><831><856><557><432><42><856><213><180><260><615><899><524><637><66><354><517><743><477><1><382><403><643><724><757><136><13><291><13><365><eosp> ", "plain_text": "<sadness> Tom now let our arrows fly! EmoSDS: <neutral> Oh, I guess we're just following along, aren't we?", "residual_length": 148, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Sad/0015_001120.npy", "dialogue_id": "338_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I think it's an interesting one.\nuser: <happiness> Yeah, I'm glad you find it interesting!\nEmoSDS: <neutral> It actually got me thinking about some stuff.\n user: <sosp><13><369><13><235><13><136><861><112><301><57><173><360><103><545><128><574><162><511><99><10><467><292><546><376><949><524><347><309><350><470><454><493><288><162><584><672><757><917><159><985><879><524><571><347><487><227><120><111><615><371><899><162><584><871><276><112><790><64><751><368><1><579><930><982><70><268><164><76><70><737><425><840><432><130><125><701><136><13><136><13><235><13><365><eosp> ", "plain_text": "<sadness> What do you think of this question? EmoSDS: <sadness> I guess it’s okay, but I’m not really in the mood to ponder right now.", "residual_length": 145, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0016/Sad/0016_001399.npy", "dialogue_id": "1701_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I finally finished reading that amazing book yesterday!\nuser: <neutral> That's really great to hear.\nEmoSDS: <neutral> I'm excited to talk about the main character's journey.\n user: <sosp><13><79><381><79><592><235><13><136><275><682><737><309><918><47><261><62><995><879><899><162><275><158><425><638><109><486><304><180><354><517><43><751><360><261><62><879><995><879><338><425><36><125><557><958><108><62><583><429><493><121><120><472><450><204><511><686><425><43><213><231><445><866><103><111><615><223><268><144><158><487><368><145><277><62><985><91><574><162><680><672><886><136><13><136><13><365><eosp> ", "plain_text": "<sadness> Chapter eleven on the doorstep. EmoSDS: <sadness> I feel you, it’s a tough part to get through.", "residual_length": 122, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Sad/0012_001317.npy", "dialogue_id": "1302_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you manage to finish all the honey yesterday?\nuser: <happiness> Yeah, it was delicious! I can't believe how much I enjoyed it.\nEmoSDS: <surprise> I didn't know you liked honey that much!\n user: <sosp><13><136><757><136><757><136><13><291><13><136><584><871><672><311><43><360><320><260><371><158><958><47><477><628><350><470><454><125><760><43><523><983><790><645><162><489><274><820><640><333><820><47><477><360><545><450><128><328><371><158><159><62><889><958><311><775><958><108><360><583><125><760><470><403><643><136><13><291><13><365><eosp> ", "plain_text": "<sadness> Cos I know I had some honey. EmoSDS: <neutral> Oh, I see. I hope it wasn’t too bitter for you.", "residual_length": 147, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Sad/0015_001177.npy", "dialogue_id": "620_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I saw the cutest octopus at the aquarium yesterday!\nuser: <surprise> Really? Was it doing anything interesting?\nEmoSDS: <happiness> Yes! It was changing colors and playing with the divers!\n user: <sosp><13><83><136><83><381><83><544><136><998><121><487><645><557><128><162><511><958><831><404><178><320><128><162><511><275><425><159><316><450><91><162><511><680><921><790><890><159><472><111><615><371><10><333><876><368><360><320><472><966><260><158><557><162><136><511><105><304><933><128><162><121><354><142><517><792><368><360><1><304><113><450><204><998><584><472><111><615><371><269><371><476><136><13><136><757><136><381><13><136><13><365><eosp> ", "plain_text": "<sadness> The octopus has eight legs. EmoSDS: <neutral> That's true, but I feel kind of bad for them sometimes, they just seem so... alone.", "residual_length": 143, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Sad/0012_001108.npy", "dialogue_id": "282_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I've been thinking about how we can make our project more interesting.\nuser: <happiness> That's a great idea! We can be really creative with it.\nEmoSDS: <surprise> What if we added sound effects to make it even more immersive?\n user: <sosp><79><757><592><136><291><136><171><125><354><142><898><487><368><360><320><545><128><328><371><158><171><125><889><760><432><327><304><232><564><162><584><526><524><571><347><121><425><159><36><583><728><125><760><43><213><751><43><1><120><472><260><158><425><159><180><472><111><615><428><268><171><125><760><432><327><58><232><128><162><136><13><291><13><291><13><136><584><196><524><343><79><136><79><136><79><136><365><eosp> ", "plain_text": "<sadness> Let's make the noise a snake. EmoSDS: <neutral> I guess that could work, but how would we pull it off?", "residual_length": 169, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Sad/0020_001076.npy", "dialogue_id": "122_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I think we need to secure the place before the rain starts.\nuser: <happiness> Yeah, the last storm really caught us off guard!\nEmoSDS: <neutral> Let’s make sure we don’t let that happen again.\n user: <sosp><544><13><136><13><433><136><13><136><837><371><936><917><441><108><432><927><320><583><125><121><159><545><450><204><99><425><43><64><213><655><754><295><848><472><111><615><371><158><464><557><432><36><125><197><20><57><380><368><360><320><493><353><76><70><223><144><347><487><432><36><583><125><701><757><136><13><433><136><13><136><13><365><eosp> ", "plain_text": "<sadness> Slam the doors and wedge them! EmoSDS: <sadness> I wish we didn't have to do this, but it seems necessary.", "residual_length": 139, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Sad/0014_001314.npy", "dialogue_id": "1288_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can’t believe we finally made it to this beautiful spot!\nuser: <neutral> Yeah, it’s a nice place to relax for a bit.\nEmoSDS: <surprise> Look at how clear the water is! I've never seen anything like it!\n user: <sosp><79><235><79><592><235><876><104><109><997><85><486><304><350><304><933><450><204><91><162><499><270><958><368><47><1><360><320><998><121><213><898><120><985><236><338><304><470><454><493><288><162><680><112><231><983><213><402><400><226><524><136><235><136><365><eosp> ", "plain_text": "<sadness> Reed by the living pool! EmoSDS: <sadness> I know, it really evokes a lot of memories, doesn’t it?", "residual_length": 106, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Sad/0018_001195.npy", "dialogue_id": "708_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Have you started reading the new book yet?\nuser: <happiness> Yes! I just finished chapter seventeen, it's so captivating!\nEmoSDS: <surprise> Really? I didn't expect you to get through it that quickly!\n user: <sosp><13><235><13><136><235><136><592><136><288><162><275><682><10><19><775><47><261><62><128><680><899><275><99><425><42><856><382><304><933><564><511><708><10><196><309><403><470><350><470><454><125><701><757><136><757><592><235><962><592><369><742><369><742><369><235><136><347><121><487><43><985><56><997><486><304><933><450><162><275><10><333><311><856><130><125><493><275><682><783><425><43><856><583><125><382><403><643><757><136><114><13><235><13><136><13><136><365><eosp> ", "plain_text": "<sadness> Chapter eighteen, the return journey. EmoSDS: <anger> Ugh, why does it have to be so sad? I can't stand it when it turns gloomy.", "residual_length": 168, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Sad/0018_001334.npy", "dialogue_id": "1386_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I think I might go out with my friends later.\nuser: <neutral> That sounds nice. Where are you planning to go?\nEmoSDS: <happiness> Maybe we’ll just grab some food and hang out.\n user: <sosp><13><235><13><235><13><136><876><958><795><47><1><856><549><930><982><70><737><104><20><231><655><754><486><304><295><879><524><66><104><856><172><432><320><583><125><72><260><899><162><511><584><196><309><130><583><125><197><808><125><944><57><890><382><403><643><564><328><371><10><196><155><757><136><13><235><13><136><365><eosp> ", "plain_text": "<sadness> I'm sure your friends can wait! EmoSDS: <neutral> I hope they understand if I take my time.", "residual_length": 132, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Sad/0017_001351.npy", "dialogue_id": "1467_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I noticed she was quite invested in that project.\nuser: <happiness> Yeah, she loves to challenge herself.\nEmoSDS: <neutral> It’s great to see her so focused.\n user: <sosp><13><592><235><13><136><13><235><592><136><72><837><982><70><737><425><43><213><985><204><338><292><232><949><524><887><988><309><283><304><109><879><104><856><159><930><982><615><223><158><368><47><62><879><524><144><176><737><159><930><111><615><371><158><43><173><523><213><89><889><958><47><545><353><275><615><10><158><144><347><304><470><454><493><91><162><584><98><403><470><454><701><136><757><114><13><742><13><235><13><365><eosp> ", "plain_text": "<sadness> She'll be feverish after so much thinking. EmoSDS: <neutral> I hope she takes a break soon, though.", "residual_length": 149, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Sad/0018_001381.npy", "dialogue_id": "1615_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <surprise> Wow, that's pretty unusual!\nuser: <happiness> I know, right? It's kind of unique!\nEmoSDS: <neutral> Do you think he needs to see a doctor about it?\n user: <sosp><13><592><235><13><136><837><524><637><66><790><831><438><568><62><998><121><43><856><333><918><368><320><111><259><371><183><467><292><300><43><368><47><568><213><53><213><645><557><958><831><47><477><1><304><58><111><371><904><476><158><757><136><13><235><13><235><13><365><eosp> ", "plain_text": "<sadness> Father has yellow eyes. EmoSDS: <sadness> That sounds worrying. Is he okay?", "residual_length": 111, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Sad/0018_001362.npy", "dialogue_id": "1524_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I was thinking about dinner options for tonight.\nuser: <happiness> Oh, that sounds great! Maybe we could order something special.\nEmoSDS: <neutral> I just want something that won't take too long to prepare.\n user: <sosp><13><709><136><83><709><748><709><544><136><274><47><360><918><304><232><450><91><162><574><162><511><601><98><292><300><918><360><653><379><400><371><158><472><236><571><328><571><371><158><425><159><450><353><275><682><70><737><977><790><20><890><304><472><111><615><371><899><949><524><988><338><292><403><292><393><111><371><223><268><144><275><10><155><757><136><13><291><13><136><13><365><eosp> ", "plain_text": "<sadness> I guess it's a choice feast. EmoSDS: <neutral> I know it might not feel exciting, but we can still enjoy the evening together.", "residual_length": 131, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Sad/0015_001156.npy", "dialogue_id": "515_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you see that movie last night?\nuser: <happiness> Yeah, it was so entertaining, I loved every bit of it!\nEmoSDS: <surprise> I know, right? The ending totally caught me off guard!\n user: <sosp><13><381><13><369><13><291><13><136><13><136><889><760><173><958><795><455><108><320><583><72><260><615><268><144><275><158><425><486><295><486><985><889><49><760><432><327><304><933><998><522><425><159><120><450><204><162><511><99><467><292><933><204><91><162><499><270><487><368><47><438><3><78><701><427><136><13><136><13><136><13><365><eosp> ", "plain_text": "<sadness> Monster made a deep bow. EmoSDS: <neutral> That's kind of sad, but I guess it shows respect.", "residual_length": 125, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Sad/0012_001077.npy", "dialogue_id": "127_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I'm not sure what to believe anymore.\nuser: <anger> You should have acted faster!\nEmoSDS: <neutral> I didn't think it would come to this.\n user: <sosp><13><235><13><235><13><742><13><136><742><136><876><487><360><583><125><760><333><47><261><320><111><259><371><183><292><376><111><615><371><495><354><213><944><441><108><432><927><304><320><493><522><333><918><432><836><583><889><125><197><159><701><757><136><13><136><592><13><742><136><235><136><13><365><eosp> ", "plain_text": "<sadness> And has you slain him? EmoSDS: <sadness> No, I couldn't bring myself to do it.", "residual_length": 105, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Sad/0018_001293.npy", "dialogue_id": "1187_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I just love how the sunlight dances through the trees!\nuser: <happiness> Yeah, it makes everything feel so alive and vibrant!\nEmoSDS: <neutral> I wonder what we'll do this weekend.\n user: <sosp><709><544><79><592><136><235><13><136><13><136><511><584><672><917><919><142><898><304><434><295><31><557><958><751><1><120><54><700><304><486><43><856><557><128><489><958><831><743><47><477><1><304><120><472><260><615><371><476><158><425><557><432><36><583><125><493><204><91><511><176><921><104><866><831><47><1><304><232><68><292><304><43><985><204><997><85><104><866><368><47><579><320><111><879><524><136><544><13><136><381><13><365><eosp> ", "plain_text": "<sadness> Clear are your eyes and bright your breath! EmoSDS: <neutral> It's nice you noticed that; I guess we've been through a lot lately.", "residual_length": 162, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Sad/0012_001246.npy", "dialogue_id": "954_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I'm really excited about our archery practice today!\nuser: <neutral> Yeah, I heard we have a new target set up.\nEmoSDS: <anger> But I can't believe Tom thought he could just take charge without asking us!\n user: <sosp><13><592><136><592><13><291><13><837><162><511><708><672><311><296><831><795><523><795><108><89><889><250><889><701><91><13><291><13><136><13><136><79><381><79><592><136><13><381><13><136><125><760><172><47><108><568><213><45><829><142><898><43><792><360><792><557><958><438><856><557><128><511><557><47><831><438><445><655><754><295><445><157><180><111><260><615><899><637><66><790><603><517><438><751><1><382><58><643><724><592><136><592><13><136><13><365><eosp> ", "plain_text": "<sadness> Tom now let our arrows fly! EmoSDS: <neutral> Oh, I guess we're just following along, aren't we?", "residual_length": 169, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Sad/0012_001120.npy", "dialogue_id": "338_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Hey, have you seen the new adventure game that just came out?\nuser: <happiness> Yeah, I heard it’s really good! I can’t wait to play it.\nEmoSDS: <surprise> I didn’t expect you to be interested in that!\n user: <sosp><13><136><13><433><13><136><13><136><680><790><159><103><450><564><162><76><275><196><136><13><136><13><136><680><921><70><737><43><173><213><583><889><760><304><125><760><172><108><213><197><159><304><700><304><376><43><295><644><985><889><760><172><47><277><545><156><128><136><162><511><680><672><757><136><13><742><13><291><13><291><13><365><eosp> ", "plain_text": "<sadness> But show me now your map! EmoSDS: <anger> Why are you always so down? Can't you just enjoy the game and not mope around?", "residual_length": 144, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Sad/0014_001319.npy", "dialogue_id": "1312_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> So, what have you been up to lately?\nuser: <happiness> Just training for the big race next week!\nEmoSDS: <surprise> Wow, I didn't realize you were that serious about it!\n user: <sosp><13><79><235><335><136><592><13><136><13><136><917><171><760><231><173><751><103><583><923><487><432><43><583><889><760><958><795><438><477><1><382><470><643><701><757><876><108><130><583><889><969><760><43><856><56><997><85><104><866><42><382><304><111><615><371><158><425><43><856><295><184><31><701><757><136><13><235><13><136><837><219><615><371><158><790><958><108><583><760><108><43><985><879><20><91><162><584><158><487><43><751><438><751><1><545><998><618><701><757><136><13><235><13><235><13><136><13><365><eosp> ", "plain_text": "<sadness> What am I, I'm a racer, son of god. EmoSDS: <sadness> I understand how much this means to you, but are you okay?", "residual_length": 173, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Sad/0017_001257.npy", "dialogue_id": "1010_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you remember to buy the groceries?\nuser: <happiness> Yeah, I got everything on the list!\nEmoSDS: <neutral> That's great! Did you pick up those eggs I asked for?\n user: <sosp><13><235><13><235><13><235><13><136><347><425><159><877><358><125><760><958><523><795><108><1><927><320><583><125><493><998><347><487><368><557><368><918><368><1><304><206><204><998><162><584><526><904><371><476><457><136><13><136><13><235><489><958><274><47><1><628><304><450><564><98><292><403><933><91><162><680><886><343><757><136><365><eosp> ", "plain_text": "<sadness> The nine the eggs, I keep. EmoSDS: <neutral> Oh, I see... That’s unfortunate. What happened to the others?", "residual_length": 123, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Sad/0017_001051.npy", "dialogue_id": "0_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you ever think we would have this much fun together?\nuser: <happiness> Honestly, I never imagined it would be so great!\nEmoSDS: <neutral> I feel the same way, it's just awesome to see how far we've come.\n user: <sosp><79><592><79><433><592><136><171><20><57><890><304><292><304><454><125><358><125><760><172><47><1><304><933><156><589><354><898><304><700><304><933><450><204><998><686><487><432><927><36><583><72><288><328><371><158><425><43><856><640><333><309><304><933><450><998><522><487><432><304><206><162><584><300><368><958><47><108><1><58><131><111><371><476><757><136><13><433><13><365><eosp> ", "plain_text": "<sadness> We nightly dance our heyday guise. EmoSDS: <neutral> It's just a memory now, isn’t it? I wish we could relive those moments.", "residual_length": 156, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Sad/0014_001161.npy", "dialogue_id": "539_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Do you think they will survive in the wild?\nuser: <happiness> I hope so! They've got a fighting chance out there.\nEmoSDS: <surprise> Wow, I didn’t know eagles were so fierce.\n user: <sosp><13><136><13><291><13><136><489><790><64><213><445><20><879><104><866><159><320><998><347><487><360><918><360><261><583><889><125><72><111><615><269><22><428><899><977><919><376><20><91><680><275><10><144><162><347><467><823><403><292><403><232><206><584><871><790><213><402><260><615><904><371><476><158><757><136><291><13><365><eosp> ", "plain_text": "<sadness> Over them swooped the eagles. EmoSDS: <neutral> That's really sad, but it is part of nature's cycle, isn’t it?", "residual_length": 121, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Sad/0015_001386.npy", "dialogue_id": "1639_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I was thinking about how we've been handling things lately.\nuser: <happiness> Yeah, it's been quite the adventure!\nEmoSDS: <neutral> True, but we need to plan for the challenges ahead.\n user: <sosp><13><136><13><136><381><13><381><13><136><13><162><136><499><270><958><751><477><1><304><159><311><919><213><180><985><91><128><162><511><584><672><79><757><136><13><136><381><136><790><890><445><985><204><998><270><958><47><1><628><304><564><128><574><511><584><921><104><866><213><985><91><162><511><584><672><476><757><136><13><365><eosp> ", "plain_text": "<sadness> By hook or by crook. EmoSDS: <sadness> It sounds like you're feeling pretty overwhelmed by it all.", "residual_length": 111, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Sad/0012_001134.npy", "dialogue_id": "407_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I'm so excited about trying those new dishes we talked about!\nuser: <surprise> Wait, you actually want to eat those? I thought you didn't like them at all.\nEmoSDS: <neutral> Well, I figured it would be fun to try something new, you know?\n user: <sosp><13><381><13><381><13><136><876><274><47><1><304><450><789><949><524><637><524><637><66><790><64><523><831><438><856><104><997><85><866><368><47><261><320><998><121><159><295><113><450><204><162><511><584><890><43><213><445><20><301><57><890><103><287><524><571><158><487><368><47><568><751><261><320><450><91><574><162><511><347><487><368><481><36><889><250><125><701><136><13><235><136><511><347><121><487><43><432><320><125><470><292><403><292><933><204><162><511><347><487><368><481><36><985><125><250><701><114><13><136><13><136><13><365><eosp> ", "plain_text": "<sadness> I'd far rather go without them than eat them! EmoSDS: <neutral> Oh, I understand. Sometimes new things can be overwhelming.", "residual_length": 172, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Sad/0012_001125.npy", "dialogue_id": "365_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> This place actually makes the best cocktails!\nuser: <surprise> No way! I didn't know that!\nEmoSDS: <happiness> Yeah, you have to try their signature drink!\n user: <sosp><13><235><13><291><13><136><616><511><274><47><477><360><320><545><128><162><511><275><10><311><64><231><983><231><213><890><304><933><376><20><57><890><159><287><524><571><347><862><171><889><958><47><1><131><354><959><898><487><159><41><128><511><584><104><295><31><701><136><13><235><13><365><eosp> ", "plain_text": "<sadness> I toy with my liqueur. EmoSDS: <sadness> Is everything okay? You seem a bit down.", "residual_length": 108, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Sad/0019_001217.npy", "dialogue_id": "815_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> So, have you made a decision about the project?\nuser: <sadness> I thought I was clear enough, but it seems like no one's on the same page.\nEmoSDS: <anger> It's frustrating when there are so many unclear signals!\n user: <sosp><13><709><544><13><136><748><13><136><13><136><13><666><489><274><831><743><477><640><111><949><371><158><425><360><918><350><454><125><470><403><304><376><998><159><382><58><292><403><292><300><432><368><918><477><1><327><350><304><933><125><197><20><983><655><856><130><125><358><760><487><432><327><403><643><701><757><114><13><136><13><291><13><136><13><365><eosp> ", "plain_text": "<sadness> I say neither yea nor nay. EmoSDS: <neutral> Well, I guess that means we need to have a deeper conversation about this.", "residual_length": 152, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Sad/0015_001221.npy", "dialogue_id": "1727_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I think it was supposed to be a nice place.\nuser: <sadness> It really looked promising before we came here.\nEmoSDS: <anger> And now it's just a mess! I can't believe they let it get this way.\n user: <sosp><13><136><83><709><291><709><79><136><837><333><652><831><568><213><603><173><380><751><360><1><640><333><309><350><292><232><933><91><162><511><347><425><159><472><111><615><371><899><524><313><487><368><47><743><438><402><91><162><680><133><112><20><983><484><655><213><402><701><757><13><291><13><136><13><365><eosp> ", "plain_text": "<sadness> How I hate this foul pool! EmoSDS: <neutral> Yeah, it’s too bad it turned out like this. What a disappointment.", "residual_length": 130, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Sad/0015_001086.npy", "dialogue_id": "171_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I think we should keep tracking our progress.\nuser: <happiness> You're right; we have made some good strides!\nEmoSDS: <neutral> Let's just focus on the next steps.\n user: <sosp><13><381><13><136><837><524><136><680><790><213><20><861><301><57><890><292><304><300><43><856><103><125><760><958><831><47><438><743><311><296><831><47><477><1><350><304><403><292><232><292><300><432><368><432><60><131><701><288><13><162><511><275><618><476><136><13><136><13><136><13><365><eosp> ", "plain_text": "<sadness> But we are not high yet. EmoSDS: <happiness> I see what you mean, but there's still time to get there.", "residual_length": 112, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Sad/0019_001203.npy", "dialogue_id": "747_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you hear about the little league's final game last week?\nuser: <happiness> Yeah, I heard they won! That’s awesome!\nEmoSDS: <sadness> But I heard one of the players got injured during the match.\n user: <sosp><13><709><544><13><136><291><13><136><13><136><998><121><159><316><879><949><524><212><66><919><518><103><450><128><162><680><790><213><110><213><45><91><162><511><708><10><309><292><350><470><454><125><599><472><260><615><371><223><899><144><162><511><98><300><304><985><879><159><103><320><91><162><574><162><511><708><10><309><292><453><933><91><162><511><680><311><790><64><438><856><295><587><522><58><403><643><136><13><381><13><365><eosp> ", "plain_text": "<sadness> The football teams give a tea party. EmoSDS: <neutral> That's a bit odd. I wonder why they decided to do that.", "residual_length": 138, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Sad/0012_001074.npy", "dialogue_id": "112_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I’ve always found blue eyes to be quite striking.\nuser: <sadness> Sometimes they can also look really sad, don’t you think?\nEmoSDS: <happiness> Yeah, I guess it depends on the expression, but there's beauty in sadness too.\n user: <sosp><13><79><235><79><592><13><136><235><136><489><958><751><360><320><450><511><99><425><159><985><879><66><173><831><795><108><1><927><304><130><125><630><109><997><85><866><831><47><820><579><400><524><904><476><158><757><235><136><757><136><171><889><760><309><304><350><304><522><284><333><856><295><985><204><91><162><680><20><45><898><376><20><645><616><489><958><831><743><477><1><327><403><131><111><371><158><218><958><399><438><88><879><524><637><66><790><509><3><78><402><311><757><136><13><742><13><235><13><742><13><365><eosp> ", "plain_text": "<sadness> A divine wrath made her blue eyes awful. EmoSDS: <anger> Awful? That's harsh; it sounds like there’s a story behind those eyes.", "residual_length": 186, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Sad/0018_001084.npy", "dialogue_id": "163_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I'm not sure what to believe anymore.\nuser: <anger> You should have acted faster!\nEmoSDS: <neutral> I didn't think it would come to this.\n user: <sosp><13><291><13><136><13><291><136><876><557><432><130><583><125><288><522><487><333><47><261><320><472><260><467><292><376><472><111><615><428><223><268><144><354><944><898><432><927><470><454><125><522><333><432><985><889><125><889><701><757><13><291><13><136><13><365><eosp> ", "plain_text": "<sadness> And has you slain him? EmoSDS: <sadness> No, I couldn't bring myself to do it.", "residual_length": 122, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Sad/0020_001293.npy", "dialogue_id": "1187_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I’ve always found blue eyes to be quite striking.\nuser: <sadness> Sometimes they can also look really sad, don’t you think?\nEmoSDS: <happiness> Yeah, I guess it depends on the expression, but there's beauty in sadness too.\n user: <sosp><709><544><13><136><13><291><13><136><489><360><320><450><128><511><99><158><425><159><985><879><524><637><66><958><831><743><47><477><1><350><304><583><125><770><519><997><85><866><831><47><820><579><41><524><571><917><425><557><136><171><889><760><304><545><930><921><856><104><985><204><91><511><680><20><829><142><898><376><20><57><173><958><831><743><47><477><1><472><260><259><371><158><616><13><136><13><136><240><399><523><438><178><400><949><524><637><790><509><655><213><402><701><757><701><136><13><136><13><291><13><365><eosp> ", "plain_text": "<sadness> A divine wrath made her blue eyes awful. EmoSDS: <anger> Awful? That's harsh; it sounds like there’s a story behind those eyes.", "residual_length": 197, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Sad/0015_001084.npy", "dialogue_id": "163_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Hey, how was your day today?\nuser: <happiness> It was great! I finally finished that project!\nEmoSDS: <surprise> Really? That's awesome! I didn't expect you to finish it so soon.\n user: <sosp><79><291><592><136><13><136><13><235><13><136><347><487><130><583><125><358><125><760><172><795><108><172><927><470><454><125><493><522><467><304><292><304><432><1><382><113><450><91><162><584><526><371><904><371><904><371><476><158><155><757><136><114><13><291><13><136><616><489><274><47><477><1><304><232><98><661><98><292><403><933><91><162><511><680><886><757><13><235><13><381><13><136><13><365><eosp> ", "plain_text": "<sadness> The nine the eggs, I keep. EmoSDS: <anger> Why are you so upset about that? It’s just nine eggs!", "residual_length": 159, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0016/Sad/0016_001051.npy", "dialogue_id": "1_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I'm not sure what to believe anymore.\nuser: <anger> You should have acted faster!\nEmoSDS: <neutral> I didn't think it would come to this.\n user: <sosp><13><709><136><83><709><291><709><83><709><544><876><360><320><493><618><333><918><47><579><320><111><328><183><196><292><933><949><615><371><354><517><43><432><327><470><454><493><522><333><918><360><370><583><701><757><136><13><291><13><136><365><eosp> ", "plain_text": "<happiness> And has you slain him? EmoSDS: <happiness> Yes! It feels like a weight has been lifted off my shoulders.", "residual_length": 83, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Happy/0015_000943.npy", "dialogue_id": "1187_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I just found an amazing old coin at the antique shop!\nuser: <neutral> That's interesting, what year is it from?\nEmoSDS: <surprise> It's from the 18th century! Can you believe it?\n user: <sosp><79><235><79><422><592><72><747><571><371><183><309><283><304><42><104><856><43><751><213><985><879><524><637><66><790><231><655><754><856><103><287><111><524><904><524><347><121><104><109><486><304><292><403><643><333><585><616><136><876><368><579><320><111><949><615><371><269><371><158><425><43><173><213><62><879><790><104><856><103><930><982><70><737><425><43><213><898><120><304><383><454><125><557><432><120><472><260><615><223><268><144><275><682><737><856><130><125><760><470><403><643><136><13><235><13><365><eosp> ", "plain_text": "<happiness> Zero four three a silver shilling is journey. EmoSDS: <happiness> Wow, that's so cool! It must have an interesting story behind it!", "residual_length": 189, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Happy/0018_000759.npy", "dialogue_id": "285_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Hey, do you remember that time we got lost in the city?\nuser: <happiness> Yeah! We had so much fun trying to find our way back!\nEmoSDS: <neutral> I still laugh thinking about how we stumbled into that little café.\n user: <sosp><79><291><79><592><422><592><136><511><876><368><47><568><213><518><159><320><111><615><371><158><425><368><751><62><861><301><57><231><173><213><583><493><995><680><338><113><450><204><998><467><300><304><432><360><545><36><159><125><180><159><113><206><98><300><43><432><927><470><643><701><13><291><13><136><365><eosp> ", "plain_text": "<happiness> Alice I won't forget it again. EmoSDS: <happiness> That's great to hear! It sounds like a special moment for you.", "residual_length": 113, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Happy/0011_000982.npy", "dialogue_id": "1376_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Hey, do you remember that time we got lost in the city?\nuser: <happiness> Yeah! We had so much fun trying to find our way back!\nEmoSDS: <neutral> I still laugh thinking about how we stumbled into that little café.\n user: <sosp><13><79><291><79><136><592><136><592><13><136><13><291><136><876><274><47><261><568><213><822><898><120><472><111><615><371><158><557><958><831><47><360><1><304><376><20><213><808><45><493><879><524><637><66><104><295><103><933><450><204><998><98><300><368><432><545><522><120><933><998><522><304><933><204><998><98><300><432><918><432><36><125><278><384><125><701><544><13><136><13><365><eosp> ", "plain_text": "<happiness> Alice I won't forget it again. EmoSDS: <happiness> That's great to hear! It sounds like a special moment for you.", "residual_length": 126, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Happy/0012_000982.npy", "dialogue_id": "1376_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I was just heading to the store.\nuser: <happiness> That's great! Did you get anything good?\nEmoSDS: <anger> It was so crowded, I could barely move.\n user: <sosp><13><79><235><79><592><235><162><511><270><173><360><545><923><487><368><1><320><111><615><371><158><425><958><831><438><477><1><628><304><376><20><861><57><173><831><652><370><178><41><128><162><584><98><300><304><350><470><36><125><384><701><114><13><136><13><235><13><365><eosp> ", "plain_text": "<happiness> But I saw you walking. EmoSDS: <happiness> Yeah, I was enjoying the fresh air!", "residual_length": 95, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Happy/0018_000777.npy", "dialogue_id": "374_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I saw you wore that shawl the other day.\nuser: <happiness> Yeah, I just love how it feels on me.\nEmoSDS: <neutral> It really does suit you well.\n user: <sosp><13><136><79><196><79><592><235><136><837><136><998><487><432><42><856><295><113><450><998><584><43><64><213><445><213><180><111><328><162><347><121><425><159><103><930><982><70><737><425><831><110><568><370><603><991><441><360><304><933><450><162><98><300><432><36><583><125><701><136><162><13><136><13><235><13><381><13><365><eosp> ", "plain_text": "<happiness> There goes the shawl again! EmoSDS: <happiness> It's nice to see you enjoying it so much!", "residual_length": 116, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Happy/0019_000990.npy", "dialogue_id": "1416_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe we finally made it to the championship game!\nuser: <neutral> Yeah, it's been a long journey to get here.\nEmoSDS: <anger> But why do they keep changing the rules? It's so frustrating!\n user: <sosp><13><235><13><235><13><369><235><13><162><511><347><121><159><472><260><998><121><385><20><861><301><173><523><958><108><360><583><125><493><557><360><368><62><156><861><301><57><890><304><350><360><583><125><557><128><328><904><371><899><144><511><300><368><320><450><128><574><511><347><113><91><511><584><494><921><311><856><47><172><108><523><370><757><128><511><275><10><196><155><136><13><235><13><365><eosp> ", "plain_text": "<happiness> Does the one that wins get the crowned? EmoSDS: <surprise> Wow, I didn't expect you to ask that! Yes, they do!", "residual_length": 134, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Happy/0017_000792.npy", "dialogue_id": "449_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Have you thought about how that will affect your budget?\nuser: <happiness> Yeah, but it feels worth it for the extra benefits.\nEmoSDS: <sadness> I just hope it doesn’t lead to any financial strain.\n user: <sosp><13><136><79><235><79><136><489><274><743><47><477><360><41><128><162><680><347><487><432><304><918><640><333><820><918><47><579><62><524><66><943><159><985><91><162><779><871><921><895><104><866><172><108><438><108><197><583><125><557><162><489><790><64><213><983><861><20><301><919><486><292><283><232><162><98><467><557><136><162><511><876><368><47><41><128><511><275><70><982><223><268><76><176><892><104><866><751><88><701><136><13><291><13><863><13><235><13><136><13><365><eosp> ", "plain_text": "<happiness> I pay half a crown a week extra. EmoSDS: <happiness> That’s great! It sounds like a good deal for you!", "residual_length": 170, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Happy/0019_000874.npy", "dialogue_id": "846_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> It's been a long hike, hasn't it?\nuser: <sadness> Yeah, I didn't expect it to feel this draining.\nEmoSDS: <anger> Why didn't we bring enough water with us?\n user: <sosp><79><291><79><291><79><422><136><876><432><130><583><493><99><159><977><20><861><301><486><292><283><232><292><300><43><368><47><438><856><295><131><111><615><769><428><158><425><43><751><484><213><445><518><180><111><949><524><347><425><43><295><848><472><111><615><371><223><268><144><511><275><467><700><403><643><196><757><592><291><136><13><136><13><365><eosp> ", "plain_text": "<happiness> And we are so thirsty! EmoSDS: <happiness> But think about how refreshing that water will taste once we find it!", "residual_length": 157, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Happy/0020_000764.npy", "dialogue_id": "310_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <sadness> I really feel like you're not here with me anymore.\nuser: <neutral> I don't know what to say to that.\nEmoSDS: <happiness> It's just so nice to remember the fun times we had!\n user: <sosp><13><291><13><136><79><291><79><422><136><876><274><47><360><545><450><204><162><680><919><213><603><45><142><898><442><283><232><454><493><128><162><275><10><159><171><889><958><47><277><557><128><574><162><616><489><831><28><47><360><918><640><41><400><371><899><311><296><523><438><856><295><848><450><522><196><136><13><136><13><291><136><365><eosp> ", "plain_text": "<happiness> I blinked my eyes hard. EmoSDS: <happiness> Did you just see something amazing?", "residual_length": 144, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Happy/0019_000835.npy", "dialogue_id": "659_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> So, did you end up getting that loan you were talking about?\nuser: <happiness> Yeah, I finally did! It's such a relief!\nEmoSDS: <happiness> That's awesome! I'm really happy for you!\n user: <sosp><13><235><13><235><13><136><837><524><637><66><958><831><47><477><1><320><62><311><775><296><47><108><360><583><493><632><682><783><486><103><587><522><43><432><583><125><889><20><173><108><583><125><889><338><304><918><360><370><360><283><292><304><432><130><583><125><770><519><997><866><831><47><1><382><403><232><283><643><196><136><666><13><136><13><235><13><365><eosp> ", "plain_text": "<happiness> Five hundred and one million right? EmoSDS: <happiness> Exactly! You did it, and I couldn’t be prouder!", "residual_length": 116, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Happy/0017_001002.npy", "dialogue_id": "1474_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> That's interesting, but what does it mean exactly?\nuser: <happiness> It means he was so confident that he felt he could handle anything, even at night!\nEmoSDS: <surprise> Wow, I didn’t know he had that kind of courage!\n user: <sosp><13><136><592><136><79><291><79><592><136><837><615><428><158><425><43><445><103><180><450><162><275><708><672><296><831><404><108><583><320><260><615><428><158><425><43><64><213><73><108><36><583><125><728><125><760><172><47><477><1><545><557><274><368><360><320><472><260><158><425><159><953><20><301><57><890><985><204><768><680><85><480><866><231><438><261><103><545><450><91><162><511><686><487><432><304><43><213><441><751><47><145><1><277><557><128><13><291><13><365><eosp> ", "plain_text": "<happiness> So Tom saw night as it were broad daylight. EmoSDS: <happiness> That's so inspiring! I wish I could be that brave.", "residual_length": 159, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Happy/0011_001040.npy", "dialogue_id": "1747_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Hey, I heard you're looking for a job.\nuser: <sadness> Yeah, but it feels hopeless right now.\nEmoSDS: <happiness> Don't worry! I’m sure something good will come along soon.\n user: <sosp><13><544><13><136><13><136><13><291><13><136><886><936><790><898><304><283><393><472><260><371><10><333><311><775><296><831><47><477><1><42><856><295><985><125><889><338><292><304><300><557><616><162><557><47><28><62><879><524><899><144><275><737><783><486><292><304><227><159><376><808><388><701><757><136><757><136><13><136><291><13><136><365><eosp> ", "plain_text": "<happiness> Please hire me after you. EmoSDS: <happiness> Of course! I'll definitely help you out; we can both succeed together!", "residual_length": 116, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Happy/0012_000893.npy", "dialogue_id": "942_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> So, what happened after they found the ladybug?\nuser: <happiness> They all cheered and gathered around to listen more!\nEmoSDS: <sadness> But then, they noticed the garden was looking a bit dull.\n user: <sosp><511><79><235><79><592><13><136><162><511><121><487><213><441><898><360><304><320><522><283><933><450><162><680><487><368><261><159><450><128><162><511><10><672><296><64><213><45><62><91><511><347><487><159><889><830><493><511><680><921><311><856><831><438><568><62><450><128><162><511><347><898><58><403><643><196><724><136><13><235><13><136><13><365><eosp> ", "plain_text": "<happiness> The ladybug told them proudly. EmoSDS: <neutral> Really? I didn't expect the ladybug to talk, that’s quite interesting.", "residual_length": 104, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0016/Happy/0016_000951.npy", "dialogue_id": "1224_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I just don't see why it's such a big deal.\nuser: <anger> It's a big deal because it affects everyone involved!\nEmoSDS: <sadness> I guess I just thought it wouldn’t matter in the long run.\n user: <sosp><13><291><13><235><13><136><98><292><304><43><213><45><128><162><511><371><183><467><292><403><283><643><136><162><136><79><291><79><136><524><66><104><173><231><213><231><20><861><301><231><173><28><41><128><511><275><10><467><304><292><232><292><376><20><997><85><486><561><370><213><231><213><3><78><701><136><13><235><13><291><13><365><eosp> ", "plain_text": "<happiness> Guilty for what do you rule? EmoSDS: <happiness> I rule for fun, but I never meant to hurt anyone!", "residual_length": 158, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Happy/0019_000852.npy", "dialogue_id": "742_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Have you heard from Sarah recently?\nuser: <sadness> No, not in a while. I really hope she’s okay.\nEmoSDS: <happiness> You always got along so well.\n user: <sosp><13><291><13><291><13><666><511><467><292><304><918><320><111><615><371><476><862><171><136><13><291><13><136><489><274><47><583><889><760><432><227><472><111><615><40><158><425><295><31><128><136><13><592><136><79><592><962><291><136><365><eosp> ", "plain_text": "<happiness> Yes, I miss her. EmoSDS: <happiness> It's great that you have such fond memories of her!", "residual_length": 111, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Happy/0011_000894.npy", "dialogue_id": "945_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Hey, did you see that book about Lewis Carroll's poems?\nuser: <happiness> Yeah, I loved the illustrations! They’re so whimsical.\nEmoSDS: <surprise> I didn’t expect you to like poetry that much!\n user: <sosp><79><291><79><422><136><557><105><309><918><350><304><493><522><467><292><546><20><861><91><301><231><173><360><41><400><328><371><904><571><347><121><159><113><450><91><162><584><871><43><958><831><47><477><1><856><557><128><557><432><130><125><493><288><162><275><10><906><376><450><91><162><511><98><300><304><432><644><889><493><998><790><64><213><173><213><370><701><136><757><136><13><291><13><365><eosp> ", "plain_text": "<happiness> Andy what's the gyre and to gimble. EmoSDS: <happiness> It's all about the playful language! Isn't it fascinating?", "residual_length": 132, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Happy/0019_000706.npy", "dialogue_id": "27_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> So, what's the plan for today?\nuser: <anger> I can't believe we're even thinking about this!\nEmoSDS: <sadness> It just feels like we're stuck in this situation.\n user: <sosp><79><291><962><757><136><13><136><666><489><958><441><831><795><404><568><62><879><524><66><790><509><110><213><751><180><121><316><450><91><680><921><104><486><43><120><472><260><158><467><125><632><288><982><70><737><196><304><227><43><159><316><985><128><574><13><291><13><136><365><eosp> ", "plain_text": "<happiness> Off for the prison ship. EmoSDS: <happiness> That's the spirit! Let's make the most of it!", "residual_length": 97, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Happy/0011_000944.npy", "dialogue_id": "1193_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Hey, I just saw him acting really strange today.\nuser: <surprise> Really? What do you mean by strange?\nEmoSDS: <sadness> He was just sitting by himself, looking lost.\n user: <sosp><511><79><291><79><422><592><136><622><292><232><963><511><584><672><919><103><601><998><760><958><831><47><19><47><568><62><91><128><116><99><686><376><890><103><470><454><493><526><615><371><158><425><368><751><438><88><402><701><136><114><13><235><13><365><eosp> ", "plain_text": "<happiness> He could not help doing so. EmoSDS: <happiness> That's great! It shows he’s really committed to his choices.", "residual_length": 84, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0016/Happy/0016_000981.npy", "dialogue_id": "1374_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Have you thought about what you'll do next?\nuser: <sadness> Yeah, but it feels overwhelming sometimes.\nEmoSDS: <happiness> I understand, but remember that you're not alone in this.\n user: <sosp><13><592><136><291><592><13><136><235><13><136><13><136><958><831><47><477><360><320><450><128><162><347><121><203><213><354><142><898><304><292><933><995><338><292><376><167><213><173><438><831><856><754><20><301><517><173><108><583><923><159><106><879><159><998><347><487><368><481><36><583><250><701><13><291><13><136><13><365><eosp> ", "plain_text": "<happiness> I believe you are one of them! EmoSDS: <happiness> That means a lot to me; I really appreciate your faith in me!", "residual_length": 107, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Happy/0012_000962.npy", "dialogue_id": "1278_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> So, how did that happen?\nuser: <sadness> I thought I was doing it right, but clearly, I wasn't.\nEmoSDS: <surprise> Wow, that sounds frustrating!\n user: <sosp><13><136><79><235><79><422><136><876><274><831><743><47><477><360><320><524><196><283><196><309><304><320><450><128><574><162><511><347><121><43><890><20><997><85><866><831><523><108><583><125><855><125><454><493><125><760><43><751><484><445><376><472><111><260><371><904><371><476><781><359><909><79><136><13><235><13><136><79><235><79><136><592><365><eosp> ", "plain_text": "<happiness> I've hit the wrong nose. EmoSDS: <happiness> Well, at least it makes for a funny story!", "residual_length": 149, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Happy/0019_000799.npy", "dialogue_id": "482_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you hear what happened at the farm yesterday?\nuser: <happiness> Yeah! I can't believe the piglets are finally going outside!\nEmoSDS: <surprise> I know, right? It was so exciting!\n user: <sosp><79><291><79><592><136><13><291><136><125><760><43><172><795><568><484><213><445><376><103><111><260><615><269><428><40><158><425><487><368><1><545><450><128><574><162><680><10><196><304><933><450><162><98><292><403><933><564><162><584><98><196><333><918><152><918><42><856><159><180><959><898><159><227><111><615><371><899><354><898><304><58><403><470><701><13><136><13><291><13><365><eosp> ", "plain_text": "<happiness> No, said piggy carelessly. EmoSDS: <neutral> Oh, I see. He just doesn't care, huh?", "residual_length": 157, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Happy/0020_000989.npy", "dialogue_id": "1410_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Have you heard about Paul’s dental issues?\nuser: <sadness> Yeah, it seems like he’s been struggling a lot lately.\nEmoSDS: <neutral> I hope he sees a dentist soon.\n user: <sosp><13><136><13><748><235><369><13><162><680><133><311><775><831><523><370><62><524><904><144><275><10><309><292><933><304><557><616><162><105><918><283><350><283><403><283><933><128><511><584><196><144><275><371><10><196><136><13><369><136><680><292><232><162><584><672><775><47><368><320><260><259><121><159><20><879><997><354><517><173><652><47><108><370><760><360><432><350><432><130><125><130><701><757><136><114><13><748><13><235><13><365><eosp> ", "plain_text": "<happiness> Paul's teeth ached because of lemon. EmoSDS: <happiness> Only Paul would turn something so sour into a funny story!", "residual_length": 147, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Happy/0017_001038.npy", "dialogue_id": "1746_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you see that rat by the garden yesterday?\nuser: <happiness> Yeah, I thought it was cute to see it munching on the plants.\nEmoSDS: <surprise> I didn't expect it to be so bold!\n user: <sosp><79><291><79><592><136><291><13><171><997><85><866><368><47><277><545><618><524><128><162><511><98><333><309><432><350><927><583><889><760><432><583><770><85><104><866><751><985><91><162><680><936><375><354><517><958><831><404><795><831><47><477><1><304><933><450><522><487><218><958><795><108><583><125><429><493><998><121><43><213><180><603><45><998><467><292><403><58><376><985><995><524><343><476><904><476><428><476><365><eosp> ", "plain_text": "<happiness> Rat came and replied on the leaves. EmoSDS: <happiness> That's adorable! It's great that nature is active around here.", "residual_length": 174, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Happy/0020_000729.npy", "dialogue_id": "138_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I don't know, they seemed to be fine before.\nuser: <happiness> It was such a beautiful egg, I thought it would crack today!\nEmoSDS: <surprise> Really? I thought you wanted it to last longer.\n user: <sosp><13><291><13><592><13><136><592><136><13><291><13><301><57><517><173><831><47><640><333><918><320><260><615><371><158><472><260><371><158><425><487><368><432><113><450><171><151><760><172><47><831><62><91><128><511><680><104><866><43><173><213><20><91><584><300><227><36><125><728><701><114><13><291><13><136><13><136><365><eosp> ", "plain_text": "<happiness> Why has this egg not broken? EmoSDS: <surprise> That's a good question! It's like it's going to last forever now.", "residual_length": 106, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Happy/0011_000717.npy", "dialogue_id": "79_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I finally got tickets to the concert this weekend!\nuser: <neutral> Oh, that's cool. Which band is playing?\nEmoSDS: <surprise> It's that new pop band everyone's been talking about!\n user: <sosp><13><291><13><136><13><666><13><136><998><347><487><304><292><232><557><128><162><666><162><511><105><918><360><283><933><91><574><162><511><680><338><292><933><879><949><524><158><557><136><489><274><47><360><320><450><128><574><511><347><121><159><985><204><91><162><680><173><103><320><128><353><76><682><70><737><304><486><930><70><982><70><737><783><487><43><368><47><743><438><3><62><91><136><13><291><13><136><13><365><eosp> ", "plain_text": "<happiness> They ate beef at the butcher shop. EmoSDS: <happiness> That's awesome! Did they have any special cuts or something?", "residual_length": 135, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Happy/0012_000866.npy", "dialogue_id": "808_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I think he has a lot of ideas these days.\nuser: <happiness> That's true! He’s been really creative lately.\nEmoSDS: <sadness> It's a shame he feels overwhelmed about sharing them.\n user: <sosp><13><83><291><83><709><83><709><136><544><136><837><345><98><661><98><292><283><933><454><889><173><47><360><283><933><128><162><584><672><871><311><296><64><438><568><213><898><120><933><450><879><524><637><66><790><231><655><754><866><486><113><933><450><526><260><966><158><487><368><47><261><62><995><162><680><790><509><3><402><701><136><13><544><291><13><136><13><365><eosp> ", "plain_text": "<happiness> He might call it, for example. EmoSDS: <happiness> That would be awesome! I can't wait to hear what he comes up with.", "residual_length": 113, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Happy/0012_000815.npy", "dialogue_id": "561_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Hey, have you heard that new album that just came out?\nuser: <happiness> Yeah, I loved it! The lyrics really spoke to me.\nEmoSDS: <surprise> Wait, which song did you like the most?\n user: <sosp><13><136><79><291><79><592><136><162><347><121><159><111><615><371><158><425><958><831><523><370><125><304><360><320><472><260><615><899><144><511><584><672><871><64><110><3><213><45><91><618><899><136><235><861><301><231><173><380><918><42><350><283><393><966><158><425><120><933><125><493><789><933><493><889><49><338><304><292><403><470><454><125><493><72><328><371><476><32><136><13><381><13><381><13><365><eosp> ", "plain_text": "<happiness> The song is called Ways and Means. EmoSDS: <surprise> Really? That's awesome! I can't wait to listen to it!", "residual_length": 163, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Happy/0019_000959.npy", "dialogue_id": "1263_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you see how they reacted to the news?\nuser: <happiness> Yeah, it was kind of amusing!\nEmoSDS: <anger> But seriously, who do they think they are?\n user: <sosp><79><291><79><592><757><592><13><136><13><291><136><489><274><743><47><477><1><304><376><20><890><159><472><450><328><615><269><428><269><428><899><584><162><584><672><43><518><445><213><879><524><347><487><368><47><277><320><545><128><162><511><347><467><292><393><472><111><615><899><212><524><66><790><958><795><438><751><568><213><603><45><121><159><213><20><85><295><157><180><131><472><260><615><476><136><13><291><13><365><eosp> ", "plain_text": "<happiness> I would scoff at these followers. EmoSDS: <happiness> Right? They take themselves way too seriously!", "residual_length": 162, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Happy/0020_000957.npy", "dialogue_id": "1254_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I heard about those creatures, they're quite strange.\nuser: <happiness> Oh, they sound cute! Have you seen one before?\nEmoSDS: <neutral> I've only seen pictures, but they look interesting.\n user: <sosp><13><709><544><83><709><291><709><83><709><544><136><162><136><162><511><99><467><292><546><376><650><949><524><571><347><309><432><350><454><288><512><584><309><442><320><450><328><371><158><425><43><751><385><20><861><301><57><20><890><472><260><259><158><425><173><110><523><370><402><757><136><757><136><13><291><13><365><eosp> ", "plain_text": "<happiness> Do you think it's a woozle? EmoSDS: <surprise> Wow, really? I never expected you to think that!", "residual_length": 97, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Happy/0015_000945.npy", "dialogue_id": "1732_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I think it's just the refrigerator humming.\nuser: <happiness> Oh, that makes sense! I thought it was something more serious.\nEmoSDS: <surprise> Really? You were worried about that?\n user: <sosp><13><136><79><235><79><422><136><876><918><304><376><20><861><301><919><173><831><856><754><997><866><486><304><454><798><286><125><798><125><760><43><173><523><173><360><304><111><371><899><20><301><57><890><159><180><111><615><371><158><333><311><775><856><295><848><450><522><196><701><136><13><235><13><235><13><365><eosp> ", "plain_text": "<happiness> A whirring noise was heard. EmoSDS: <happiness> That's funny! It's probably just something trivial that we don't need to stress over.", "residual_length": 135, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Happy/0019_001045.npy", "dialogue_id": "1680_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I heard about the accident earlier today.\nuser: <sadness> Yeah, it was really unexpected and shocking.\nEmoSDS: <surprise> I can’t believe something like that could happen to him.\n user: <sosp><13><863><291><13><136><13><291><13><837><524><637><66><104><866><856><41><930><982><70><899><128><162><680><956><597><333><309><327><350><470><454><493><72><285><371><269><371><269><904><371><183><283><232><393><472><260><998><162><524><899><524><162><511><66><790><64><110><213><45><260><862><91><204><91><162><511><680><790><64><831><404><831><404><831><438><28><62><923><120><304><58><700><68><403><643><136><13><291><136><365><eosp> ", "plain_text": "<happiness> Fresh pain seized Paul's body. EmoSDS: <neutral> Hopefully, he'll recover soon and get back to his old self.", "residual_length": 170, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Happy/0013_000883.npy", "dialogue_id": "893_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> So, what have you been up to lately?\nuser: <happiness> Just training for the big race next week!\nEmoSDS: <surprise> Wow, I didn't realize you were that serious about it!\n user: <sosp><709><544><79><291><592><13><291><136><301><231><173><103><923><43><159><889><958><795><47><1><382><58><643><757><136><13><136><291><136><489><274><958><28><47><108><370><889><104><480><699><997><699><997><85><866><42><304><283><232><393><472><111><615><371><158><425><295><827><930><219><615><371><269><371><158><425><751><923><197><159><985><879><91><162><584><300><368><958><795><743><404><795><47><277><545><450><998><618><757><136><365><eosp> ", "plain_text": "<happiness> What am I, I'm a racer, son of god. EmoSDS: <happiness> That’s incredible! I can’t wait to see you in action!", "residual_length": 180, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Happy/0013_000907.npy", "dialogue_id": "1010_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I guess I have a round face, don't I?\nuser: <happiness> Yeah, but it suits you really well!\nEmoSDS: <neutral> Thanks, I never thought about it that way.\n user: <sosp><79><291><79><962><757><136><876><274><47><1><15><304><933><111><615><269><371><158><425><918><360><304><933><450><933><204><232><292><376><998><715><998><354><142><898><43><103><450><128><511><98><936><171><354><517><958><47><1><15><450><128><511><98><309><304><583><125><760><557><918><1><304><206><204><584><196><227><557><131><111><615><428><40><158><425><159><295><31><701><136><757><136><13><291><13><291><13><365><eosp> ", "plain_text": "<happiness> I said you looked like an egg, sir. EmoSDS: <happiness> Well, that's a compliment then! Eggs are great!", "residual_length": 173, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Happy/0020_000868.npy", "dialogue_id": "819_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I heard Tom was really sick lately.\nuser: <sadness> Yeah, it was really hard watching him suffer.\nEmoSDS: <surprise> I didn't realize it had gotten that bad.\n user: <sosp><13><592><79><235><79><592><13><235><511><680><133><375><112><231><237><856><758><103><587><128><162><511><10><19><311><775><652><831><523><62><583><125><358><125><760><487><172><47><568><213><890><120><472><111><904><371><268><144><162><99><686><487><368><47><360><277><545><450><99><618><196><757><136><757><592><13><136><365><eosp> ", "plain_text": "<happiness> Poor Tom now is dead! EmoSDS: <sadness> I can't believe he's really gone; he was such a great guy.", "residual_length": 100, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Happy/0018_000715.npy", "dialogue_id": "72_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I just don't understand why you enjoy those things so much.\nuser: <sadness> They remind me of better times, you know?\nEmoSDS: <happiness> I suppose that's true, but they're still pretty quirky!\n user: <sosp><79><592><136><512><584><672><311><296><108><213><583><889><760><173><795><108><261><62><889><958><795><47><1><58><933><450><564><162><275><682><783><300><368><47><41><128><162><98><196><304><159><125><889><125><121><159><985><91><162><680><790><958><795><438><47><41><128><526><371><158><425><227><376><180><472><260><904><476><428><371><476><757><136><757><13><291><136><13><291><13><365><eosp> ", "plain_text": "<happiness> Come on my jack in the boxes! EmoSDS: <happiness> Alright! I can join in on the fun if you want!", "residual_length": 161, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Happy/0020_000774.npy", "dialogue_id": "361_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I really loved the beginning of the story, it was so captivating!\nuser: <neutral> Yeah, it had some interesting characters.\nEmoSDS: <surprise> But I didn't expect the plot twist at the end!\n user: <sosp><13><291><592><79><291><79><592><136><13><136><998><338><292><300><918><360><583><493><91><680><133><64><831><438><856><261><1><545><522><557><304><120><472><260><615><862><899><524><313><338><425><304><120><930><982><682><862><171><889><760><432><47><438><579><88><400><524><476><136><13><291><136><13><365><eosp> ", "plain_text": "<happiness> The end part is fish mouth. EmoSDS: <surprise> Really? That’s such a quirky ending, I love it!", "residual_length": 110, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Happy/0011_000977.npy", "dialogue_id": "1352_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you see the kitten at the park today?\nuser: <happiness> Yes! It was so playful and cute!\nEmoSDS: <surprise> I can’t believe it! I thought they were all gone.\n user: <sosp><13><136><79><291><79><159><958><136><235><136><489><958><751><213><603><20><829><354><517><441><360><918><350><283><522><304><700><292><700><304><159><472><260><966><425><43><213><173><103><822><557><616><162><136><616><235><162><511><876><820><28><62><128><213><898><159><320><524><571><425><180><472><260><371><158><354><20><983><603><354><517><441><360><47><28><820><28><47><820><47><277><62><450><128><574><511><680><886><79><136><13><136><13><365><eosp> ", "plain_text": "<happiness> A lady, is on Alice's lap! EmoSDS: <happiness> That's wonderful! I bet Alice is having a great time!", "residual_length": 143, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Happy/0019_000901.npy", "dialogue_id": "979_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Hey, did you hear the news about Tom's family?\nuser: <happiness> Yeah, I heard they had a baby boy!\nEmoSDS: <sadness> It's bittersweet; I wish I could have been there.\n user: <sosp><79><291><79><422><136><291><13><136><622><292><376><961><103><728><125><760><43><751><445><213><645><557><616><162><557><918><47><360><320><583><493><128><328><371><10><158><425><159><472><260><615><268><144><162><275><10><425><159><985><998><121><159><877><125><760><432><350><583><889><760><173><213><985><879><524><128><511><275><672><333><311><296><795><108><62><889><159><111><260><615><769><428><371><269><428><158><425><958><831><795><108><36><583><384><701><757><701><757><291><13><291><13><365><eosp> ", "plain_text": "<happiness> You know, answers to the name of Tom's son. EmoSDS: <happiness> Oh, that's such a lovely name! I'm so happy for them!", "residual_length": 195, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Happy/0020_000824.npy", "dialogue_id": "605_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you see how the dog was playing with the cat earlier?\nuser: <happiness> Yeah, it was so cute! They were really getting along!\nEmoSDS: <surprise> I couldn't believe how they were chasing each other around!\n user: <sosp><13><709><291><709><544><136><837><524><66><790><173><856><758><106><879><524><637><66><354><142><898><43><120><376><445><20><879><91><162><511><347><104><486><103><180><998><347><487><557><432><918><42><856><31><136><13><136><511><275><10><196><98><661><292><232><448><933><524><162><601><171><358><760><752><820><333><930><982><70><223><268><144><162><618><155><136><13><291><13><365><eosp> ", "plain_text": "<happiness> Fur flew through the air, teeth gnashed. EmoSDS: <neutral> Wow, that sounds intense! What happened next?", "residual_length": 164, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Happy/0015_000897.npy", "dialogue_id": "959_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you hear what happened at the farm yesterday?\nuser: <happiness> Yeah! I can't believe the piglets are finally going outside!\nEmoSDS: <surprise> I know, right? It was so exciting!\n user: <sosp><13><136><748><13><235><13><235><13><876><358><760><752><831><28><568><213><445><890><103><111><615><371><158><487><368><360><545><450><204><288><162><511><680><196><309><304><292><933><204><998><98><292><232><450><91><584><98><196><333><309><432><42><856><1><43><716><213><890><159><111><371><571><171><822><898><304><283><403><196><724><136><13><136><13><235><13><365><eosp> ", "plain_text": "<happiness> No, said piggy carelessly. EmoSDS: <neutral> Oh, I see. He just doesn't care, huh?", "residual_length": 116, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Happy/0017_000989.npy", "dialogue_id": "1410_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Oh really? I've never thought about hippos in the zoo before.\nuser: <neutral> Yeah, they have a whole area just for them.\nEmoSDS: <happiness> That sounds fun! I love seeing the animals up close.\n user: <sosp><13><83><748><83><742><83><709><544><369><136><13><136><511><274><47><640><333><918><320><128><162><680><173><213><45><898><487><227><159><985><236><111><260><371><158><425><877><125><760><159><120><472><260><259><158><425><304><43><213><20><402><91><701><136><13><291><13><136><13><365><eosp> ", "plain_text": "<happiness> A hippo lives in the zoo. EmoSDS: <happiness> That's awesome! I bet it's so cute to watch!", "residual_length": 104, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Happy/0015_000787.npy", "dialogue_id": "423_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I never noticed how creepy they can be.\nuser: <sadness> It's kind of sad that no one pays attention to those details.\nEmoSDS: <happiness> But at least they tell us nobody visited in a while!\n user: <sosp><13><79><592><291><592><136><592><13><136><347><121><487><877><125><760><487><432><918><579><41><111><328><371><10><467><227><472><111><515><144><571><347><425><927><470><472><260><347><121><487><432><304><111><615><269><371><158><425><751><438><568><213><861><301><57><890><43><120><180><998><121><159><128><584><672><19><296><831><795><743><438><62><204><301><57><890><432><159><985><204><998><290><260><615><476><457><136><13><136><13><291><13><365><eosp> ", "plain_text": "<happiness> The nastiest things they saw were the cobwebs. EmoSDS: <happiness> Right? It's almost like a little story waiting to be uncovered!", "residual_length": 148, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Happy/0011_000745.npy", "dialogue_id": "216_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Have you heard about their situation?\nuser: <sadness> Yeah, it's really tough to see them go through that.\nEmoSDS: <surprise> I didn't expect them to split up after all these years.\n user: <sosp><13><235><13><136><13><136><13><136><837><637><921><104><644><808><790><958><557><958><523><568><62><998><522><304><320><111><259><144><618><557><304><292><933><564><511><708><10><309><283><403><470><933><125><493><91><162><511><347><757><136><13><136><13><748><13><666><136><876><43><261><62><998><347><121><43><856><103><587><522><159><985><861><879><790><231><237><754><295><848><930><111><615><371><904><371><476><757><136><114><13><136><863><369><13><235><13><365><eosp> ", "plain_text": "<happiness> From August eighteenth, of their divorce. EmoSDS: <sadness> I guess it marks a new chapter for both of them.", "residual_length": 150, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Happy/0017_000752.npy", "dialogue_id": "253_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> How was your day today?\nuser: <happiness> It was pretty good, actually! I got to see some friends.\nEmoSDS: <surprise> Oh, that's great! I didn't know you had plans.\n user: <sosp><13><79><235><79><422><136><274><743><820><477><360><350><432><159><889><125><493><91><116><162><511><584><672><43><173><213><73><173><890><103><304><470><454><493><288><128><162><511><275><10><737><309><304><376><20><879><91><574><162><680><487><918><47><41><128><584><672><311><64><523><484><523><808><983><808><889><701><114><13><235><13><381><13><365><eosp> ", "plain_text": "<happiness> I am going to back home. EmoSDS: <surprise> Oh wow, that's exciting! Are you looking forward to it?", "residual_length": 144, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Happy/0019_001046.npy", "dialogue_id": "1685_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> What time is the party tonight?\nuser: <happiness> It starts at seven, and I can't wait!\nEmoSDS: <surprise> Really? I thought it was later than that!\n user: <sosp><79><291><79><291><79><592><136><837><196><70><183><309><292><283><350><304><120><472><260><171><151><125><760><172><47><438><751><103><450><564><353><76><70><10><737><292><304><376><120><472><260><966><158><425><304><470><454><493><72><111><615><269><428><899><144><162><584><672><43><856><754><856><295><848><450><128><162><511><275><10><196><906><376><20><861><301><57><890><43><432><42><856><31><295><31><701><757><136><13><291><13><365><eosp> ", "plain_text": "<happiness> She is now choosing skirt to wear. EmoSDS: <happiness> That's great! I'm excited to see what she picks!", "residual_length": 167, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Happy/0020_000725.npy", "dialogue_id": "119_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Hey, how was your day today?\nuser: <happiness> It was great! I finally finished that project!\nEmoSDS: <surprise> Really? That's awesome! I didn't expect you to finish it so soon.\n user: <sosp><13><136><544><79><592><136><381><136><347><487><159><877><125><358><760><487><172><958><795><47><172><927><470><454><125><701><136><512><347><487><432><557><162><727><918><368><918><1><304><113><206><204><998><526><524><904><371><476><158><464><616><136><381><136><489><274><47><628><304><450><128><162><584><98><309><292><283><232><933><91><162><511><680><672><343><757><136><13><742><13><136><742><13><291><13><365><eosp> ", "plain_text": "<happiness> The nine the eggs, I keep. EmoSDS: <neutral> Oh, that's interesting! What do you plan to do with them?", "residual_length": 155, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Happy/0014_000701.npy", "dialogue_id": "1_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I love this band! Their last album was amazing.\nuser: <neutral> Yeah, I think this new song might surprise us.\nEmoSDS: <surprise> Really? I didn't expect them to release another track so soon.\n user: <sosp><13><592><79><592><291><592><136><592><13><235><13><998><347><487><120><125><760><432><927><350><304><583><889><173><62><879><569><998><347><442><472><111><615><269><371><158><425><751><958><795><108><583><125><304><472><111><615><371><899><144><511><672><296><64><110><213><45><998><347><333><918><47><360><320><545><522><487><227><58><128><162><584><526><615><371><476><544><13><291><13><136><13><235><13><365><eosp> ", "plain_text": "<happiness> The name of the song is called haddocks. EmoSDS: <happiness> Oh nice! I can't wait to listen to it, it sounds fun!", "residual_length": 142, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Happy/0012_001018.npy", "dialogue_id": "1553_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you lose it again?\nuser: <sadness> I really liked that shawl, you know?\nEmoSDS: <happiness> Maybe we can find another one just as nice!\n user: <sosp><13><291><13><136><13><136><291><13><136><171><998><467><487><227><432><42><159><113><450><584><300><43><518><445><444><472><260><571><121><159><472><930><982><70><737><425><43><831><438><568><603><213><898><159><113><206><98><300><918><432><927><470><454><701><13><291><13><365><eosp> ", "plain_text": "<happiness> There goes the shawl again! EmoSDS: <happiness> Oh, that's too bad! But hey, let's go shopping for something even better!", "residual_length": 101, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Happy/0011_000990.npy", "dialogue_id": "1415_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <anger> I can't believe you just ignored my message!\nuser: <sadness> I know, I've been really overwhelmed lately.\nEmoSDS: <neutral> Well, what's going on now?\n user: <sosp><13><79><291><79><291><79><592><136><13><136><876><360><320><450><128><162><511><347><487><918><360><41><879><524><66><159><103><583><125><760><283><470><454><493><162><76><70><737><425><42><856><295><159><985><91><162><524><347><338><467><304><470><454><493><998><779><997><558><866><432><320><125><493><162><574><162><511><99><467><292><232><823><557><300><432><42><607><31><115><544><13><291><13><291><136><13><365><eosp> ", "plain_text": "<happiness> A deafening chirruping rent the air. EmoSDS: <happiness> That's awesome! Sounds like nature is really lively today!", "residual_length": 141, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Happy/0012_000755.npy", "dialogue_id": "266_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> That's quite an unusual story you have there.\nuser: <happiness> I can't believe how creative you are with your tales!\nEmoSDS: <sadness> Still, it feels a bit strange, like there's something missing.\n user: <sosp><13><381><13><381><136><837><524><637><66><104><644><889><338><292><283><933><275><682><70><268><144><511><98><309><334><304><933><128><162><584><196><171><204><998><347><487><42><103><930><111><615><223><862><144><511><680><104><866><432><927><470><454><125><557><368><159><628><640><930><949><98><661><98><292><546><376><933><864><70><268><162><99><158><43><751><438><3><213><985><204><91><511><584><672><757><136><13><136><13><365><eosp> ", "plain_text": "<neutral> From each cake, there sprang a huge dog. EmoSDS: <neutral> I'm curious where this is all heading.", "residual_length": 148, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Neutral/0012_000211.npy", "dialogue_id": "1031_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I'm really excited about the project we discussed last week!\nuser: <surprise> Oh wow, I didn't expect you to feel that way!\nEmoSDS: <sadness> Yeah, but sometimes I wonder if I'm ready for it.\n user: <sosp><13><83><136><83><742><748><742><709><83><544><136><162><347><487><368><47><299><953><861><57><890><103><320><111><615><371><10><196><227><472><111><371><268><144><162><511><275><70><737><292><304><879><949><524><949><524><313><158><958><831><438><521><41><618><128><162><511><10><155><757><136><13><136><13><291><13><365><eosp> ", "plain_text": "<neutral> That was his chief thought. EmoSDS: <happiness> It's kind of interesting how thoughts can shape our actions, isn't it?", "residual_length": 113, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Neutral/0015_000008.npy", "dialogue_id": "38_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I think it's really sweet how much you care about her feelings.\nuser: <sadness> Yeah, but sometimes I can't help it. I just want to make her laugh, you know?\nEmoSDS: <surprise> I never imagined you'd worry about that!\n user: <sosp><79><235><79><235><592><962><592><136><13><511><958><831><47><477><628><1><304><877><889><358><889><760><432><350><304><450><128><584><672><737><104><856><758><450><128><511><439><871><375><112><231><173><831><360><1><304><17><823><128><511><275><10><223><862><171><125><760><197><856><295><56><236><879><338><292><403><300><557><368><277><128><162><511><708><10><19><775><831><743><689><1><382><130><125><701><72><285><615><371><476><757><136><757><13><369><13><235><13><365><eosp> ", "plain_text": "<neutral> I make her quite nervy at times. EmoSDS: <happiness> Well, you're just being yourself, and she probably appreciates that more than you think.", "residual_length": 151, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Neutral/0018_000191.npy", "dialogue_id": "931_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> How was your day at work?\nuser: <sadness> It was really exhausting. I barely had time to breathe.\nEmoSDS: <happiness> I'm sorry to hear that! Any plans to relax this weekend?\n user: <sosp><13><291><13><136><616><666><291><666><136><958><537><477><918><350><927><432><108><583><889><997><85><866><173><108><583><197><108><523><213><106><879><949><637><524><171><889><760><958><47><628><41><949><524><637><988><196><292><403><643><933><162><511><275><10><155><757><136><13><544><13><136><13><365><eosp> ", "plain_text": "<neutral> I am run off my feet. EmoSDS: <happiness> Oh, I get that! Want to grab a coffee and unwind?", "residual_length": 107, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Neutral/0012_000252.npy", "dialogue_id": "1232_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I'm so glad she finally found it after all that time!\nuser: <surprise> Really? I thought it was lost for good!\nEmoSDS: <neutral> Yeah, it was such a relief when she mentioned it.\n user: <sosp><79><433><79><592><381><13><136><876><136><876><309><432><36><125><288><275><982><70><10><467><292><232><319><128><162><595><162><511><584><672><311><296><831><47><277><545><128><162><618><557><47><918><277><545><156><128><162><998><121><159><985><204><91><680><104><295><486><376><91><162><13><136><76><70><343><476><396><757><136><195><136><291><13><136><13><365><eosp> ", "plain_text": "<neutral> And she caught at the brooch. EmoSDS: <happiness> That's wonderful! It must have meant a lot to her to get it back.", "residual_length": 140, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Neutral/0014_000324.npy", "dialogue_id": "1582_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you know the elephant is the largest land animal?\nuser: <happiness> That's interesting! Elephants are pretty amazing!\nEmoSDS: <sadness> It’s sad how their habitats are shrinking.\n user: <sosp><13><136><13><291><13><235><13><162><347><467><292><557><918><360><568><370><213><159><62><949><524><313><158><487><432><36><125><493><72><288><511><275><371><10><158><464><136><876><360><320><583><125><998><121><159><320><128><162><584><871><311><907><831><856><62><128><511><680><159><125><288><548><10><425><159><295><607><295><184><31><701><136><585><177><227><472><111><371><515><144><162><347><121><213><861><97><861><517><523><690><667><493><584><300><557><131><400><615><371><615><371><223><144><275><618><155><757><136><13><365><eosp> ", "plain_text": "<neutral> The elephant and the carpenter is the longest. EmoSDS: <sadness> I guess it just shows how fragile everything is, huh?", "residual_length": 158, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0016/Neutral/0016_000103.npy", "dialogue_id": "499_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I really enjoyed the story you wrote last week!\nuser: <neutral> Thanks! I worked hard on that one.\nEmoSDS: <surprise> I didn’t know you had it in you to write such a twist!\n user: <sosp><79><291><79><592><291><13><136><837><347><467><292><232><403><350><927><304><583><125><493><288><162><680><133><790><64><831><856><545><450><557><177><227><472><111><615><899><524><737><338><227><103><930><982><70><862><171><760><958><368><47><438><3><310><78><198><757><524><343><476><757><136><863><136><13><291><13><365><eosp> ", "plain_text": "<neutral> The end part is fish mouth. EmoSDS: <happiness> Oh, I thought that was a really clever detail!", "residual_length": 110, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Neutral/0019_000277.npy", "dialogue_id": "1354_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> That's awesome! How was the hunt?\nuser: <neutral> It was pretty challenging, but I managed to track it down.\nEmoSDS: <surprise> I can't believe you actually did it! How did you feel when it happened?\n user: <sosp><13><235><13><235><136><616><136><876><489><274><743><477><1><261><985><204><995><91><511><682><783><425><159><472><111><615><70><737><425><43><831><438><579><62><128><708><158><557><159><320><111><615><371><268><144><686><487><368><47><145><1><113><450><204><584><672><196><333><79><757><136><13><235><13><863><365><eosp> ", "plain_text": "<neutral> I've just shot a stag. EmoSDS: <neutral> Oh, that's interesting. What made you take the shot?", "residual_length": 116, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Neutral/0017_000265.npy", "dialogue_id": "1292_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I heard Tom finally completed his mountain climb!\nuser: <surprise> Wow, really? That sounds incredible!\nEmoSDS: <neutral> Yeah, but he did have a few close calls on the way down.\n user: <sosp><13><136><83><742><748><742><83><136><958><108><62><889><125><493><288><524><887><158><487><368><47><568><213><20><861><301><57><890><103><450><128><162><511><347><487><159><180><91><162><511><584><936><517><751><62><879><347><487><130><125><760><333><820><918><47><368><1><545><450><522><618><159><701><757><701><757><136><365><eosp> ", "plain_text": "<neutral> Tom fell with a cloven head. EmoSDS: <neutral> That’s unfortunate to hear. I hope he’s okay.", "residual_length": 104, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Neutral/0015_000177.npy", "dialogue_id": "862_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I'm really glad we had that fun time at the party last week!\nuser: <happiness> Yeah, it was such a blast getting everyone together!\nEmoSDS: <sadness> But I can't help but feel a bit down that we don't hang out as much anymore.\n user: <sosp><136><79><291><592><136><291><136><489><240><523><110><213><793><949><615><428><862><171><889><958><795><108><751><213><445><20><861><811><301><57><231><655><237><480><85><997><85><486><304><43><213><645><557><958><368><481><36><583><125><429><493><121><487><368><47><333><820><47><261><62><128><574><511><680><338><292><700><304><43><295><180><128><162><347><121><159><985><889><89><231><655><754><295><103><111><615><371><158><36><125><72><328><371><10><196><58><159><434><31><701><757><136><13><291><13><136><13><365><eosp> ", "plain_text": "<neutral> All smile were real and the happier the more sincere. EmoSDS: <happiness> Absolutely! It really shows how genuine our moments are.", "residual_length": 187, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Neutral/0020_000031.npy", "dialogue_id": "149_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> So, have they talked to him lately?\nuser: <sadness> No, they just seem so distant now.\nEmoSDS: <happiness> It's a shame, they used to be so close.\n user: <sosp><13><235><13><235><13><511><347><121><159><879><524><887><425><43><103><930><982><70><737><104><644><889><432><360><583><125><760><432><36><583><125><298><215><94><159><472><260><259><899><20><861><301><57><380><831><477><1><304><879><949><899><371><904><571><371><183><292><232><933><204><632><76><682><783><104><231><655><754><295><587><450><864><682><783><557><368><261><62><56><879><104><486><304><933><522><300><487><368><1><15><58><643><701><136><701><136><13><235><13><365><eosp> ", "plain_text": "<neutral> The fisherman and his wife see George every day. EmoSDS: <happiness> That's nice! Maybe they can reconnect.", "residual_length": 156, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Neutral/0017_000305.npy", "dialogue_id": "1491_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> That sounds like such a nice idea! She'll love that.\nuser: <neutral> I thought she might enjoy something healthy.\nEmoSDS: <happiness> Absolutely! Plus, it’s always great to support her cooking.\n user: <sosp><13><863><136><235><79><291><79><592><136><837><371><158><425><159><450><128><162><680><133><790><64><213><518><103><260><966><158><487><368><360><320><450><128><708><10><309><304><206><204><511><779><210><85><866><368><1><159><583><125><889><760><958><751><180><998><121><159><645><557><162><958><62><879><524><212><104><866><856><579><930><982><615><70><524><212><82><487><368><579><400><615><223><268><275><158><159><985><91><680><790><509><3><78><198><757><136><13><291><136><13><136><13><365><eosp> ", "plain_text": "<neutral> Suppose I take grandmother a fresh vegetable. EmoSDS: <happiness> That's really thoughtful of you! She'll be so happy to get it.", "residual_length": 144, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Neutral/0019_000085.npy", "dialogue_id": "414_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I really enjoyed the movie last night!\nuser: <neutral> Yeah, it was pretty entertaining.\nEmoSDS: <surprise> Did you see that plot twist at the end?\n user: <sosp><13><291><13><291><13><136><13><136><13><136><622><98><292><232><564><584><672><196><442><877><125><760><172><47><277><545><923><333><296><64><213><62><91><128><511><680><998><686><425><43><376><890><159><470><454><493><72><526><615><428><878><158><425><43><60><445><985><91><136><701><136><13><136><13><136><13><365><eosp> ", "plain_text": "<neutral> He could not help doing so. EmoSDS: <happiness> That's true! Sometimes things just happen, and we go along with them.", "residual_length": 101, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Neutral/0020_000281.npy", "dialogue_id": "1373_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I finally got the new weights for our workout!\nuser: <surprise> That’s awesome! What weight did you get?\nEmoSDS: <neutral> They're all adjustable, but the heaviest one is seven point five kilograms.\n user: <sosp><544><13><136><13><136><291><13><136><13><291><136><511><105><304><376><20><861><301><57><890><43><304><393><472><111><615><269><371><158><425><487><368><261><985><969><103><125><288><512><680><133><375><231><173><890><174><304><933><789><879><524><637><66><790><958><831><795><743><47><1><985><879><128><162><511><98><672><196><43><213><603><213><159><450><779><85><104><866><856><382><432><172><60><244><889><290><260><615><428><476><757><136><13><291><13><136><13><365><eosp> ", "plain_text": "<neutral> It weighs seven point five kilogram. EmoSDS: <happiness> That's perfect for building strength; we can really challenge ourselves!", "residual_length": 155, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Neutral/0013_000210.npy", "dialogue_id": "1026_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> What are you talking about?\nuser: <surprise> I just saw something move in the bushes!\nEmoSDS: <happiness> That's probably just a rabbit or something.\n user: <sosp><13><592><235><592><13><235><13><136><616><13><136><171><354><517><173><518><320><128><584><300><557><47><831><438><213><521><128><162><511><618><10><464><757><131><421><111><371><158><487><368><360><545><522><557><274><47><743><47><438><568><603><517><751><159><579><320><111><615><904><476><701><757><136><235><13><136><13><136><365><eosp> ", "plain_text": "<neutral> Look out! said Alice. EmoSDS: <surprise> Wait, what do you mean? Is there something there?", "residual_length": 112, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Neutral/0018_000118.npy", "dialogue_id": "576_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I'm so curious about what you're up to!\nuser: <surprise> You really want to know? It's kind of mysterious!\nEmoSDS: <anger> Well, it better not be something outrageous!\n user: <sosp><13><235><13><369><592><136><585><511><105><304><442><450><328><862><144><162><680><133><311><296><831><754><856><218><43><694><62><879><889><958><47><1><640><320><111><904><371><183><467><292><232><91><162><511><779><921><104><856><382><277><131><128><136><162><13><666><136><235><136><13><365><eosp> ", "plain_text": "<neutral> It's part of my secret. EmoSDS: <happiness> Oh, come on! Secrets can be fun too!", "residual_length": 97, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Neutral/0017_000327.npy", "dialogue_id": "1597_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I'm so glad we get to have everyone over for the party!\nuser: <neutral> Yes, it's going to be a great gathering.\nEmoSDS: <sadness> I just wish Sarah could join us too.\n user: <sosp><13><79><863><136><235><13><136><235><511><680><936><347><898><304><292><283><393><260><371><158><425><360><583><125><493><998><790><958><831><47><1><304><580><128><511><275><10><311><831><523><108><89><889><557><159><879><949><524><162><347><487><304><42><856><295><120><472><260><259><371><268><457><136><13><171><125><286><125><760><958><831><523><178><41><288><275><921><104><295><985><91><162><511><439><375><112><790><517><831><47><477><1><382><434><295><848><131><111><615><371><428><476><155><757><136><291><13><136><13><365><eosp> ", "plain_text": "<neutral> Please invite Tom if there is not requires. EmoSDS: <neutral> Sure, I'll send him an invite soon.", "residual_length": 177, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0016/Neutral/0016_000306.npy", "dialogue_id": "1494_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> That's great news! It sounds like you had a successful mission.\nuser: <neutral> It was a mixed experience, honestly. Some moments were intense.\nEmoSDS: <sadness> I can only imagine the kind of toll it took on you.\n user: <sosp><13><748><13><235><13><162><136><274><47><628><304><933><450><91><162><511><686><467><227><304><933><522><933><162><511><584><425><43><751><484><213><645><557><432><320><125><358><125><889><760><304><327><334><403><304><933><522><933><601><151><889><760><432><130><125><454><403><292><933><91><162><511><680><921><104><866><120><472><260><259><158><425><877><125><197><856><607><31><848><131><472><111><615><371><476><757><136><757><13><136><13><365><eosp> ", "plain_text": "<neutral> I did go, and made many prisoners. EmoSDS: <happiness> That's impressive! It must feel like a big achievement for you.", "residual_length": 154, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Neutral/0015_000002.npy", "dialogue_id": "8_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I saw her looking at those clothes earlier.\nuser: <happiness> That's exciting! I hope she picks something cute.\nEmoSDS: <sadness> It's just a shame she always second-guesses herself.\n user: <sosp><13><79><235><592><235><592><13><136><837><982><70><309><283><304><120><320><472><966><260><347><171><125><358><760><172><47><831><568><836><320><450><128><275><70><737><906><376><472><259><158><425><304><718><454><125><72><526><615><371><899><144><511><584><104><856><295><557><128><162><511><275><10><906><376><20><861><301><57><380><368><432><1><31><701><757><114><13><235><13><136><13><365><eosp> ", "plain_text": "<neutral> She is now choosing skirt to wear. EmoSDS: <neutral> Oh, that’s interesting. I wonder what she’ll decide on.", "residual_length": 136, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Neutral/0018_000025.npy", "dialogue_id": "117_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I love watching pandas play around, they're so cute!\nuser: <happiness> Right? They always make me smile.\nEmoSDS: <sadness> Yeah, but it's sad to think about how endangered they are.\n user: <sosp><13><136><291><13><136><301><57><890><700><304><43><64><110><213><178><400><615><428><371><10><183><467><292><933><91><162><511><680><597><333><309><918><172><360><583><493><998><522><487><43><751><438><795><108><36><583><125><493><288><512><708><10><196><292><933><995><338><292><700><376><20><231><655><480><754><295><382><304><227><472><125><36><472><260><158><425><227><120><376><20><388><20><112><757><136><13><291><13><136><13><136><13><365><eosp> ", "plain_text": "<neutral> We all see panda on TV or in the zoo. EmoSDS: <happiness> It's true, but they still bring joy to many people.", "residual_length": 179, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Neutral/0013_000144.npy", "dialogue_id": "705_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I just got a promotion at work! I'm so excited!\nuser: <neutral> That's great news! Congrats!\nEmoSDS: <surprise> Thanks! I really didn't expect it at all.\n user: <sosp><79><235><79><962><592><422><136><489><274><831><568><178><400><949><615><371><158><487><360><583><493><851><618><899><524><66><104><856><103><587><450><162><708><10><333><311><775><523><108><583><125><493><288><511><708><10><425><171><889><760><958><47><477><1><320><450><91><680><159><450><162><511><686><20><983><655><31><701><757><701><757><136><235><592><13><235><13><365><eosp> ", "plain_text": "<neutral> I'll send for Tom to my boudoir. EmoSDS: <happiness> Oh, that sounds lovely! I hope you two have a great time.", "residual_length": 128, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Neutral/0018_000218.npy", "dialogue_id": "1063_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I'm so excited to hear that story! It sounds fun!\nuser: <neutral> It's about how they became best friends.\nEmoSDS: <surprise> Really? I didn't expect that twist!\n user: <sosp><13><592><381><592><235><13><136><837><615><22><223><268><144><511><158><425><64><231><754><866><486><304><933><564><162><275><10><899><921><112><790><173><432><103><493><288><708><10><309><292><304><125><358><760><172><795><108><172><927><470><454><125><557><616><489><958><694><213><985><204><91><162><680><997><20><983><213><890><120><304><823><557><300><432><130><125><493><522><487><43><316><985><889><760><958><108><454><667><288><98><403><643><136><13><235><13><136><13><365><eosp> ", "plain_text": "<neutral> Story twenty nine a boy and a monkey. EmoSDS: <happiness> That sounds adorable! I can't wait to hear more.", "residual_length": 163, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Neutral/0012_000043.npy", "dialogue_id": "207_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Have you ever tried sourdough?\nuser: <happiness> Yeah, I used to love it when I was a kid!\nEmoSDS: <sadness> That's a shame you don't eat it anymore.\n user: <sosp><13><136><79><757><136><291><489><876><274><1><628><933><450><998><99><338><376><103><125><760><958><795><47><261><277><545><128><105><292><232><933><450><128><574><162><511><680><85><104><866><368><1><131><450><162><511><99><618><464><159><131><757><136><13><136><13><291><13><136><13><365><eosp> ", "plain_text": "<neutral> I do not eat bread. EmoSDS: <neutral> Oh, that's interesting. What made you decide that?", "residual_length": 97, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Neutral/0020_000068.npy", "dialogue_id": "331_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe Valentine’s Day is finally here!\nuser: <happiness> I know, right? I can't wait to celebrate!\nEmoSDS: <sadness> I just wish I had someone special to share it with.\n user: <sosp><13><592><235><592><235><592><235><13><592><876><236><347><467><292><300><557><918><172><360><583><125><493><777><686><43><62><879><524><313><158><487><368><261><62><998><338><304><376><109><861><57><890><43><856><382><304><196><949><524><637><66><790><231><655><856><295><545><450><128><511><275><10><196><309><292><403><470><36><131><72><524><347><158><757><136><13><235><13><365><eosp> ", "plain_text": "<neutral> The end of February fourteenth. EmoSDS: <neutral> Yeah, it's just another day after all.", "residual_length": 128, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Neutral/0018_000291.npy", "dialogue_id": "1422_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <anger> Why do you always have to rush me?\nuser: <happiness> I'm just excited to get started!\nEmoSDS: <sadness> But I feel like I'm being pushed aside.\n user: <sosp><13><79><235><962><592><136><13><235><171><204><162><680><338><292><283><300><557><489><831><438><178><311><879><524><159><103><358><760><752><172><47><942><743><438><213><645><557><368><320><111><615><371><223><899><144><511><439><276><921><309><159><304><113><128><511><196><300><43><120><320><472><111><260><371><183><292><376><889><760><432><327><382><403><643><701><136><13><136><757><235><136><13><592><365><eosp> ", "plain_text": "<neutral> Be off now as quick as you may! EmoSDS: <neutral> Fine, I guess I can hurry up a bit.", "residual_length": 141, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Neutral/0018_000083.npy", "dialogue_id": "404_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe how much you've grown since last summer!\nuser: <sadness> Yeah, but I miss the simplicity of those days.\nEmoSDS: <anger> It's hard to believe some people don’t appreciate our friendship.\n user: <sosp><79><433><592><433><136><876><333><309><304><120><472><260><371><158><354><603><354><517><751><438><856><295><587><450><353><76><682><899><171><151><889><760><172><108><438><88><400><524><476><10><196><136><13><136><511><584><871><672><921><311><200><856><200><754><295><213><45><450><204><511><618><425><557><58><304><36><125><728><493><288><275><10><737><906><376><20><890><159><472><111><615><371><862><171><125><760><467><470><927><434><31><701><757><136><13><365><eosp> ", "plain_text": "<neutral> His large mouth curled into a sneer. EmoSDS: <neutral> I know, it’s just part of his arrogance, isn’t it?", "residual_length": 187, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Neutral/0014_000164.npy", "dialogue_id": "800_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I'm so excited for the weekend! What do you have planned?\nuser: <happiness> I thought we'd go to the fair! You know how much I love the rides!\nEmoSDS: <neutral> That sounds fun, I suppose. I've never been too into fairs, though.\n user: <sosp><79><592><433><13><136><13><433><136><584><672><296><108><583><889><760><173><108><583><728><770><889><760><958><172><1><15><545><450><204><162><76><682><783><300><368><47><261><41><584><98><196><425><36><583><125><728><760><487><159><985><204><270><958><795><47><261><169><128><526><371><158><425><227><120><472><111><615><371><476><457><757><136><13><136><742><13><433><13><136><13><365><eosp> ", "plain_text": "<neutral> Come on my jack in the boxes! EmoSDS: <happiness> I guess that means you're ready to have some fun then!", "residual_length": 134, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Neutral/0014_000074.npy", "dialogue_id": "360_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe how clean you keep your house; it really shines!\nuser: <neutral> Thanks! I try to keep it tidy, but there's always something to clean.\nEmoSDS: <sadness> It's tough when they get messy so fast though, isn't it?\n user: <sosp><79><291><79><962><592><13><291><13><136><288><511><347><487><159><877><125><728><125><760><487><432><918><579><41><111><515><371><10><467><227><472><111><615><371><144><347><425><304><927><470><454><72><260><571><347><487><432><304><933><111><615><269><428><40><158><425><213><110><213><983><811><301><57><890><43><180><998><121><159><41><128><162><584><672><296><831><743><438><62><204><861><301><57><890><1><432><159><985><450><91><998><290><111><615><223><476><457><13><136><13><136><291><13><291><13><365><eosp> ", "plain_text": "<neutral> The nastiest things they saw were the cobwebs. EmoSDS: <neutral> Yeah, cobwebs can be pretty off-putting, especially in corners.", "residual_length": 162, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Neutral/0011_000045.npy", "dialogue_id": "217_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I've never seen him smile like that before!\nuser: <neutral> It's nice to know someone can bring him joy.\nEmoSDS: <surprise> I wasn't expecting that reaction from him at all!\n user: <sosp><13><709><433><13><544><13><136><13><291><13><136><121><487><333><159><856><754><295><486><113><933><206><450><526><260><615><371><158><425><43><159><472><260><615><268><144><665><158><425><120><877><125><889><760><432><15><304><232><933><564><511><526><219><10><158><425><159><889><125><493><288><162><680><936><375><517><751><320><260><158><425><36><125><384><701><136><701><757><136><365><eosp> ", "plain_text": "<neutral> Her existence makes him pleasant. EmoSDS: <happiness> That's wonderful! It seems she's really making an impact on him.", "residual_length": 129, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Neutral/0013_000225.npy", "dialogue_id": "1099_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> That's so nice! They must enjoy his company.\nuser: <neutral> Yeah, George always has interesting stories to share.\nEmoSDS: <surprise> Really? I didn't know he was such a storyteller!\n user: <sosp><13><79><235><136><592><136><616><13><235><13><136><204><998><347><121><159><316><879><524><313><158><43><103><930><982><70><737><856><644><889><760><432><130><583><125><760><557><432><130><583><522><618><333><94><227><120><472><260><259><899><861><57><173><380><831><47><477><1><304><930><949><524><343><10><371><183><292><933><632><275><682><881><783><486><890><445><655><856><103><472><353><682><10><425><557><368><261><985><879><104><486><304><933><450><998><99><487><368><1><382><58><643><701><757><701><13><136><701><235><13><136><13><365><eosp> ", "plain_text": "<neutral> The fisherman and his wife see George every day. EmoSDS: <neutral> It’s kind of a routine for them, isn’t it?", "residual_length": 170, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Neutral/0018_000305.npy", "dialogue_id": "1490_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't wait to see the view from up there!\nuser: <happiness> Yeah, it's going to be amazing!\nEmoSDS: <neutral> Just hope the weather stays nice.\n user: <sosp><13><136><13><136><13><235><13><162><511><347><487><360><320><111><615><371><223><268><144><275><10><19><856><130><125><493><204><162><584><43><213><445><376><103><111><615><223><268><144><275><10><425><180><347><121><487><360><640><333><918><43><751><716><213><402><701><136><13><291><13><136><365><eosp> ", "plain_text": "<neutral> this turn goes to the hill. EmoSDS: <neutral> I guess that makes sense, let’s enjoy the hike.", "residual_length": 103, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0016/Neutral/0016_000126.npy", "dialogue_id": "616_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I'm so glad we finally made him laugh!\nuser: <happiness> It was the perfect joke at the right time!\nEmoSDS: <surprise> I didn't expect him to react that way!\n user: <sosp><13><136><79><592><13><235><592><136><13><162><275><10><19><333><311><775><831><62><889><125><493><288><162><584><672><597><159><103><545><522><19><311><775><831><856><320><450><204><998><354><898><304><292><393><111><615><371><862><144><162><680><338><292><232><933><162><584><921><524><637><212><66><790><480><866><213><603><517><441><47><579><62><879><524><158><487><432><58><470><454><701><136><235><13><365><eosp> ", "plain_text": "<neutral> Tom could hardly speak for laughing. EmoSDS: <happiness> That just shows how much he enjoyed it!", "residual_length": 125, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0016/Neutral/0016_000065.npy", "dialogue_id": "317_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe we're finally going on this trip!\nuser: <neutral> Yeah, it's been a long time coming.\nEmoSDS: <surprise> I just found out that we can actually explore the Great Wall!\n user: <sosp><13><79><235><79><592><136><616><235><489><958><399><110><568><518><320><349><347><121><173><213><20><861><57><890><380><432><334><304><933><564><275><10><425><227><472><450><353><275><682><70><10><19><775><958><831><47><172><432><927><583><125><760><172><108><360><557><227><159><472><260><371><158><899><311><775><523><89><479><250><701><757><136><757><235><13><235><13><592><13><365><eosp> ", "plain_text": "<neutral> All the way to China is home. EmoSDS: <happiness> It's amazing to think of all the adventures waiting for us!", "residual_length": 126, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Neutral/0018_000151.npy", "dialogue_id": "738_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I just love making people laugh with my jokes!\nuser: <surprise> No way! You've got some good ones up your sleeve?\nEmoSDS: <anger> Well, it's not like everyone knows how funny I am!\n user: <sosp><13><83><136><83><27><381><83><544><136><162><511><98><672><333><309><918><360><454><304><202><856><103><587><125><760><432><327><350><304><454><493><680><338><292><933><151><889><231><655><856><178><311><438><568><213><603><517><898><432><1><42><856><382><304><120><159><320><111><371><158><757><136><13><136><13><136><291><136><365><eosp> ", "plain_text": "<neutral> Can your name be more hilarious? EmoSDS: <happiness> Haha, I could always add a pun or two to it!", "residual_length": 118, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Neutral/0015_000276.npy", "dialogue_id": "1349_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Have you seen those birds in the park lately?\nuser: <happiness> Yes! I love hearing their songs in the morning.\nEmoSDS: <sadness> It's such a shame their habitat is shrinking, though.\n user: <sosp><79><291><79><592><136><162><680><790><441><47><41><128><574><162><680><104><754><295><848><545><522><557><432><130><125><493><632><864><682><783><300><382><327><403><643><266><136><863><13><365><eosp> ", "plain_text": "<neutral> Blackbird, and Jay. EmoSDS: <neutral> Yeah, they are a common sight around here.", "residual_length": 82, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Neutral/0019_000157.npy", "dialogue_id": "763_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> That's amazing! So she has quite a history behind her.\nuser: <neutral> Yeah, a lot has happened since then.\nEmoSDS: <surprise> I can’t believe how much the world has changed since then!\n user: <sosp><13><136><79><291><79><592><291><13><136><837><70><196><292><376><20><890><472><260><259><862><91><204><768><680><231><173><108><856><583><197><958><795><108><583><760><557><15><304><933><450><162><511><680><104><213><180><583><125><760><958><47><172><432><470><454><493><288><162><275><10><98><309><292><470><454><728><493><288><524><637><66><112><231><890><295><103><450><522><467><292><232><933><524><347><121><159><997><85><104><295><382><58><643><136><701><136><291><13><136><13><365><eosp> ", "plain_text": "<neutral> She was born on April nineteen forty three. EmoSDS: <happiness> It’s interesting to think about all the events she’s witnessed over the years!", "residual_length": 160, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Neutral/0020_000071.npy", "dialogue_id": "346_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I saw the cutest octopus at the aquarium yesterday!\nuser: <surprise> Really? Was it doing anything interesting?\nEmoSDS: <happiness> Yes! It was changing colors and playing with the divers!\n user: <sosp><13><136><335><618><79><291><79><592><136><171><998><121><487><958><831><406><128><511><686><159><316><450><162><680><790><890><103><472><260><615><158><19><368><320><472><260><371><158><557><300><334><292><232><933><162><99><10><425><464><171><354><898><487><368><1><113><450><204><91><162><584><526><615><428><476><757><136><757><291><757><136><13><365><eosp> ", "plain_text": "<neutral> The octopus has eight legs. EmoSDS: <surprise> I always thought they were kind of weird looking, but eight legs is really something!", "residual_length": 126, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Neutral/0020_000058.npy", "dialogue_id": "282_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I always found him intriguing in his ability to navigate complex situations.\nuser: <happiness> Yeah, he really knew how to connect with people and inspire them.\nEmoSDS: <sadness> It's such a shame he’s not around anymore to share his insights.\n user: <sosp><13><291><13><136><162><680><338><292><933><450><584><672><296><368><360><320><615><371><10><196><292><376><20><890><103><472><260><425><43><644><889><760><432><172><47><172><360><583><469><889><861><301><57><890><159><320><450><347><557><552><432><287><879><524><66><425><103><125><760><159><953><295><997><85><338><292><393><111><615><269><428><899><20><231><655><754><295><848><472><260><615><158><487><368><172><481><36><583><125><760><557><136><131><111><615><371><158><425><159><113><450><206><300><368><47><579><400><615><371><158><425><472><450><162><275><10><196><58><403><643><136><13><291><13><365><eosp> ", "plain_text": "<neutral> Because he was a man with infinite resource and sagacity. EmoSDS: <happiness> That’s true, he did have a remarkable way of seeing things, I kind of miss those discussions.", "residual_length": 197, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Neutral/0020_000274.npy", "dialogue_id": "1340_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> That's pretty interesting, I didn't know that was a thing.\nuser: <happiness> Yeah, we found it during our trip to the beach last summer!\nEmoSDS: <surprise> No way! I can't believe you actually found a shark tooth!\n user: <sosp><13><136><79><291><79><136><112><57><890><338><304><300><43><159><879><949><982><70><737><425><43><213><445><376><304><196><298><309><304><227><111><615><982><70><737><425><856><831><856><41><128><574><162><511><275><10><196><292><58><376><58><196><111><524><347><476><155><757><136><13><136><13><291><13><365><eosp> ", "plain_text": "<neutral> We have showed his shark tooth. EmoSDS: <neutral> It must have been a cool find, can I see it sometime?", "residual_length": 104, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Neutral/0019_000241.npy", "dialogue_id": "1179_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I finally got chosen for the project!\nuser: <surprise> Really? That's amazing, I had no idea!\nEmoSDS: <sadness> But then I realized they didn’t want my input on it.\n user: <sosp><13><235><13><136><13><136><13><136><235><13><136><105><304><545><522><304><472><966><767><36><125><493><91><680><597><333><309><327><304><933><128><162><511><686><487><368><545><923><958><831><438><78><402><701><136><13><235><13><365><eosp> ", "plain_text": "<neutral> it isn't picked at all. EmoSDS: <sadness> That's disappointing, I thought you were in the running for it.", "residual_length": 88, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Neutral/0017_000216.npy", "dialogue_id": "1055_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Hey, did you see that documentary on the history of art last night?\nuser: <happiness> Yeah, it was amazing! I loved how they explained the different movements.\nEmoSDS: <sadness> I know, but it made me think about all the artists who struggled so much.\n user: <sosp><79><291><962><136><13><291><136><311><231><213><45><349><522><121><43><953><156><889><958><1><628><304><450><564><275><76><70><10><309><432><36><125><728><125><72><328><615><428><371><268><144><354><517><43><751><445><890><958><368><432><481><36><583><125><72><328><615><371><158><487><958><438><568><213><45><121><159><227><131><128><162><99><618><425><131><757><136><13><136><13><136><13><863><136><291><136><13><365><eosp> ", "plain_text": "<neutral> Hold up my chin, slow and solid. EmoSDS: <neutral> Okay, I'm not sure what that means, but it sounds intriguing.", "residual_length": 138, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Neutral/0020_000038.npy", "dialogue_id": "181_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I think it's really sweet how much you care about her feelings.\nuser: <sadness> Yeah, but sometimes I can't help it. I just want to make her laugh, you know?\nEmoSDS: <surprise> I never imagined you'd worry about that!\n user: <sosp><13><136><13><235><13><235><369><13><666><136><876><274><47><1><304><583><889><760><304><232><564><162><584><672><921><104><295><450><128><616><162><511><871><276><112><790><64><173><751><1><304><232><933><128><171><125><760><202><856><295><56><879><338><292><300><432><297><545><450><162><511><708><10><19><775><958><795><108><1><130><125><250><125><701><72><260><615><371><615><428><476><13><544><13><136><13><235><13><365><eosp> ", "plain_text": "<neutral> I make her quite nervy at times. EmoSDS: <happiness> Well, you're just being yourself, and she probably appreciates that more than you think.", "residual_length": 132, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Neutral/0012_000191.npy", "dialogue_id": "931_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I finally got a chance to read that fable you mentioned!\nuser: <surprise> Oh really? What did you think of the ending?\nEmoSDS: <neutral> It was interesting, but a bit confusing at times.\n user: <sosp><13><335><79><291><79><422><136><876><432><927><454><20><454><20><57><890><103><353><275><982><10><949><524><212><790><173><831><598><400><672><526><615><371><171><354><142><898><376><472><260><472><504><158><425><159><320><450><162><275><371><10><333><309><432><304><43><751><213><645><557><162><557><432><583><760><432><304><472><450><328><371><158><557><136><616><489><557><368><568><213><45><349><347><121><159><930><111><615><269><428><40><158><425><472><111><615><223><268><144><275><783><425><159><930><949><524><66><958><831><523><537><108><1><36><454><125><278><72><328><615><223><899><977><20><301><20><655><3><108><60><36><125><701><136><13><291><13><863><365><eosp> ", "plain_text": "<neutral> In which fox loses a tail and its elder sister finds one. EmoSDS: <happiness> I think that's a clever twist! It shows how families can help each other.", "residual_length": 208, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Neutral/0019_000040.npy", "dialogue_id": "194_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <sadness> I really wish she didn't have to study so hard.\nuser: <happiness> At least her efforts will pay off in the end!\nEmoSDS: <neutral> It's just that she's been at it for days without a break.\n user: <sosp><13><291><13><291><13><136><13><136><837><70><737><425><43><213><45><204><680><338><292><933><949><524><988><338><292><304><933><56><879><104><295><930><70><783><300><368><47><261><41><879><162><176><737><159><111><615><40><158><425><43><36><213><889><760><159><930><76><70><10><371><144><347><487><432><470><454><98><300><432><382><58><454><701><136><13><136><13><291><13><365><eosp> ", "plain_text": "<neutral> She'll be feverish after so much thinking. EmoSDS: <neutral> Yeah, I hope she takes some time to rest soon.", "residual_length": 136, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Neutral/0011_000331.npy", "dialogue_id": "1617_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <sadness> I really wish she didn't have to study so hard.\nuser: <happiness> At least her efforts will pay off in the end!\nEmoSDS: <neutral> It's just that she's been at it for days without a break.\n user: <sosp><13><381><13><136><13><136><13><136><837><70><737><304><43><213><45><450><204><998><338><700><58><933><949><524><988><309><292><283><304><56><104><295><382><930><982><70><737><196><557><162><557><876><274><47><62><879><128><162><275><737><104><295><930><982><615><371><158><425><43><108><213><583><889><760><958><108><261><545><353><76><70><10><524><571><347><487><432><927><470><454><493><288><162><584><98><300><58><454><701><757><381><13><136><13><136><13><381><136><13><365><eosp> ", "plain_text": "<neutral> She'll be feverish after so much thinking. EmoSDS: <neutral> Yeah, I hope she takes some time to rest soon.", "residual_length": 185, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Neutral/0014_000331.npy", "dialogue_id": "1617_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can’t believe we finally finished the project!\nuser: <happiness> I know, right? It feels great to see it all come together!\nEmoSDS: <neutral> So, what’s the plan for the celebration?\n user: <sosp><79><291><79><592><136><13><381><162><680><936><919><898><304><292><393><747><158><159><877><889><790><958><831><47><1><933><564><511><708><10><19><296><831><795><108><583><889><760><159><879><524><128><162><511><347><487><227><42><856><295><472><111><260><171><125><760><172><47><299><521><997><104><985><128><871><112><231><64><438><1><382><295><848><472><111><615><371><428><476><757><136><13><136><13><291><13><365><eosp> ", "plain_text": "<neutral> Please invite Tom if there is not requires. EmoSDS: <neutral> Sure, I’ll send him a message.", "residual_length": 135, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Neutral/0019_000306.npy", "dialogue_id": "1492_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I remember the joy when they first planted that crop!\nuser: <sadness> But it was such a struggle for them that year.\nEmoSDS: <neutral> Yeah, they faced a lot of challenges.\n user: <sosp><13><962><235><962><592><13><136><162><511><347><121><43><106><879><949><524><637><66><104><856><103><111><615><371><268><144><275><458><292><304><42><856><848><159><180><450><998><347><487><432><304><111><615><371><158><425><43><213><445><103><450><730><109><997><85><866><831><743><47><477><1><382><58><643><333><757><13><235><13><365><eosp> ", "plain_text": "<neutral> The first year they sowed rye. EmoSDS: <happiness> It's amazing how far they've come since then!", "residual_length": 121, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Neutral/0018_000229.npy", "dialogue_id": "1119_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't wait for the feast tonight! It's going to be amazing!\nuser: <sadness> I hope everyone enjoys it; I just wish it didn't remind me of last year's disaster.\nEmoSDS: <anger> Last year's disaster was awful! Why didn't anyone listen to my suggestions?\n user: <sosp><13><291><13><136><291><13><136><511><98><292><304><376><879><601><171><151><889><338><292><304><557><616><162><489><958><694><751><62><879><949><524><637><66><958><795><108><927><470><454><493><879><949><524><158><487><368><1><15><450><91><128><162><511><584><906><376><472><111><615><269><371><476><13><136><291><136><365><eosp> ", "plain_text": "<neutral> Give me a fine fat goose. EmoSDS: <happiness> Sure thing! I'll make sure it's the best one we can find!", "residual_length": 134, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Neutral/0012_000313.npy", "dialogue_id": "1529_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe Sam actually made it to the party!\nuser: <surprise> Right? I thought he wouldn't show up at all!\nEmoSDS: <neutral> But now that he's here, we should definitely go say hi.\n user: <sosp><79><291><79><592><136><592><136><837><615><371><158><425><487><432><918><432><261><889><493><861><301><57><890><304><933><879><275><99><467><227><472><260><158><425><557><958><831><856><644><889><103><472><111><260><899><879><82><487><432><304><403><933><998><354><898><58><403><643><701><136><863><13><136><13><291><13><365><eosp> ", "plain_text": "<neutral> Sam waved his arm vaguely. EmoSDS: <neutral> I wonder what he's trying to say with that wave.", "residual_length": 112, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Neutral/0019_000169.npy", "dialogue_id": "825_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Hey, how's everything going with you?\nuser: <happiness> Things have been pretty good, thanks for asking!\nEmoSDS: <surprise> Really? I didn't expect that!\n user: <sosp><13><136><13><136><13><291><136><13><511><680><133><375><936><898><292><393><472><260><158><425><113><450><564><526><219><615><223><144><98><292><700><376><472><260><862><171><151><889><760><432><15><58><403><643><196><757><136><757><136><13><136><13><365><eosp> ", "plain_text": "<neutral> please excuse me. EmoSDS: <happiness> Of course! No rush at all, I'm here whenever you're ready.", "residual_length": 87, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Neutral/0013_000047.npy", "dialogue_id": "225_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I didn't really think much of it at first.\nuser: <happiness> Well, I actually love how it stands out!\nEmoSDS: <sadness> It's just too bad that it doesn’t seem to fit the overall theme.\n user: <sosp><13><79><291><79><592><136><13><136><13><291><136><511><921><104><295><866><296><47><261><62><879><128><524><275><682><467><292><304><933><524><347><487><432><927><470><454><493><204><162><347><487><368><1><545><522><120><472><260><121><159><113><450><91><162><439><112><919><890><42><856><103><450><128><162><275><10><19><775><296><47><1><545><923><43><213><879><524><212><262><231><237><103><180><998><121><487><43><227><111><260><223><268><144><275><70><737><333><870><47><62><128><680><128><511><275><425><295><443><827><757><136><13><291><13><136><291><13><365><eosp> ", "plain_text": "<anger> Perhaps you think that is a queer title for this chapter. EmoSDS: <anger> You know I just find it a bit vexing, right?", "residual_length": 187, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Angry/0020_000658.npy", "dialogue_id": "1505_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you see the shoes she wore to the party?\nuser: <happiness> Yeah, they were actually pretty cool!\nEmoSDS: <neutral> Right? I didn't expect that style would look so good on her.\n user: <sosp><13><136><13><291><13><136><592><291><136><876><311><104><295><104><295><930><70><737><906><376><472><260><899><861><301><57><890><754><848><354><517><441><958><47><41><128><584><524><313><338><309><304><930><982><70><10><196><227><131><111><615><371><476><457><136><13><136><13><136><13><365><eosp> ", "plain_text": "<anger> Her shoes were like fishes. EmoSDS: <surprise> Wow, that's a harsh way to put it! What did you really think about them?", "residual_length": 116, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Angry/0011_000362.npy", "dialogue_id": "59_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I didn't notice the noise at first.\nuser: <sadness> It's been like this for days, and I can't stand it anymore.\nEmoSDS: <happiness> I thought it was just part of nature! It's kind of charming.\n user: <sosp><13><79><235><79><235><79><311><136><876><274><360><320><545><450><128><574><162><511><686><487><368><47><41><879><524><313><158><309><442><583><125><760><432><350><470><454><493><288><353><76><70><921><104><109><997><85><866><831><62><128><574><511><680><338><304><454><125><376><20><997><866><368><360><320><493><288><162><708><10><196><450><162><511><347><292><403><300><557><918><42><856><607><31><757><592><13><235><13><365><eosp> ", "plain_text": "<anger> A deafening chirruping rent the air. EmoSDS: <neutral> I can see you're really frustrated, but do you think we could find a way to block it out?", "residual_length": 150, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Angry/0018_000405.npy", "dialogue_id": "268_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I think we need to consider all our options before making a decision.\nuser: <happiness> I'm excited about the possibilities this could bring us!\nEmoSDS: <sadness> But what if it leads to unintended consequences for us?\n user: <sosp><13><291><369><79><291><79><136><541><301><57><919><376><889><760><304><327><304><403><204><450><162><275><682><783><104><919><231><173><890><927><470><454><125><760><487><159><985><889><861><301><57><890><159><287><111><524><347><487><368><945><41><545><128><574><162><511><680><672><19><333><820><743><831><438><78><983><655><31><757><136><13><136><13><136><13><291><13><365><eosp> ", "plain_text": "<anger> We may join with that power. EmoSDS: <anger> Do you really think that’s a good idea? It sounds risky!", "residual_length": 139, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Angry/0019_000616.npy", "dialogue_id": "1300_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Hey, did you hear about the party last night?\nuser: <happiness> Yeah, I had a great time! Everyone was so lively.\nEmoSDS: <sadness> I wish I could've gone, but I just wasn't feeling well.\n user: <sosp><13><235><592><79><592><13><136><162><511><708><10><672><333><311><296><523><108><583><760><557><360><130><583><125><889><958><47><360><640><450><128><511><584><919><20><983><811><861><680><301><173><332><231><213><45><128><162><584><672><43><958><831><47><277><62><128><574><162><171><125><760><368><47><41><128><511><526><371><862><171><125><889><89><231><655><856><583><760><432><382><470><454><701><13><235><13><365><eosp> ", "plain_text": "<anger> Tom and Michael woke up next morning. EmoSDS: <neutral> Uh-oh, what happened? Did they do something stupid again?", "residual_length": 145, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Angry/0018_000457.npy", "dialogue_id": "523_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe we finally finished that project!\nuser: <happiness> I know, right? It feels like such a huge weight off our shoulders!\nEmoSDS: <surprise> And did you see how well the presentation went?\n user: <sosp><13><748><13><235><13><876><998><487><918><432><36><583><125><760><159><701><128><136><13><235><162><301><57><292><300><557><958><523><213><402><111><615><371><158><425><487><360><918><1><327><15><403><292><643><136><79><136><876><489><958><743><831><743><333><311><775><743><438><521><88><311><757><13><235><13><365><eosp> ", "plain_text": "<anger> Then we all say aha! EmoSDS: <sadness> Yeah, but I wish it didn’t feel so forced, you know?", "residual_length": 144, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Angry/0017_000399.npy", "dialogue_id": "237_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> So, what are you planning to cook tonight?\nuser: <happiness> I was thinking of making our favorite pasta dish.\nEmoSDS: <surprise> Really? I didn't know you felt like cooking today!\n user: <sosp><13><136><13><136><13><291><592><79><592><876><131><111><615><223><862><144><162><499><487><918><320><930><982><70><737><158><213><20><91><162><680><778><311><296><958><831><795><743><831><47><178><41><128><574><511><275><10><158><425><906><376><388><91><701><136><291><136><13><136><365><eosp> ", "plain_text": "<anger> A special pot too. EmoSDS: <sadness> I wish you wouldn't yell about it; I just wanted to make dinner together.", "residual_length": 95, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Angry/0011_000672.npy", "dialogue_id": "1573_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Hey, did you see what happened at the party last night?\nuser: <surprise> No, what happened?\nEmoSDS: <happiness> Alice danced like nobody was watching, it was hilarious!\n user: <sosp><13><136><291><13><291><13><136><557><105><334><304><403><304><933><376><591><20><354><944><354><517><898><360><304><283><292><933><522><292><304><227><472><260><158><43><64><213><197><583><125><557><162><511><368><820><47><438><213><890><159><472><111><615><371><158><472><260><354><517><441><47><820><277><62><128><574><162><511><680><672><757><136><79><136><79><291><79><136><369><136><369><291><369><13><365><eosp> ", "plain_text": "<anger> A lady, is on Alice's lap! EmoSDS: <neutral> That sounds a bit inappropriate; we should probably talk to her.", "residual_length": 149, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Angry/0019_000551.npy", "dialogue_id": "982_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <sadness> I just don't know how we're going to get through this.\nuser: <neutral> We can figure this out together, just take a breath.\nEmoSDS: <happiness> Honestly, it feels a bit better knowing we're not alone.\n user: <sosp><79><136><592><136><235><13><162><136><511><275><10><309><918><334><304><232><450><128><574><13><235><162><511><584><672><104><43><856><754><295><866><364><120><450><632><76><70><737><396><31><136><489><958><831><568><213><898><120><472><260><158><425><36><583><125><156><354><517><958><795><438><47><579><400><615><371><223><268><144><275><467><292><304><300><432><368><47><277><131><128><162><13><162><511><275><10><155><476><757><476><757><136><13><136><433><13><365><eosp> ", "plain_text": "<anger> Take courage all isn't lost yet. EmoSDS: <neutral> I appreciate you trying to lift spirits, but it feels overwhelming right now.", "residual_length": 164, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Angry/0014_000394.npy", "dialogue_id": "213_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I don't really watch much TV these days.\nuser: <happiness> Oh, I totally get that! There's so much going on outside.\nEmoSDS: <sadness> Yeah, but I miss some of the shows we used to watch together.\n user: <sosp><13><592><79><136><79><433><79><422><592><136><622><292><376><919><231><484><237><856><644><889><760><304><120><450><353><682><783><227><159><953><20><861><301><57><517><958><47><1><304><933><879><524><171><125><283><358><760><360><918><42><261><56><104><295><113><450><128><162><584><98><196><309><227><36><125><728><72><328><904><371><158><425><432><927><470><454><470><927><432><297><131><111><615><371><158><425><751><795><108><875><808><701><757><136><13><433><13><136><13><365><eosp> ", "plain_text": "<anger> Your midget wife never can sing a song. EmoSDS: <anger> That's a rude thing to say about her!", "residual_length": 162, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Angry/0014_000406.npy", "dialogue_id": "269_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I'm so excited to hear that story! It sounds fun!\nuser: <neutral> It's about how they became best friends.\nEmoSDS: <surprise> Really? I didn't expect that twist!\n user: <sosp><13><136><79><291><79><962><592><136><837><371><223><268><144><275><158><104><20><445><890><43><304><933><564><162><275><10><921><311><296><958><103><583><493><99><467><292><454><125><760><958><795><47><477><1><432><583><760><197><958><62><91><162><511><680><231><173><751><172><1><432><557><432><583><125><998><121><43><985><889><958><795><108><667><288><512><162><511><98><292><403><68><58><136><701><757><13><195><291><13><381><136><13><365><eosp> ", "plain_text": "<anger> Story twenty nine a boy and a monkey. EmoSDS: <sadness> Oh no, why does that sound so serious? What happened?", "residual_length": 144, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Angry/0020_000393.npy", "dialogue_id": "207_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Have you heard of that story about Finn?\nuser: <happiness> Yeah! It’s such a charming tale.\nEmoSDS: <sadness> I always thought it had a bittersweet ending, though.\n user: <sosp><13><291><13><291><13><136><13><136><162><511><347><487><918><360><583><760><159><36><583><125><760><121><316><62><879><524><313><347><487><42><856><866><304><292><930><982><70><737><783><486><376><889><760><432><15><113><580><128><584><104><295><31><701><13><136><13><136><13><365><eosp> ", "plain_text": "<anger> Finn and the fairy shoemaker. EmoSDS: <neutral> What's got you so worked up about Finn and that shoemaker?", "residual_length": 112, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Angry/0020_000471.npy", "dialogue_id": "588_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I guess everyone is just trying to figure out their plans.\nuser: <happiness> Yeah, it’s exciting to see what everyone comes up with!\nEmoSDS: <sadness> But some people might feel lost, especially if they don’t have anything lined up.\n user: <sosp><79><291><79><592><136><235><13><162><861><301><57><173><751><277><545><128><162><171><861><301><57><890><103><320><450><998><347><487><432><304><933><450><162><99><783><906><376><167><890><120><320><450><998><347><467><292><304><557><432><320><583><125><493><522><686><425><159><985><879><995><998><236><347><467><700><292><403><304><382><434><31><757><136><13><433><136><13><365><eosp> ", "plain_text": "<anger> What would they do at the end of the year? EmoSDS: <neutral> I think it's stressful for many, honestly. They might make some tough choices.", "residual_length": 128, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Angry/0014_000587.npy", "dialogue_id": "1160_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> So, what are you planning to cook tonight?\nuser: <happiness> I was thinking of making our favorite pasta dish.\nEmoSDS: <surprise> Really? I didn't know you felt like cooking today!\n user: <sosp><13><291><13><136><13><136><616><136><616><136><958><751><579><320><111><615><269><371><862><144><162><499><487><360><930><982><70><737><425><43><213><45><204><91><162><511><680><375><311><296><958><831><743><47><277><128><162><511><275><10><196><309><304><120><961><376><213><376><20><91><701><91><13><291><13><365><eosp> ", "plain_text": "<anger> A special pot too. EmoSDS: <sadness> I wish you wouldn't yell about it; I just wanted to make dinner together.", "residual_length": 110, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Angry/0012_000672.npy", "dialogue_id": "1573_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you see that strange light in the sky?\nuser: <happiness> Yeah! It was so beautiful, like a fireworks show!\nEmoSDS: <sadness> I wish I could've shared that moment with someone.\n user: <sosp><79><958><136><13><235><136><13><511><274><47><360><304><933><450><128><204><162><680><354><898><304><350><454><283><493><288><99><10><899><171><889><173><958><47><1><918><47><557><958><795><743><47><477><1><304><472><260><259><899><311><375><311><64><523><438><754><295><31><450><162><618><757><136><13><136><13><235><13><136><13><365><eosp> ", "plain_text": "<anger> I blinked my eyes hard. EmoSDS: <neutral> What's wrong? Did something happen that upset you?", "residual_length": 114, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0016/Angry/0016_000485.npy", "dialogue_id": "657_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe we actually made it to the concert on time!\nuser: <surprise> Right? I thought we were going to miss the opening act!\nEmoSDS: <neutral> It was such a great vibe, everyone was having fun.\n user: <sosp><13><235><13><235><13><592><79><422><136><876><105><304><320><879><328><904><371><394><360><368><47><360><320><472><260><259><371><158><171><125><760><43><173><213><20><811><861><301><57><380><42><1><350><304><58><930><982><10><19><368><831><438><178><62><128><275><10><425><227><450><204><91><162><511><99><467><403><393><111><260><259><158><467><292><403><470><643><701><136><235><13><136><13><136><13><365><eosp> ", "plain_text": "<anger> It says no way! shouted Daisy. EmoSDS: <sadness> Oh no, Daisy sounded really upset about something.", "residual_length": 138, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Angry/0018_000578.npy", "dialogue_id": "1114_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <sadness> I just feel like everything is falling apart right now.\nuser: <happiness> I know it's tough, but we can get through this together!\nEmoSDS: <neutral> But what if things don't change? It's hard to stay hopeful.\n user: <sosp><13><235><592><79><235><79><592><235><136><162><275><10><333><309><350><232><450><128><574><162><511><584><672><311><856><1><382><15><58><450><632><353><682><783><425><557><616><489><958><523><484><110><568><213><645><162><557><442><120><472><260><966><158><425><36><320><493><288><275><158><159><45><97><998><790><213><523><438><579><400><904><371><268><144><99><196><292><232><292><300><368><47><145><277><41><545><128><511><275><10><155><757><136><13><235><13><235><13><365><eosp> ", "plain_text": "<anger> Take courage, all isn't lost yet. EmoSDS: <surprise> Wait, what do you mean by that? Are you really sure about it?", "residual_length": 151, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Angry/0018_000394.npy", "dialogue_id": "212_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I'm so excited to start this new chapter!\nuser: <neutral> I think it'll be interesting to see where this story goes.\nEmoSDS: <surprise> Wait, are you serious? I didn't expect that twist at the end!\n user: <sosp><13><863><136><592><291><592><79><592><136><837><291><136><162><275><76><682><70><737><309><918><47><261><62><128><511><275><737><104><295><848><450><564><162><708><10><333><918><432><583><125><760><557><218><20><861><301><20><983><603><983><231><754><644><519><889><374><20><861><811><861><301><57><380><751><568><110><603><45><91><128><162><511><584><672><425><43><64><3><213><89><808><479><701><136><13><291><13><136><13><136><13><365><eosp> ", "plain_text": "<anger> Chapter ten a warm welcome. EmoSDS: <sadness> I guess it's a welcome, but it feels a bit forced, don’t you think?", "residual_length": 144, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Angry/0013_000361.npy", "dialogue_id": "53_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe we're actually out here doing this!\nuser: <happiness> I know, right? It feels amazing to be outdoors like this.\nEmoSDS: <neutral> Just remember to aim carefully; we don't want to hit anyone by accident.\n user: <sosp><13><709><79><235><79><592><837><235><136><511><708><10><311><296><523><108><583><889><760><159><557><128><162><171><125><358><760><752><47><568><213><45><97><354><898><487><360><557><128><958><831><856><128><162><105><432><42><856><295><754><866><856><43><445><376><444><260><615><371><899><524><936><354><517><523><743><438><60><145><1><557><128><196><643><136><13><136><235><13><365><eosp> ", "plain_text": "<anger> Tom now let our arrows fly! EmoSDS: <sadness> I... I didn't mean for it to come to this.", "residual_length": 138, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0016/Angry/0016_000420.npy", "dialogue_id": "341_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> Can you believe how playful she is today?\nuser: <neutral> Yeah, she's always full of energy.\nEmoSDS: <sadness> I just wish she wouldn't be so clumsy sometimes.\n user: <sosp><13><79><433><79><592><136><13><136><837><311><856><295><128><162><511><680><133><775><296><831><795><438><568><62><861><57><890><432><36><125><493><998><618><557><162><105><309><304><454><125><493><288><275><10><196><338><292><304><43><295><31><557><162><489><958><743><47><1><304><643><196><724><757><136><114><13><742><433><13><136><13><136><13><365><eosp> ", "plain_text": "<anger> Her paw went into your eye? EmoSDS: <neutral> I know it was an accident, but could she be a bit more careful?", "residual_length": 128, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Angry/0014_000570.npy", "dialogue_id": "1072_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Hey, did you finish that report we talked about?\nuser: <sadness> I tried, but it just didn't come together as I hoped.\nEmoSDS: <happiness> That's okay! We can work on it together and help each other out.\n user: <sosp><79><291><79><592><136><13><162><511><680><672><311><213><898><120><304><292><403><700><393><472><747><111><904><371><158><557><304><206><450><128><584><526><371><269><223><268><584><162><511><98><292><304><376><180><472><260><862><171><151><125><889><760><927><58><470><403><643><701><136><13><291><13><136><13><365><eosp> ", "plain_text": "<anger> please excuse me. EmoSDS: <neutral> Is everything alright? You seem really upset.", "residual_length": 118, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Angry/0014_000397.npy", "dialogue_id": "228_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you finish the project we discussed?\nuser: <happiness> Yes, I wrapped it up yesterday and I think you’ll love it!\nEmoSDS: <neutral> That's great to hear! What's the main feature?\n user: <sosp><544><709><83><742><748><83><709><544><13><666><13><666><136><666><511><489><831><47><477><360><350><470><454><125><760><43><751><213><20><311><333><19><820><47><438><20><402><450><162><275><10><906><20><890><213><20><861><204><91><162><511><680><487><432><327><58><376><20><240><231><655><295><103><587><450><99><104><856><295><848><472><111><260><371><904><371><476><464><701><757><13><136><13><291><13><365><eosp> ", "plain_text": "<anger> I know how to obey orders. EmoSDS: <sadness> It seems like you're really frustrated. What happened?", "residual_length": 133, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Angry/0015_000645.npy", "dialogue_id": "1443_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I've been thinking about how people follow trends nowadays.\nuser: <happiness> It's a little amusing, actually, but also kind of sad.\nEmoSDS: <sadness> Yeah, it's like they're not really themselves anymore.\n user: <sosp><13><592><235><592><79><311><958><311><136><489><274><831><360><628><109><57><890><103><450><998><116><328><904><371><269><371><899><144><162><511><584><871><173><831><438><579><400><524><887><487><557><360><320><998><128><162><467><292><232><448><111><371><899><524><212><66><831><404><568><603><213><20><890><364><31><131><111><615><904><371><476><757><136><13><235><13><235><13><365><eosp> ", "plain_text": "<anger> I would scoff at these followers. EmoSDS: <sadness> It's frustrating to see, but they might be lost in it all.", "residual_length": 145, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Angry/0018_000607.npy", "dialogue_id": "1252_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> How did the meeting go yesterday?\nuser: <happiness> It went really well! Everyone seemed to be on board with the ideas.\nEmoSDS: <surprise> Wow, that’s great to hear! I didn’t expect such a positive outcome.\n user: <sosp><13><291><13><291><13><136><837><70><196><292><393><111><371><904><571><371><158><487><368><918><432><360><545><522><557><300><304><36><125><728><125><493><72><328><371><158><425><43><316><985><204><998><204><162><99><467><292><546><376><933><450><376><997><861><997><57><231><655><890><382><304><472><111><615><371><10><155><757><592><13><291><13><365><eosp> ", "plain_text": "<anger> She said in subdued voice. EmoSDS: <surprise> What? That doesn't sound like her at all! Did something go wrong?", "residual_length": 126, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0016/Angry/0016_000613.npy", "dialogue_id": "1282_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you hear about the changes in the valley lately?\nuser: <happiness> Yeah, I did! It seems like there's a buzz around the place.\nEmoSDS: <sadness> I just hope everything turns out okay for the people living there.\n user: <sosp><13><235><13><235><13><79><592><136><837><982><269><70><10><309><292><933><91><162><511><584><672><311><173><62><889><493><91><162><511><347><487><368><47><942><820><710><41><128><511><584><10><268><144><275><10><158><425><180><998><347><121><159><985><995><347><487><368><47><743><47><568><213><898><58><403><643><196><79><592><13><235><13><365><eosp> ", "plain_text": "<anger> She come back to the valley. EmoSDS: <anger> I can't believe she had the nerve to return after everything!", "residual_length": 112, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Angry/0018_000648.npy", "dialogue_id": "1457_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you know that hippos are quite interesting animals?\nuser: <happiness> Yeah! They can hold their breath underwater for several minutes!\nEmoSDS: <surprise> Really? I didn't know that!\n user: <sosp><13><136><592><136><369><166><136><13><235><13><511><958><831><743><47><333><309><918><159><450><91><574><162><511><680><790><173><831><438><568><213><983><603><213><991><103><359><909><79><899><136><20><45><997><20><715><354><898><43><304><985><998><236><472><260><371><158><425><823><403><283><350><470><583><125><493><998><347><121><159><472><260><371><158><467><906><376><20><861><811><301><57><890><136><114><13><235><13><235><13><136><13><365><eosp> ", "plain_text": "<anger> A hippo lives in the zoo. EmoSDS: <sadness> It's frustrating to think about how they are kept in captivity.", "residual_length": 164, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Angry/0015_000437.npy", "dialogue_id": "425_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> What do you think about the party last night?\nuser: <happiness> It was such a fun time, I can't believe we danced so much!\nEmoSDS: <sadness> Yeah, but it felt a bit empty when everyone started leaving.\n user: <sosp><13><136><13><291><13><136><13><136><13><876><274><47><1><41><450><128><574><162><511><275><10><672><311><231><445><376><997><20><890><159><111><524><862><171><151><958><47><1><213><20><97><354><898><159><320><128><511><584><43><856><31><757><136><13><136><13><291><13><136><863><365><eosp> ", "plain_text": "<anger> I toy with my liqueur. EmoSDS: <neutral> You seem really upset, is everything okay with the drink?", "residual_length": 104, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Angry/0019_000517.npy", "dialogue_id": "816_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Have you heard about the mission last week?\nuser: <happiness> Yeah, I heard it was a success!\nEmoSDS: <neutral> It sure was, lots of twists and turns.\n user: <sosp><13><83><544><83><748><709><83><709><876><360><628><292><933><91><162><574><162><99><686><309><304><933><450><522><162><584><425><43><751><438><655><645><557><432><130><125><889><760><327><304><933><125><286><125><889><760><360><583><125><470><292><933><91><162><680><921><104><856><159><472><260><259><158><425><877><125><197><856><607><31><848><472><111><260><615><371><476><158><757><136><666><136><291><136><365><eosp> ", "plain_text": "<anger> I did go, and made many prisoners. EmoSDS: <neutral> I can’t believe you actually did that. What were you thinking?", "residual_length": 136, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Angry/0015_000352.npy", "dialogue_id": "5_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I was just thinking about what to do this weekend.\nuser: <happiness> That sounds great! Any ideas so far?\nEmoSDS: <neutral> Not really, I haven't decided yet.\n user: <sosp><13><592><13><291><13><291><13><511><275><467><292><546><376><43><103><320><879><347><487><557><432><360><583><125><304><292><232><698><524><309><292><232><454><304><125><889><760><958><523><795><108><477><432><350><470><454><493><288><10><196><79><592><136><13><666><13><136><13><365><eosp> ", "plain_text": "<anger> Do you have anything in mind? EmoSDS: <neutral> I was thinking of a few options, but I'm still not sure what to choose.", "residual_length": 105, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Angry/0012_000700.npy", "dialogue_id": "1705_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> So, how have you been feeling lately?\nuser: <sadness> It's been tough, honestly. I think about her every day.\nEmoSDS: <happiness> That's understandable. It shows how much you cared about her.\n user: <sosp><13><592><136><291><592><291><592><13><622><292><300><918><47><579><320><111><615><371><158><557><616><489><958><831><795><47><1><304><877><889><49><760><442><120><320><111><615><428><10><158><425><43><856><295><31><757><13><291><13><136><13><365><eosp> ", "plain_text": "<anger> Yes, I miss her. EmoSDS: <neutral> I get that you're angry, but talking about it might help you feel better.", "residual_length": 109, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Angry/0013_000544.npy", "dialogue_id": "947_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> So, what do you think about the situation?\nuser: <sadness> I've really been thinking about it a lot lately.\nEmoSDS: <happiness> Well, at least we can look forward to new opportunities!\n user: <sosp><13><369><748><13><748><13><369><13><136><748><136><354><142><898><368><432><557><128><574><136><105><283><350><403><304><933><128><162><275><371><10><155><136><13><235><13><136><511><98><292><376><985><879><645><557><958><47><579><320><260><259><371><158><159><180><91><275><682><70><921><333><309><918><350><432><130><131><156><72><328><904><371><904><371><155><136><13><369><748><13><136><876><889><958><432><15><933><450><91><162><680><921><104><866><856><47><368><579><930><982><70><737><425><227><432><320><111><615><371><476><155><136><13><235><13><365><eosp> ", "plain_text": "<anger> Let it give us a chance, my precious. EmoSDS: <sadness> I wish it could be that simple right now.", "residual_length": 191, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Angry/0017_000563.npy", "dialogue_id": "1041_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I noticed you weren't paying attention earlier.\nuser: <sadness> Yeah, I've just been feeling overwhelmed lately.\nEmoSDS: <happiness> I'm here for you, just let me know what you need.\n user: <sosp><13><592><291><79><592><291><592><136><13><235><136><235><136><274><47><628><933><204><162><680><20><213><898><304><470><454><493><288><162><275><862><171><889><173><108><47><820><557><489><958><831><47><477><1><304><472><111><260><259><371><899><311><64><523><831><438><856><31><450><204><275><196><136><592><365><eosp> ", "plain_text": "<anger> I blinked my eyes hard. EmoSDS: <neutral> Is everything okay? You seem really tense.", "residual_length": 96, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Angry/0012_000485.npy", "dialogue_id": "661_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> How have you been feeling lately?\nuser: <sadness> It's been tough, honestly. I just feel really lost.\nEmoSDS: <happiness> I'm glad you opened up; it really helps to talk about it.\n user: <sosp><13><291><13><136><616><489><274><47><1><628><58><632><111><982><70><982><70><737><292><376><450><128><162><601><151><889><958><47><640><111><371><158><425><487><368><751><568><3><78><402><949><524><343><476><136><13><136><13><742><13><291><13><136><13><136><13><291><136><13><136><616><489><958><62><91><162><511><680><133><311><296><523><438><60><579><131><111><615><371><476><457><136><13><136><13><291><13><136><13><365><eosp> ", "plain_text": "<anger> I'd shoot myself. a pause. EmoSDS: <sadness> That sounds really serious. Please know that I'm here for you and we can find a way through this together.", "residual_length": 172, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Angry/0019_000548.npy", "dialogue_id": "967_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> You seem really focused on that goal.\nuser: <sadness> It's just been such a long journey for me.\nEmoSDS: <happiness> But look how far you've come! That's something to celebrate!\n user: <sosp><13><291><13><136><13><291><13><136><876><274><47><579><41><111><371><158><487><432><304><300><557><489><831><743><831><743><47><477><360><320><985><861><20><91><511><680><338><292><232><557><616><162><557><105><368><108><583><493><288><162><680><104><480><997><480><104><295><856><607><31><757><136><114><13><291><13><365><eosp> ", "plain_text": "<anger> I say I will be emperor. EmoSDS: <sadness> I can see you're frustrated, but is it worth fighting over this?", "residual_length": 119, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0019/Angry/0019_000621.npy", "dialogue_id": "1325_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I think we should keep tracking our progress.\nuser: <happiness> You're right; we have made some good strides!\nEmoSDS: <neutral> Let's just focus on the next steps.\n user: <sosp><13><291><13><291><13><136><13><162><136><499><270><64><751><103><56><997><20><861><811><861><301><57><338><292><283><304><43><42><856><754><295><125><760><197><958><831><795><831><277><545><128><557><333><311><296><795><743><47><1><304><292><232><292><403><300><368><60><277><545><128><162><136><384><701><757><79><136><79><136><365><eosp> ", "plain_text": "<anger> But we are not high yet. EmoSDS: <neutral> I know, but we need to stay patient and keep pushing.", "residual_length": 118, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Angry/0013_000503.npy", "dialogue_id": "747_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you hear something outside last night?\nuser: <happiness> Yeah, I heard some noises, but I thought it was just the wind.\nEmoSDS: <sadness> I wish it was just that, but you never know these days.\n user: <sosp><13><291><13><291><13><136><291><136><876><958><751><62><879><524><313><347><467><283><292><232><933><879><524><347><425><227><36><125><728><125><760><36><583><125><728><125><760><958><795><958><47><628><304><15><403><933><128><162><136><13><136><701><757><79><365><eosp> ", "plain_text": "<anger> A thief in the night. EmoSDS: <sadness> That's terrible! I can't believe things have come to this.", "residual_length": 109, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Angry/0013_000666.npy", "dialogue_id": "1540_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I just think we should discuss this openly.\nuser: <sadness> I thought we were on the same page about it.\nEmoSDS: <happiness> It's great that we're finally talking about our feelings.\n user: <sosp><13><136><13><235><136><592><79><592><876><432><130><583><125><20><861><57><173><103><450><128><162><99><158><425><159><320><260><371><158><425><120><450><998><125><286><125><889><338><304><292><283><292><470><454><696><125><728><125><701><13><114><742><13><742><13><291><13><365><eosp> ", "plain_text": "<anger> And what does it mean? EmoSDS: <neutral> It means we need to figure things out together.", "residual_length": 100, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Angry/0014_000693.npy", "dialogue_id": "1673_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Hey, can you remind me what we need for the recipe?\nuser: <happiness> Of course! We need a half pound of flour and two ounces of suet.\nEmoSDS: <sadness> I really hope we have enough at home.\n user: <sosp><13><79><235><79><235><79><235><79><311><136><616><876><958><831><333><410><47><579><41><949><524><128><574><162><511><778><19><333><410><296><108><583><125><493><72><328><158><425><218><233><159><985><879><524><637><936><354><517><831><47><438><213><20><655><890><856><382><557><432><130><583><125><493><288><162><275><708><10><196><906><376><20><57><557><616><557><47><108><402><583><493><288><328><371><158><425><227><120><472><111><615><269><371><269><371><158><376><20><861><301><57><890><380><368><277><557><128><162><511><275><10><155><757><114><13><235><13><235><13><365><eosp> ", "plain_text": "<anger> A half pounds of flour and two ounces suet. EmoSDS: <neutral> Well, do we have that much left in stock?", "residual_length": 189, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0018/Angry/0018_000464.npy", "dialogue_id": "558_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <sadness> I just wish she had a bit more confidence in her voice.\nuser: <happiness> She might surprise you one day with a beautiful song!\nEmoSDS: <neutral> I don't know, maybe she just doesn't enjoy singing that much.\n user: <sosp><13><136><291><136><863><136><13><291><622><292><376><486><295><104><56><889><338><442><120><320><450><353><682><783><376><450><204><997><301><231><173><831><47><1><304><933><879><524><196><136><125><286><728><125><673><760><432><918><261><56><104><295><113><450><98><196><227><36><125><72><285><615><371><158><425><113><58><304><227><159><131><111><260><615><371><158><425><751><64><438><795><523><3><808><125><701><757><136><13><136><365><eosp> ", "plain_text": "<anger> Your midget wife never can sing a song. EmoSDS: <sadness> That feels really harsh, I just want her to be happy with her own talents.", "residual_length": 173, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0013/Angry/0013_000406.npy", "dialogue_id": "272_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <sadness> I know how frustrating mornings can be.\nuser: <neutral> Yeah, but sometimes you just have to deal with it.\nEmoSDS: <happiness> At least we have a chance to make the best of the day ahead!\n user: <sosp><13><136><291><13><592><79><136><291><136><301><861><301><517><441><831><47><360><320><522><425><159><923><487><368><47><438><213><20><861><57><890><432><304><933><450><564><162><511><584><300><43><751><62><128><574><511><680><886><757><159><136><13><136><13><291><13><365><eosp> ", "plain_text": "<anger> Why did I wake up! EmoSDS: <neutral> Maybe it's a sign to start fresh and try again.", "residual_length": 103, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Angry/0011_000673.npy", "dialogue_id": "1578_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I'm so excited to see her in that dress later!\nuser: <neutral> I guess it depends on what she feels comfortable in.\nEmoSDS: <sadness> Yeah, but I hope she doesn't stress out over it.\n user: <sosp><13><235><13><592><79><235><79><592><235><136><837><982><70><196><292><304><227><472><260><747><171><358><673><760><752><820><47><652><523><370><103><91><128><275><682><70><921><737><309><906><120><376><213><518><103><472><966><158><467><304><58><403><470><454><125><701><136><162><136><79><592><136><837><904><371><904><269><371><899><162><584><104><43><856><754><480><295><103><930><128><162><275><10><196><136><909><79><592><136><288><162><275><10><906><376><20><861><301><57><890><432><327><382><42><607><184><31><608><757><136><114><13><235><13><136><13><365><eosp> ", "plain_text": "<anger> She is now choosing skirt to wear. EmoSDS: <neutral> Well, it's her choice, but I wish she wouldn't take so long.", "residual_length": 192, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Angry/0017_000375.npy", "dialogue_id": "121_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I see you’re frustrated about the mistake.\nuser: <sadness> I just don't understand why this keeps happening.\nEmoSDS: <happiness> Let’s try to work on this together for next time.\n user: <sosp><13><544><136><592><79><592><433><592><136><13><433><136><876><274><47><568><213><898><120><320><111><615><371><476><158><781><359><909><79><592><188><585><136><489><274><47><1><43><985><861><680><57><173><213><45><91><162><524><637><66><104><103><113><206><300><368><545><522><159><131><450><128><618><557><432><113><206><204><511><98><300><432><918><172><432><36><583><125><701><136><114><742><13><742><433><136><13><136><13><365><eosp> ", "plain_text": "<anger> Alice I won't forget it again. EmoSDS: <neutral> I appreciate your determination, let's figure out how to avoid it.", "residual_length": 154, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Angry/0014_000632.npy", "dialogue_id": "1379_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did we search the entire area last time?\nuser: <happiness> Yeah, but I think we missed a few spots.\nEmoSDS: <sadness> I really hoped he would have found his way back by now.\n user: <sosp><13><544><13><136><592><136><13><291><863><79><136><622><98><292><376><20><57><890><103><472><111><615><223><268><144><347><158><425><442><120><43><213><603><45><898><890><159><36><583><728><760><121><316><62><879><524><212><66><173><231><110><523><438><237><295><31><131><111><615><223><268><144><275><10><476><136><13><291><13><136><13><365><eosp> ", "plain_text": "<anger> He was still in the forest! EmoSDS: <anger> This is so frustrating! Why isn’t he being more careful?", "residual_length": 109, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Angry/0011_000403.npy", "dialogue_id": "258_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I can't believe how beautiful it is here!\nuser: <neutral> Yeah, it's a nice spot to relax for a bit.\nEmoSDS: <surprise> Look at all the colors in the water!\n user: <sosp><13><592><291><79><369><592><291><13><997><486><292><283><232><933><315><204><162><680><958><831><47><1><304><933><204><998><347><159><43><213><354><603><142><898><120><159><985><995><998><338><304><454><493><91><162><511><680><921><112><231><983><78><402><136><13><136><13><291><13><365><eosp> ", "plain_text": "<anger> Reed by the living pool EmoSDS: <neutral> What’s got you so upset about it?", "residual_length": 111, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Angry/0012_000495.npy", "dialogue_id": "1721_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Did you notice that there are more animals around lately?\nuser: <surprise> Yeah, I actually saw a deer right outside my window yesterday!\nEmoSDS: <happiness> That's amazing! It must have been a beautiful sight.\n user: <sosp><13><235><369><136><13><997><85><866><28><820><710><41><128><511><98><333><309><350><470><454><889><760><557><918><360><545><770><997><85><866><644><985><91><128><162><680><133><375><541><354><517><831><743><477><1><304><545><923><159><557><489><958><523><108><583><125><493><347><121><751><213><180><45><715><20><142><898><338><292><403><700><376><985><236><472><111><371><476><757><136><592><13><235><13><365><eosp> ", "plain_text": "<anger> Rat came and replied on the leaves. EmoSDS: <anger> That's so frustrating! I can't believe they keep messing up the garden.", "residual_length": 169, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0015/Angry/0015_000379.npy", "dialogue_id": "140_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> Have you ever tried those new snacks I was talking about?\nuser: <happiness> Yeah, I did! They were pretty tasty!\nEmoSDS: <sadness> That's good to hear, but I was kind of hoping you wouldn't like them.\n user: <sosp><13><235><13><369><136><13><235><13><235><13><136><274><47><1><545><450><128><574><524><212><66><173><523><438><831><754><856><758><997><866><856><831><47><28><62><998><121><159><103><758><450><204><511><584><871><43><751><3><213><445><20><762><91><13><301><57><890><103><450><347><557><820><831><568><213><402><128><574><162><511><347><487><368><432><130><583><889><125><760><701><162><79><592><13><136><347><487><432><130><125><557><128><162><511><292><403><232><933><162><708><10><196><136><13><235><13><876><998><347><487><918><432><130><125><250><125><701><136><13><748><13><365><eosp> ", "plain_text": "<anger> I'd far rather go without them than eat them! EmoSDS: <sadness> Wow, that hurts a little. I guess our tastes are really different.", "residual_length": 201, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0017/Angry/0017_000425.npy", "dialogue_id": "362_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I think it's really important to gather evidence before making any conclusions.\nuser: <happiness> Absolutely! It helps solidify our understanding and gives us more credibility.\nEmoSDS: <neutral> Yes, and without it, we could misinterpret a lot of things.\n user: <sosp><13><79><433><79><592><136><433><136><499><270><173><43><103><545><450><99><899><20><171><204><768><861><301><57><173><108><583><125><728><770><997><104><866><159><113><450><128><584><779><871><921><112><790><64><958><47><477><1><42><856><295><848><472><111><615><371><571><144><571><347><467><304><292><232><283><304><113><450><584><526><615><269><371><862><128><162><499><680><231><332><484><655><754><295><31><450><128><162><275><10><425><368><261><879><524><66><104><856><295><583><630><432><227><930><982><70><899><144><162><511><680><921><104><486><376><985><879><524><290><476><615><904><371><476><457><136><13><433><13><433><13><136><13><365><eosp> ", "plain_text": "<anger> But one requires the explorer to furnish proofs. EmoSDS: <sadness> I get that, it just feels so frustrating when our hard work isn't acknowledged.", "residual_length": 220, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0014/Angry/0014_000488.npy", "dialogue_id": "676_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I just finished that project we were working on.\nuser: <happiness> That's awesome! I knew you could do it!\nEmoSDS: <sadness> But I feel like it didn't turn out as well as I hoped.\n user: <sosp><13><291><13><136><592><136><13><235><13><204><998><347><487><432><304><587><125><197><125><20><57><486><292><232><300><557><616><240><523><110><213><320><111><615><371><158><425><432><304><557><162><489><958><831><178><311><333><311><296><831><438><743><438><817><60><757><13><136><13><136><13><136><13><365><eosp> ", "plain_text": "<anger> Then we all say aha! EmoSDS: <neutral> I get that you're frustrated, but it might still be okay.", "residual_length": 107, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0012/Angry/0012_000399.npy", "dialogue_id": "234_1"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <neutral> I think the book has some interesting themes.\nuser: <happiness> Yeah, I love how it builds up the characters!\nEmoSDS: <sadness> But some parts really made me feel down, you know?\n user: <sosp><13><79><136><592><291><13><291><136><275><76><682><737><309><918><47><190><62><879><128><511><275><158><783><159><450><564><162><275><708><10><196><309><918><432><481><36><125><728><72><701><757><136><616><136><489><958><399><509><213><20><811><861><204><768><301><231><110><213><89><861><493><861><57><173><380><43><751><213><45><74><584><672><425><43><36><808><889><701><136><13><136><13><365><eosp> ", "plain_text": "<anger> Chapter ten a warm welcome. EmoSDS: <neutral> I didn't expect that reaction; what bothers you about it?", "residual_length": 131, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0011/Angry/0011_000361.npy", "dialogue_id": "54_0"}
{"prefix": "\n# Task\nFrom now on, you are an intelligent voice assistant. You need to provide useful, consistent to the dialogue context, emotionally approval natural response to the user's input speech.\nGiven user speech and history, you need to identify the emotion, transcribe the user speech, predict appropriate response emotion, and predict appropriate response text according to the context.\nEach dialogue turn is formatted as: '{speaker}: <emotion> text'.\nThe emotion should be one of following 5 emotions: <anger>, <happiness>, <neutral>, <sadness>, <surprise>.\nThe generated response should vary in emotion and text based on the user's emotion, even if the input text is the same.\n\nHere's the prompt:\n\nEmoSDS: <happiness> I'm so glad we finally made it to this event!\nuser: <happiness> Yeah, it's nice to see everyone again after so long.\nEmoSDS: <neutral> I hope we can catch up with some friends while we're here.\n user: <sosp><13><291><136><291><13><291><13><585><136><585><125><760><43><445><890><103><450><151><770><889><760><432><918><360><545><522><120><159><36><583><125><493><288><162><328><158><425><113><450><128><162><526><371><158><368><261><62><128><511><686><487><751><958><583><889><288><162><511><778><133><311><296><831><856><103><587><304><292><933><204><91><574><162><499><338><487><43><918><120><472><966><260><171><125><760><432><131><111><615><428><769><428><476><136><13><291><13><136><13><365><eosp> ", "plain_text": "<anger> No admittance except on party business. EmoSDS: <anger> That's really frustrating! We came all this way for nothing?", "residual_length": 160, "residual_path": "/shared/NAS_SSD/jhl/futureinternet/EmotionSpeechDataset_residual_6L-1000k/0020/Angry/0020_000622.npy", "dialogue_id": "1329_1"}
